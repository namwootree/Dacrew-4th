{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setting"
      ],
      "metadata": {
        "id": "TKId0SH-oQ-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library"
      ],
      "metadata": {
        "id": "tqkHJMatoTQG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Uwe-PUxx1Flz"
      },
      "outputs": [],
      "source": [
        "# 데이터 다루기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "# 전처리\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.decomposition import PCA, KernelPCA, SparsePCA, TruncatedSVD, FastICA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
        "\n",
        "# 모델링\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score # 재현율\n",
        "from sklearn.metrics import precision_score # 정밀도\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 기타\n",
        "import os\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "B7YGq6Py1HFA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.optim import Optimizer, AdamW\n",
        "from torch.optim.lr_scheduler import LambdaLR, CyclicLR, OneCycleLR"
      ],
      "metadata": {
        "id": "U-Df5snx1IVE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "1saXz_tA1KFq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU"
      ],
      "metadata": {
        "id": "Jx1fv0oNobYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWXlBCmpoN-R",
        "outputId": "d4083ed1-c2f2-4bac-ed8e-56e6c2124d0e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb 19 05:46:04 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    50W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')"
      ],
      "metadata": {
        "id": "VKVUFl5Z1Li8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixed Random Seed"
      ],
      "metadata": {
        "id": "jpHKZdrzodHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(42) # Seed 고정"
      ],
      "metadata": {
        "id": "uJJcsV1r1Mt1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data Set"
      ],
      "metadata": {
        "id": "6UuYP97soe3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goolge Drive Mount"
      ],
      "metadata": {
        "id": "AStlM68DogNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeVZI9271PKV",
        "outputId": "20bfcdd7-431d-4153-fe2f-9cd163f3cf63"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unzip File"
      ],
      "metadata": {
        "id": "ubzOI9QioiFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip --qq '/content/drive/MyDrive/머신러닝 엔지니어링/데이콘/사기거래/data/사기거래.zip'"
      ],
      "metadata": {
        "id": "Hcg3DfOl1Qlr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load CSV"
      ],
      "metadata": {
        "id": "1fzNvNFIojiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/train.csv')\n",
        "val = pd.read_csv('/content/val.csv')\n",
        "test = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "EwSXD0ex1R0q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "B1mUo_-zon3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection"
      ],
      "metadata": {
        "id": "9vOfjM8oopiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.drop(columns=['ID']) \n",
        "\n",
        "X_val = val.drop(columns=['ID', 'Class']) \n",
        "y_val = val['Class']\n",
        "\n",
        "X_test = test.drop(columns=['ID'])"
      ],
      "metadata": {
        "id": "1th0Lc6h1TTk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[['V3', 'V4', 'V9', 'V10', 'V11',\n",
        "                   'V12', 'V14', 'V16', 'V17', 'V18']]\n",
        "\n",
        "X_val = X_val[['V3', 'V4', 'V9', 'V10', 'V11',\n",
        "               'V12', 'V14', 'V16', 'V17', 'V18']]\n",
        "\n",
        "X_test = X_test[['V3', 'V4', 'V9', 'V10', 'V11',\n",
        "                 'V12', 'V14', 'V16', 'V17', 'V18']]"
      ],
      "metadata": {
        "id": "suWUzg_w1UO4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_drop_cols = list(X_train.columns) + ['ID']\n",
        "\n",
        "list_etc_cols = list(train.drop(columns=list_drop_cols))"
      ],
      "metadata": {
        "id": "n5MQTkr_1Vsr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list_etc_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoPjhwYcGHIy",
        "outputId": "e631d6fd-9221-48b8-ccff-0dec89c2245d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dimesion_reducer(train, val, test, random_state):\n",
        "\n",
        "  dimesion_reducer = SparsePCA(n_components=128,\n",
        "                             alpha=0.001,\n",
        "                             random_state=random_state)\n",
        "\n",
        "  PCA_train = dimesion_reducer.fit_transform(train)\n",
        "  PCA_val = dimesion_reducer.transform(val)\n",
        "  PCA_test = dimesion_reducer.transform(test)\n",
        "\n",
        "  PCA_train = pd.DataFrame(PCA_train) \n",
        "  PCA_val = pd.DataFrame(PCA_val)\n",
        "  PCA_test = pd.DataFrame(PCA_test)\n",
        "\n",
        "  dimesion_reducer = SparseRandomProjection(n_components=128,\n",
        "                                          eps=0.1,\n",
        "                                          random_state=42)\n",
        "\n",
        "  SRP_train = dimesion_reducer.fit_transform(train)\n",
        "  SRP_val = dimesion_reducer.transform(val)\n",
        "  SRP_test = dimesion_reducer.transform(test)\n",
        "\n",
        "  SRP_train = pd.DataFrame(SRP_train)\n",
        "  SRP_val = pd.DataFrame(SRP_val)\n",
        "  SRP_test = pd.DataFrame(SRP_test)\n",
        "  \n",
        "  dimesion_reducer = FastICA(n_components=128,\n",
        "                             algorithm='parallel',\n",
        "                             whiten=True,\n",
        "                             max_iter=100,\n",
        "                             random_state=42)\n",
        "\n",
        "  ICA_train = dimesion_reducer.fit_transform(train)\n",
        "  ICA_val = dimesion_reducer.transform(val)\n",
        "  ICA_test = dimesion_reducer.transform(test)\n",
        "\n",
        "  ICA_train = pd.DataFrame(ICA_train)\n",
        "  ICA_val = pd.DataFrame(ICA_val)\n",
        "  ICA_test = pd.DataFrame(ICA_test)\n",
        "\n",
        "  # dimesion_reducer = TruncatedSVD(n_components=256,\n",
        "  #                               algorithm='randomized',\n",
        "  #                               n_iter=100,\n",
        "  #                               random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "  # SVD_train = dimesion_reducer.fit_transform(train)\n",
        "  # SVD_val = dimesion_reducer.transform(val)\n",
        "  # SVD_test = dimesion_reducer.transform(test)\n",
        "\n",
        "  # SVD_train = pd.DataFrame(SVD_train)\n",
        "  # SVD_val = pd.DataFrame(SVD_val)\n",
        "  # SVD_test = pd.DataFrame(SVD_test)\n",
        "    \n",
        "  preprocessed_train = pd.concat([PCA_train,\n",
        "                                  SRP_train,\n",
        "                                  ICA_train,\n",
        "                                  #SVD_train,\n",
        "                                  ],\n",
        "                                 axis=1)\n",
        "\n",
        "  preprocessed_val = pd.concat([PCA_val,\n",
        "                                SRP_val,\n",
        "                                ICA_val,\n",
        "                                #SVD_val,\n",
        "                                ],\n",
        "                               axis=1)\n",
        "    \n",
        "  preprocessed_test = pd.concat([PCA_test,\n",
        "                                 SRP_test,\n",
        "                                 ICA_test,\n",
        "                                 #SVD_test,\n",
        "                                 ],\n",
        "                                axis=1)\n",
        "\n",
        "  preprocessed_train.columns = [i for i in range(len(preprocessed_train.columns))]\n",
        "  preprocessed_val.columns = [i for i in range(len(preprocessed_val.columns))]\n",
        "  preprocessed_test.columns = [i for i in range(len(preprocessed_test.columns))]\n",
        "    \n",
        "\n",
        "  return preprocessed_train, preprocessed_val, preprocessed_test"
      ],
      "metadata": {
        "id": "u1UviFrCsLTV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "njK9HQKrozKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auto Encoder"
      ],
      "metadata": {
        "id": "hwoYANqco6kP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, df, eval_mode):\n",
        "        self.df = df\n",
        "        self.eval_mode = eval_mode\n",
        "        if self.eval_mode:\n",
        "            self.labels = self.df['Class'].values\n",
        "            self.df = self.df.drop(columns=['Class']).values\n",
        "        else:\n",
        "            self.df = self.df.values\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        if self.eval_mode:\n",
        "            x = torch.from_numpy(self.df[index]).type(torch.FloatTensor)\n",
        "            y = torch.FloatTensor([self.labels[index]])\n",
        "            return x, y\n",
        "            #self.x = self.df[index]\n",
        "            #self.y = self.labels[index]\n",
        "            #return torch.Tensor(self.x), self.y\n",
        "        else:\n",
        "            self.x = self.df[index]\n",
        "            return torch.Tensor(self.x)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "metadata": {
        "id": "adZTW_tb3RpH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        self.Encoder = nn.Sequential(\n",
        "            \n",
        "            nn.Linear(384,128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.Linear(128,64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.Linear(64,32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.Linear(32,16),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.Linear(16,4),\n",
        "            nn.BatchNorm1d(4),\n",
        "            nn.LeakyReLU(),\n",
        "        )\n",
        "        self.Decoder = nn.Sequential(\n",
        "            \n",
        "            nn.Linear(4,16),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.LeakyReLU(),\n",
        "            \n",
        "            nn.Linear(16,32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.Linear(32,64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.Linear(64,128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.Linear(128,384),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.Encoder(x)\n",
        "        x = self.Decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "NBYFd8UN3TgD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.scheduler = scheduler\n",
        "        self.device = device\n",
        "        # Loss Function\n",
        "        self.criterion = nn.L1Loss().to(self.device)\n",
        "        \n",
        "    def fit(self):\n",
        "        self.model.to(self.device)\n",
        "        best_score = 0\n",
        "        avg = 1\n",
        "        for epoch in range(60):\n",
        "            self.model.train()\n",
        "            train_loss = []\n",
        "            for x in iter(self.train_loader):\n",
        "                x = x.float().to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                _x = self.model(x)\n",
        "                loss = self.criterion(x, _x)\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                train_loss.append(loss.item())\n",
        "\n",
        "            score = self.validation(self.model, 0.975)\n",
        "            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n",
        "\n",
        "            if self.scheduler is not None:\n",
        "                self.scheduler.step(score)\n",
        "\n",
        "            if best_score <= score and avg > np.mean(train_loss):\n",
        "                best_score = score\n",
        "                avg = np.mean(train_loss)\n",
        "                torch.save(model.module.state_dict(), './best_model.pth', _use_new_zipfile_serialization=False)\n",
        "    \n",
        "    def validation(self, eval_model, thr):\n",
        "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "        eval_model.eval()\n",
        "        pred = []\n",
        "        true = []\n",
        "        with torch.no_grad():\n",
        "            for x, y in iter(self.val_loader):\n",
        "                x = x.float().to(self.device)\n",
        "\n",
        "                _x = self.model(x)\n",
        "                diff = cos(x, _x).cpu().tolist()\n",
        "                batch_pred = np.where(np.array(diff)<thr, 1, 0).tolist()\n",
        "                pred += batch_pred\n",
        "                true += y.tolist()\n",
        "\n",
        "        return f1_score(true, pred, average='macro')"
      ],
      "metadata": {
        "id": "XXsRIChU3ge-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(model, thr, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "    pred = []\n",
        "    with torch.no_grad():\n",
        "        for x in iter(test_loader):\n",
        "            x = x.float().to(device)\n",
        "            _x = model(x)\n",
        "            \n",
        "            diff = cos(x, _x).cpu().tolist()\n",
        "            batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n",
        "            pred += batch_pred\n",
        "    return pred"
      ],
      "metadata": {
        "id": "-rCC4zAp3iSq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "nO-3riEao_Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_val = np.zeros(val.shape[0])\n",
        "result_test = np.zeros(test.shape[0])\n",
        "\n",
        "y_val = val[['Class']]\n",
        "\n",
        "for etc_col in list_etc_cols:\n",
        "\n",
        "  X_train = pd.concat([X_train, train[[etc_col]]], axis=1)\n",
        "  X_val = pd.concat([X_val, val[[etc_col]]], axis=1)\n",
        "  X_test = pd.concat([X_test, test[[etc_col]]], axis=1)\n",
        "\n",
        "  scaler = RobustScaler(quantile_range=(45.0, 55.0))\n",
        "\n",
        "  scaled_train = scaler.fit_transform(X_train)\n",
        "\n",
        "  scaled_val = scaler.transform(X_val)\n",
        "  scaled_test = scaler.transform(X_test)\n",
        "\n",
        "  scaled_train = pd.DataFrame(scaled_train)\n",
        "  scaled_val = pd.DataFrame(scaled_val)\n",
        "  scaled_test = pd.DataFrame(scaled_test)\n",
        "\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "\n",
        "  scaled_train = scaler.fit_transform(scaled_train)\n",
        "  scaled_val = scaler.transform(scaled_val)\n",
        "  scaled_test = scaler.transform(scaled_test)\n",
        "\n",
        "  scaled_train = pd.DataFrame(scaled_train)\n",
        "  scaled_val = pd.DataFrame(scaled_val)\n",
        "  scaled_test = pd.DataFrame(scaled_test)\n",
        "\n",
        "  main_columns = list(scaled_train.columns)\n",
        "\n",
        "  com_main = list(combinations(main_columns, 5))\n",
        "\n",
        "  for com in com_main:\n",
        "\n",
        "    x = com[0]\n",
        "    y = com[1]\n",
        "    z = com[2]\n",
        "    w = com[3]\n",
        "    v = com[-1]\n",
        "\n",
        "    scaled_train[f'{x}_{y}_{z}_{w}_{v}_mean'] = (scaled_train[x] + \\\n",
        "                                                 scaled_train[y] + \\\n",
        "                                                 scaled_train[z] + \\\n",
        "                                                 scaled_train[w] + \\\n",
        "                                                 scaled_train[v]) / 5\n",
        "\n",
        "    scaled_val[f'{x}_{y}_{z}_{w}_{v}_mean'] = (scaled_val[x] + \\\n",
        "                                               scaled_val[y] + \\\n",
        "                                               scaled_val[z] + \\\n",
        "                                               scaled_val[w] + \\\n",
        "                                               scaled_val[v]) / 5\n",
        "\n",
        "    scaled_test[f'{x}_{y}_{z}_{w}_{v}_mean'] = (scaled_test[x] + \\\n",
        "                                                scaled_test[y] + \\\n",
        "                                                scaled_test[z] + \\\n",
        "                                                scaled_test[w] + \\\n",
        "                                                scaled_test[v]) / 5\n",
        "  \n",
        "  reduced_train, reduced_val, reduced_test = dimesion_reducer(scaled_train,\n",
        "                                                              scaled_val,\n",
        "                                                              scaled_test,\n",
        "                                                              random_state=42)\n",
        "\n",
        "  print()\n",
        "  print('-'*100)\n",
        "  print()\n",
        "  print(f'{etc_col}')\n",
        "\n",
        "  train_dataset = MyDataset(df=reduced_train, eval_mode=False)\n",
        "  train_loader = DataLoader(train_dataset,\n",
        "                            batch_size=2**13,\n",
        "                            shuffle=True,\n",
        "                            num_workers=6)\n",
        "\n",
        "  reduced_val=pd.concat([reduced_val, val[['Class']]], axis=1)\n",
        "  val_dataset = MyDataset(df=reduced_val, eval_mode=True)\n",
        "  val_loader = DataLoader(val_dataset,\n",
        "                          batch_size=2**13,\n",
        "                          shuffle=False,\n",
        "                          num_workers=6)\n",
        "\n",
        "  model = nn.DataParallel(AutoEncoder())\n",
        "  model.eval()\n",
        "  optimizer = torch.optim.Adam(params = model.parameters(), lr = 1e-2)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                         mode='max',\n",
        "                                                         factor=0.5,\n",
        "                                                         patience=10,\n",
        "                                                         threshold_mode='abs',\n",
        "                                                         min_lr=1e-8, \n",
        "                                                         verbose=True)\n",
        "\n",
        "  trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n",
        "  trainer.fit()\n",
        "\n",
        "  model = AutoEncoder()\n",
        "  model.load_state_dict(torch.load('./best_model.pth'))\n",
        "  model = nn.DataParallel(model)\n",
        "  model.eval()\n",
        "\n",
        "  reduced_val = reduced_val.drop(columns=['Class'])\n",
        "  val_dataset = MyDataset(reduced_val, False)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=2**13, shuffle=False, num_workers=6)\n",
        "\n",
        "  pred_val = prediction(model, 0.975, val_loader, device)\n",
        "  result_val += pred_val\n",
        "\n",
        "  val_score = f1_score(y_val, pred_val, average='macro')\n",
        "  print(f'\\netc col : {etc_col} / Marco F1 Score : {val_score}\\n')\n",
        "\n",
        "  test_dataset = MyDataset(reduced_test, False)\n",
        "  test_loader = DataLoader(test_dataset,\n",
        "                           batch_size=2**13,\n",
        "                           shuffle=False,\n",
        "                           num_workers=6)\n",
        "\n",
        "  pred_test = prediction(model, 0.975, test_loader, device)\n",
        "  result_test += pred_test\n",
        "\n",
        "  X_train = X_train.drop(columns=etc_col)\n",
        "  X_val = X_val.drop(columns=etc_col)\n",
        "  X_test = X_test.drop(columns=etc_col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OVQIg-J2Gao",
        "outputId": "b920eafe-d033-4419-cffc-f078f7d451bd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V1\n",
            "Epoch : [0] Train loss : [0.21008165872522763] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.05966903828084469] Val Score : [0.8652615319692264])\n",
            "Epoch : [2] Train loss : [0.047747542283364704] Val Score : [0.009259262928472728])\n",
            "Epoch : [3] Train loss : [0.03370854750807796] Val Score : [0.9165787375726882])\n",
            "Epoch : [4] Train loss : [0.0387753550229328] Val Score : [0.9165787375726882])\n",
            "Epoch : [5] Train loss : [0.02836516885352986] Val Score : [0.9165787375726882])\n",
            "Epoch : [6] Train loss : [0.024221501845334257] Val Score : [0.9097393418694286])\n",
            "Epoch : [7] Train loss : [0.02456813239093338] Val Score : [0.9097393418694286])\n",
            "Epoch : [8] Train loss : [0.02886658308229276] Val Score : [0.9165787375726882])\n",
            "Epoch : [9] Train loss : [0.02760490189705576] Val Score : [0.8887833851083367])\n",
            "Epoch : [10] Train loss : [0.024304884485900402] Val Score : [0.9034120550289857])\n",
            "Epoch : [11] Train loss : [0.024886378220149448] Val Score : [0.8927516353661109])\n",
            "Epoch : [12] Train loss : [0.02323252148926258] Val Score : [0.9034120550289857])\n",
            "Epoch : [13] Train loss : [0.023646736118410314] Val Score : [0.9034120550289857])\n",
            "Epoch : [14] Train loss : [0.020776721249733652] Val Score : [0.9165787375726882])\n",
            "Epoch 00015: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [15] Train loss : [0.020556672609278133] Val Score : [0.8652615319692264])\n",
            "Epoch : [16] Train loss : [0.019508561518575464] Val Score : [0.8331926764657618])\n",
            "Epoch : [17] Train loss : [0.02148334528984768] Val Score : [0.8331926764657618])\n",
            "Epoch : [18] Train loss : [0.01663584608052458] Val Score : [0.8331926764657618])\n",
            "Epoch : [19] Train loss : [0.01711838087067008] Val Score : [0.8331926764657618])\n",
            "Epoch : [20] Train loss : [0.01783218121688281] Val Score : [0.8189994908759815])\n",
            "Epoch : [21] Train loss : [0.018376788523580347] Val Score : [0.8189994908759815])\n",
            "Epoch : [22] Train loss : [0.017312670592218637] Val Score : [0.8331926764657618])\n",
            "Epoch : [23] Train loss : [0.015816666651517153] Val Score : [0.8331926764657618])\n",
            "Epoch : [24] Train loss : [0.01768829141344343] Val Score : [0.8331926764657618])\n",
            "Epoch : [25] Train loss : [0.018387250269630125] Val Score : [0.8331926764657618])\n",
            "Epoch 00026: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [26] Train loss : [0.01550955159057464] Val Score : [0.8041895926750926])\n",
            "Epoch : [27] Train loss : [0.015776568558067083] Val Score : [0.8189994908759815])\n",
            "Epoch : [28] Train loss : [0.014483470536236252] Val Score : [0.8041895926750926])\n",
            "Epoch : [29] Train loss : [0.016970938670315912] Val Score : [0.7887218676684034])\n",
            "Epoch : [30] Train loss : [0.01966524975640433] Val Score : [0.8041895926750926])\n",
            "Epoch : [31] Train loss : [0.018560406951499835] Val Score : [0.8189994908759815])\n",
            "Epoch : [32] Train loss : [0.017651340392019068] Val Score : [0.8189994908759815])\n",
            "Epoch : [33] Train loss : [0.01564129628241062] Val Score : [0.8041895926750926])\n",
            "Epoch : [34] Train loss : [0.01557296228462032] Val Score : [0.7887218676684034])\n",
            "Epoch : [35] Train loss : [0.0164730230213276] Val Score : [0.8041895926750926])\n",
            "Epoch : [36] Train loss : [0.01587826618924737] Val Score : [0.7887218676684034])\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [37] Train loss : [0.015184725036046334] Val Score : [0.7617289593661732])\n",
            "Epoch : [38] Train loss : [0.015040665931467499] Val Score : [0.755629357577611])\n",
            "Epoch : [39] Train loss : [0.015277140640786715] Val Score : [0.755629357577611])\n",
            "Epoch : [40] Train loss : [0.014979072979518346] Val Score : [0.755629357577611])\n",
            "Epoch : [41] Train loss : [0.0149159487336874] Val Score : [0.755629357577611])\n",
            "Epoch : [42] Train loss : [0.015221875892685992] Val Score : [0.755629357577611])\n",
            "Epoch : [43] Train loss : [0.0149941033284579] Val Score : [0.7887218676684034])\n",
            "Epoch : [44] Train loss : [0.014251932368746825] Val Score : [0.7617289593661732])\n",
            "Epoch : [45] Train loss : [0.015283477359584399] Val Score : [0.8041895926750926])\n",
            "Epoch : [46] Train loss : [0.01480793287711484] Val Score : [0.7437178496040009])\n",
            "Epoch : [47] Train loss : [0.014554598767842566] Val Score : [0.7887218676684034])\n",
            "Epoch 00048: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [48] Train loss : [0.01592541705550892] Val Score : [0.7725514640071602])\n",
            "Epoch : [49] Train loss : [0.01478884562051722] Val Score : [0.6174185476616381])\n",
            "Epoch : [50] Train loss : [0.014694506701614176] Val Score : [0.5320032001215638])\n",
            "Epoch : [51] Train loss : [0.014626896740602595] Val Score : [0.755629357577611])\n",
            "Epoch : [52] Train loss : [0.014134490529873542] Val Score : [0.6839995781035756])\n",
            "Epoch : [53] Train loss : [0.014196997308837516] Val Score : [0.755629357577611])\n",
            "Epoch : [54] Train loss : [0.014766497204878501] Val Score : [0.5906717950274928])\n",
            "Epoch : [55] Train loss : [0.015511102708322662] Val Score : [0.6174185476616381])\n",
            "Epoch : [56] Train loss : [0.014849340410104819] Val Score : [0.7887218676684034])\n",
            "Epoch : [57] Train loss : [0.014161281886377506] Val Score : [0.7725514640071602])\n",
            "Epoch : [58] Train loss : [0.01502487329500062] Val Score : [0.7103329465949443])\n",
            "Epoch 00059: reducing learning rate of group 0 to 3.1250e-04.\n",
            "Epoch : [59] Train loss : [0.01383557410112449] Val Score : [0.6174185476616381])\n",
            "\n",
            "etc col : V1 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V2\n",
            "Epoch : [0] Train loss : [0.2021984372820173] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.059510121920279095] Val Score : [0.6104154666330657])\n",
            "Epoch : [2] Train loss : [0.0434318957850337] Val Score : [0.7353562550268086])\n",
            "Epoch : [3] Train loss : [0.03077042954308646] Val Score : [0.2901715377532269])\n",
            "Epoch : [4] Train loss : [0.037909060051398616] Val Score : [0.5031410366215426])\n",
            "Epoch : [5] Train loss : [0.03874421864748001] Val Score : [0.890501890608512])\n",
            "Epoch : [6] Train loss : [0.028909696266055107] Val Score : [0.432085653863341])\n",
            "Epoch : [7] Train loss : [0.025217739599091665] Val Score : [0.9137051774467988])\n",
            "Epoch : [8] Train loss : [0.025922335551253388] Val Score : [0.9137051774467988])\n",
            "Epoch : [9] Train loss : [0.03272838491414275] Val Score : [0.6080793471614693])\n",
            "Epoch : [10] Train loss : [0.027158092175211226] Val Score : [0.8967110829723166])\n",
            "Epoch : [11] Train loss : [0.025617236138454506] Val Score : [0.890501890608512])\n",
            "Epoch : [12] Train loss : [0.02042973999466215] Val Score : [0.899903286500554])\n",
            "Epoch : [13] Train loss : [0.020394293990518366] Val Score : [0.8598769209128951])\n",
            "Epoch : [14] Train loss : [0.02106649867658104] Val Score : [0.8927516353661109])\n",
            "Epoch : [15] Train loss : [0.018902543133922985] Val Score : [0.8598769209128951])\n",
            "Epoch : [16] Train loss : [0.021646908750491484] Val Score : [0.890501890608512])\n",
            "Epoch : [17] Train loss : [0.02188639103301934] Val Score : [0.9137051774467988])\n",
            "Epoch : [18] Train loss : [0.021608904669327394] Val Score : [0.899903286500554])\n",
            "Epoch 00019: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [19] Train loss : [0.02124673207955701] Val Score : [0.8887833851083367])\n",
            "Epoch : [20] Train loss : [0.020904878420489176] Val Score : [0.8598769209128951])\n",
            "Epoch : [21] Train loss : [0.020724672158913954] Val Score : [0.9034120550289857])\n",
            "Epoch : [22] Train loss : [0.020858499221503735] Val Score : [0.899903286500554])\n",
            "Epoch : [23] Train loss : [0.020089888546083654] Val Score : [0.8598769209128951])\n",
            "Epoch : [24] Train loss : [0.01723008556291461] Val Score : [0.8598769209128951])\n",
            "Epoch : [25] Train loss : [0.016567446357969726] Val Score : [0.8041895926750926])\n",
            "Epoch : [26] Train loss : [0.01698802039027214] Val Score : [0.8189994908759815])\n",
            "Epoch : [27] Train loss : [0.017512313688972166] Val Score : [0.7887218676684034])\n",
            "Epoch : [28] Train loss : [0.017537222443414584] Val Score : [0.8858506104888013])\n",
            "Epoch : [29] Train loss : [0.017248486833912984] Val Score : [0.8189994908759815])\n",
            "Epoch 00030: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [30] Train loss : [0.015754740419132367] Val Score : [0.8189994908759815])\n",
            "Epoch : [31] Train loss : [0.015464149881154299] Val Score : [0.8041895926750926])\n",
            "Epoch : [32] Train loss : [0.017990097403526306] Val Score : [0.755629357577611])\n",
            "Epoch : [33] Train loss : [0.01783771506909813] Val Score : [0.7887218676684034])\n",
            "Epoch : [34] Train loss : [0.016845891451729194] Val Score : [0.8189994908759815])\n",
            "Epoch : [35] Train loss : [0.015411652158945799] Val Score : [0.8189994908759815])\n",
            "Epoch : [36] Train loss : [0.016276170233530656] Val Score : [0.8041895926750926])\n",
            "Epoch : [37] Train loss : [0.01615529939798372] Val Score : [0.8189994908759815])\n",
            "Epoch : [38] Train loss : [0.016057198401540518] Val Score : [0.7887218676684034])\n",
            "Epoch : [39] Train loss : [0.016599946189671755] Val Score : [0.8189994908759815])\n",
            "Epoch : [40] Train loss : [0.015318952766912324] Val Score : [0.8041895926750926])\n",
            "Epoch 00041: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [41] Train loss : [0.016078636249793426] Val Score : [0.7725514640071602])\n",
            "Epoch : [42] Train loss : [0.015075157662587506] Val Score : [0.7498242036425005])\n",
            "Epoch : [43] Train loss : [0.015559482454721416] Val Score : [0.7498242036425005])\n",
            "Epoch : [44] Train loss : [0.01507625835282462] Val Score : [0.6174185476616381])\n",
            "Epoch : [45] Train loss : [0.01568791376692908] Val Score : [0.755629357577611])\n",
            "Epoch : [46] Train loss : [0.015320186037570238] Val Score : [0.6619424283038114])\n",
            "Epoch : [47] Train loss : [0.015090558278773512] Val Score : [0.7725514640071602])\n",
            "Epoch : [48] Train loss : [0.01689135349754776] Val Score : [0.755629357577611])\n",
            "Epoch : [49] Train loss : [0.01584200607612729] Val Score : [0.755629357577611])\n",
            "Epoch : [50] Train loss : [0.015656225117189542] Val Score : [0.755629357577611])\n",
            "Epoch : [51] Train loss : [0.014896011578717403] Val Score : [0.755629357577611])\n",
            "Epoch 00052: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [52] Train loss : [0.015052254178694316] Val Score : [0.7103329465949443])\n",
            "Epoch : [53] Train loss : [0.014927144428449017] Val Score : [0.6839995781035756])\n",
            "Epoch : [54] Train loss : [0.015014578787876027] Val Score : [0.5906717950274928])\n",
            "Epoch : [55] Train loss : [0.014928595761635475] Val Score : [0.5320032001215638])\n",
            "Epoch : [56] Train loss : [0.01492133756567325] Val Score : [0.7379018553027905])\n",
            "Epoch : [57] Train loss : [0.015514008168663298] Val Score : [0.5320032001215638])\n",
            "Epoch : [58] Train loss : [0.015773063259465352] Val Score : [0.7379018553027905])\n",
            "Epoch : [59] Train loss : [0.014815003611147404] Val Score : [0.755629357577611])\n",
            "\n",
            "etc col : V2 / Marco F1 Score : 0.9137051774467988\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V5\n",
            "Epoch : [0] Train loss : [0.20085278472730092] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.055217753031424115] Val Score : [0.8064116050121081])\n",
            "Epoch : [2] Train loss : [0.0456593068582671] Val Score : [0.5571658045217939])\n",
            "Epoch : [3] Train loss : [0.032518992865724225] Val Score : [0.8202665410912253])\n",
            "Epoch : [4] Train loss : [0.03309245713587318] Val Score : [0.9031202878275757])\n",
            "Epoch : [5] Train loss : [0.024200046168906347] Val Score : [0.890501890608512])\n",
            "Epoch : [6] Train loss : [0.022102607946310724] Val Score : [0.9031202878275757])\n",
            "Epoch : [7] Train loss : [0.021286234658743654] Val Score : [0.9031202878275757])\n",
            "Epoch : [8] Train loss : [0.022117522012974535] Val Score : [0.8844834793761085])\n",
            "Epoch : [9] Train loss : [0.023297626791255816] Val Score : [0.890501890608512])\n",
            "Epoch : [10] Train loss : [0.018389919639698098] Val Score : [0.79380975986869])\n",
            "Epoch : [11] Train loss : [0.019431901829583303] Val Score : [0.9031202878275757])\n",
            "Epoch : [12] Train loss : [0.02103336182023798] Val Score : [0.9031202878275757])\n",
            "Epoch : [13] Train loss : [0.02185636492712157] Val Score : [0.9097393418694286])\n",
            "Epoch : [14] Train loss : [0.025236557237803936] Val Score : [0.9097393418694286])\n",
            "Epoch : [15] Train loss : [0.023858627969665185] Val Score : [0.9031202878275757])\n",
            "Epoch : [16] Train loss : [0.020732619666627476] Val Score : [0.9031202878275757])\n",
            "Epoch : [17] Train loss : [0.023707447573542595] Val Score : [0.9031202878275757])\n",
            "Epoch : [18] Train loss : [0.020313796853380545] Val Score : [0.9031202878275757])\n",
            "Epoch : [19] Train loss : [0.020229742197053775] Val Score : [0.9097393418694286])\n",
            "Epoch : [20] Train loss : [0.021601068122046336] Val Score : [0.9031202878275757])\n",
            "Epoch : [21] Train loss : [0.017042759406779493] Val Score : [0.9034120550289857])\n",
            "Epoch : [22] Train loss : [0.018791544517236098] Val Score : [0.9137051774467988])\n",
            "Epoch : [23] Train loss : [0.020646477384226664] Val Score : [0.9137051774467988])\n",
            "Epoch : [24] Train loss : [0.019117101361708983] Val Score : [0.8927516353661109])\n",
            "Epoch : [25] Train loss : [0.021955925172993114] Val Score : [0.9097393418694286])\n",
            "Epoch : [26] Train loss : [0.017566802512322153] Val Score : [0.9137051774467988])\n",
            "Epoch : [27] Train loss : [0.018317201840026037] Val Score : [0.8772441968135101])\n",
            "Epoch : [28] Train loss : [0.020019934911813055] Val Score : [0.8927516353661109])\n",
            "Epoch : [29] Train loss : [0.01631597496036972] Val Score : [0.8927516353661109])\n",
            "Epoch : [30] Train loss : [0.019169639529926435] Val Score : [0.9066829407144783])\n",
            "Epoch : [31] Train loss : [0.01648078080532806] Val Score : [0.870247282626393])\n",
            "Epoch : [32] Train loss : [0.017350157988922938] Val Score : [0.8748769079271295])\n",
            "Epoch : [33] Train loss : [0.01572298537939787] Val Score : [0.870247282626393])\n",
            "Epoch 00034: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [34] Train loss : [0.014546050823160581] Val Score : [0.8858506104888013])\n",
            "Epoch : [35] Train loss : [0.014206083424921547] Val Score : [0.846806907378336])\n",
            "Epoch : [36] Train loss : [0.013845081175012248] Val Score : [0.8331926764657618])\n",
            "Epoch : [37] Train loss : [0.016229236631521156] Val Score : [0.8652615319692264])\n",
            "Epoch : [38] Train loss : [0.013529512099921703] Val Score : [0.8331926764657618])\n",
            "Epoch : [39] Train loss : [0.012957216506557805] Val Score : [0.8331926764657618])\n",
            "Epoch : [40] Train loss : [0.013298258118863617] Val Score : [0.8331926764657618])\n",
            "Epoch : [41] Train loss : [0.015031881696943725] Val Score : [0.8331926764657618])\n",
            "Epoch : [42] Train loss : [0.013061132282018661] Val Score : [0.8189994908759815])\n",
            "Epoch : [43] Train loss : [0.015644952056131194] Val Score : [0.8858506104888013])\n",
            "Epoch : [44] Train loss : [0.01449058617332152] Val Score : [0.8652615319692264])\n",
            "Epoch 00045: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [45] Train loss : [0.013444022674645697] Val Score : [0.8331926764657618])\n",
            "Epoch : [46] Train loss : [0.01299968980518835] Val Score : [0.8041895926750926])\n",
            "Epoch : [47] Train loss : [0.014112153489674841] Val Score : [0.8189994908759815])\n",
            "Epoch : [48] Train loss : [0.012408868941877569] Val Score : [0.8041895926750926])\n",
            "Epoch : [49] Train loss : [0.014049195817538671] Val Score : [0.8041895926750926])\n",
            "Epoch : [50] Train loss : [0.013024213457746165] Val Score : [0.8331926764657618])\n",
            "Epoch : [51] Train loss : [0.01243582587423069] Val Score : [0.7887218676684034])\n",
            "Epoch : [52] Train loss : [0.012808970042637416] Val Score : [0.8331926764657618])\n",
            "Epoch : [53] Train loss : [0.011983421298542194] Val Score : [0.8041895926750926])\n",
            "Epoch : [54] Train loss : [0.013993563995297467] Val Score : [0.8189994908759815])\n",
            "Epoch : [55] Train loss : [0.01296167414901512] Val Score : [0.8331926764657618])\n",
            "Epoch 00056: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [56] Train loss : [0.012433765189988273] Val Score : [0.7725514640071602])\n",
            "Epoch : [57] Train loss : [0.011594540506069149] Val Score : [0.755629357577611])\n",
            "Epoch : [58] Train loss : [0.012300226371735334] Val Score : [0.7887218676684034])\n",
            "Epoch : [59] Train loss : [0.012291380337306432] Val Score : [0.7193100257567631])\n",
            "\n",
            "etc col : V5 / Marco F1 Score : 0.9034120550289857\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V6\n",
            "Epoch : [0] Train loss : [0.20256481426102774] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.07082763287637915] Val Score : [0.6890326111700028])\n",
            "Epoch : [2] Train loss : [0.03752454197300332] Val Score : [0.9097393418694286])\n",
            "Epoch : [3] Train loss : [0.030786453081028804] Val Score : [0.9165787375726882])\n",
            "Epoch : [4] Train loss : [0.030905221988047873] Val Score : [0.8844834793761085])\n",
            "Epoch : [5] Train loss : [0.03281501494348049] Val Score : [0.890501890608512])\n",
            "Epoch : [6] Train loss : [0.03826964007956641] Val Score : [0.9165787375726882])\n",
            "Epoch : [7] Train loss : [0.046721497417560647] Val Score : [0.007454980901555274])\n",
            "Epoch : [8] Train loss : [0.02856128423341683] Val Score : [0.45955839360529915])\n",
            "Epoch : [9] Train loss : [0.024334105529955456] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.024687568790146282] Val Score : [0.9137051774467988])\n",
            "Epoch : [11] Train loss : [0.023766931678567613] Val Score : [0.9137051774467988])\n",
            "Epoch : [12] Train loss : [0.023699962267918245] Val Score : [0.9137051774467988])\n",
            "Epoch : [13] Train loss : [0.023116322500365123] Val Score : [0.9165787375726882])\n",
            "Epoch : [14] Train loss : [0.020850255819303647] Val Score : [0.9165787375726882])\n",
            "Epoch 00015: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [15] Train loss : [0.01894918895725693] Val Score : [0.8817038840461091])\n",
            "Epoch : [16] Train loss : [0.01922999122845275] Val Score : [0.8927516353661109])\n",
            "Epoch : [17] Train loss : [0.020247826352715492] Val Score : [0.8772441968135101])\n",
            "Epoch : [18] Train loss : [0.021323154946523055] Val Score : [0.8927516353661109])\n",
            "Epoch : [19] Train loss : [0.01844240858086518] Val Score : [0.8927516353661109])\n",
            "Epoch : [20] Train loss : [0.017300737888685296] Val Score : [0.8724347298745778])\n",
            "Epoch : [21] Train loss : [0.01727577591581004] Val Score : [0.8845098845450512])\n",
            "Epoch : [22] Train loss : [0.0187781708581107] Val Score : [0.8724347298745778])\n",
            "Epoch : [23] Train loss : [0.017759601652090038] Val Score : [0.8772441968135101])\n",
            "Epoch : [24] Train loss : [0.018810136642839228] Val Score : [0.9137051774467988])\n",
            "Epoch : [25] Train loss : [0.017487370874732733] Val Score : [0.8927516353661109])\n",
            "Epoch 00026: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [26] Train loss : [0.016588217711874416] Val Score : [0.846806907378336])\n",
            "Epoch : [27] Train loss : [0.015906901098787785] Val Score : [0.8331926764657618])\n",
            "Epoch : [28] Train loss : [0.016274823075426475] Val Score : [0.8189994908759815])\n",
            "Epoch : [29] Train loss : [0.01728915922077639] Val Score : [0.8189994908759815])\n",
            "Epoch : [30] Train loss : [0.016010368508952006] Val Score : [0.8598769209128951])\n",
            "Epoch : [31] Train loss : [0.015820884811026708] Val Score : [0.8528093037014359])\n",
            "Epoch : [32] Train loss : [0.01594067125448159] Val Score : [0.8598769209128951])\n",
            "Epoch : [33] Train loss : [0.017527736257761717] Val Score : [0.8887833851083367])\n",
            "Epoch : [34] Train loss : [0.01579677313566208] Val Score : [0.8598769209128951])\n",
            "Epoch : [35] Train loss : [0.015793878119438887] Val Score : [0.846806907378336])\n",
            "Epoch : [36] Train loss : [0.015942920331976244] Val Score : [0.8331926764657618])\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [37] Train loss : [0.014709991868585348] Val Score : [0.8041895926750926])\n",
            "Epoch : [38] Train loss : [0.015684353254203285] Val Score : [0.8041895926750926])\n",
            "Epoch : [39] Train loss : [0.016132813213127] Val Score : [0.7887218676684034])\n",
            "Epoch : [40] Train loss : [0.015230796965105193] Val Score : [0.8041895926750926])\n",
            "Epoch : [41] Train loss : [0.01510374793516738] Val Score : [0.7887218676684034])\n",
            "Epoch : [42] Train loss : [0.015615037309804134] Val Score : [0.8189994908759815])\n",
            "Epoch : [43] Train loss : [0.01509507978335023] Val Score : [0.8189994908759815])\n",
            "Epoch : [44] Train loss : [0.014873348642140627] Val Score : [0.8041895926750926])\n",
            "Epoch : [45] Train loss : [0.015161568099366767] Val Score : [0.8041895926750926])\n",
            "Epoch : [46] Train loss : [0.015506192177001919] Val Score : [0.8189994908759815])\n",
            "Epoch : [47] Train loss : [0.01631876147751297] Val Score : [0.8189994908759815])\n",
            "Epoch 00048: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [48] Train loss : [0.015443691385111638] Val Score : [0.7887218676684034])\n",
            "Epoch : [49] Train loss : [0.01497989660128951] Val Score : [0.7887218676684034])\n",
            "Epoch : [50] Train loss : [0.015079742231007134] Val Score : [0.7379018553027905])\n",
            "Epoch : [51] Train loss : [0.015551706576453788] Val Score : [0.7379018553027905])\n",
            "Epoch : [52] Train loss : [0.015246552348669087] Val Score : [0.755629357577611])\n",
            "Epoch : [53] Train loss : [0.015262439780469452] Val Score : [0.755629357577611])\n",
            "Epoch : [54] Train loss : [0.014729532014046396] Val Score : [0.755629357577611])\n",
            "Epoch : [55] Train loss : [0.015084145391093833] Val Score : [0.7379018553027905])\n",
            "Epoch : [56] Train loss : [0.015016493320997273] Val Score : [0.7379018553027905])\n",
            "Epoch : [57] Train loss : [0.01454368227028421] Val Score : [0.755629357577611])\n",
            "Epoch : [58] Train loss : [0.014792423562279769] Val Score : [0.755629357577611])\n",
            "Epoch 00059: reducing learning rate of group 0 to 3.1250e-04.\n",
            "Epoch : [59] Train loss : [0.01500442357999938] Val Score : [0.6889870340395065])\n",
            "\n",
            "etc col : V6 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V7\n",
            "Epoch : [0] Train loss : [0.20153983682394028] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.05811315508825438] Val Score : [0.7217823446841288])\n",
            "Epoch : [2] Train loss : [0.04377815420074122] Val Score : [0.40176255124487953])\n",
            "Epoch : [3] Train loss : [0.03532472891466958] Val Score : [0.8045965667777433])\n",
            "Epoch : [4] Train loss : [0.026602068516824926] Val Score : [0.8470287373843977])\n",
            "Epoch : [5] Train loss : [0.03423174044915608] Val Score : [0.8376267560436427])\n",
            "Epoch : [6] Train loss : [0.036214004802916734] Val Score : [0.7713696202996474])\n",
            "Epoch : [7] Train loss : [0.028260304858641967] Val Score : [0.003966752107950074])\n",
            "Epoch : [8] Train loss : [0.02414234767534903] Val Score : [0.8592167164966584])\n",
            "Epoch : [9] Train loss : [0.02283684935952936] Val Score : [0.7998241727327075])\n",
            "Epoch : [10] Train loss : [0.02946554816194943] Val Score : [0.8844834793761085])\n",
            "Epoch : [11] Train loss : [0.025409969501197338] Val Score : [0.8967110829723166])\n",
            "Epoch : [12] Train loss : [0.025541103977177824] Val Score : [0.8786471773914175])\n",
            "Epoch : [13] Train loss : [0.02144970212663923] Val Score : [0.8580418693769312])\n",
            "Epoch : [14] Train loss : [0.02229505338306938] Val Score : [0.8832102326017632])\n",
            "Epoch : [15] Train loss : [0.024013965257576535] Val Score : [0.8635044815916644])\n",
            "Epoch : [16] Train loss : [0.03069683683237859] Val Score : [0.6777789518174134])\n",
            "Epoch : [17] Train loss : [0.024335795348244055] Val Score : [0.9097393418694286])\n",
            "Epoch : [18] Train loss : [0.02563785495502608] Val Score : [0.9031202878275757])\n",
            "Epoch : [19] Train loss : [0.024521625467709134] Val Score : [0.8938162802174903])\n",
            "Epoch : [20] Train loss : [0.02132610830345324] Val Score : [0.8817038840461091])\n",
            "Epoch : [21] Train loss : [0.021731125190854073] Val Score : [0.8583586886309732])\n",
            "Epoch : [22] Train loss : [0.02722381760499307] Val Score : [0.9137051774467988])\n",
            "Epoch : [23] Train loss : [0.025002962643546716] Val Score : [0.9236496787663914])\n",
            "Epoch : [24] Train loss : [0.019203891046345234] Val Score : [0.899903286500554])\n",
            "Epoch : [25] Train loss : [0.019595871679484844] Val Score : [0.9137051774467988])\n",
            "Epoch : [26] Train loss : [0.01839761981474502] Val Score : [0.846806907378336])\n",
            "Epoch : [27] Train loss : [0.017994215578905175] Val Score : [0.8724347298745778])\n",
            "Epoch : [28] Train loss : [0.01834484169791852] Val Score : [0.9236496787663914])\n",
            "Epoch : [29] Train loss : [0.01862535692219223] Val Score : [0.8660300854960024])\n",
            "Epoch : [30] Train loss : [0.01612534194386431] Val Score : [0.8398593381861659])\n",
            "Epoch : [31] Train loss : [0.016892098356038332] Val Score : [0.8724347298745778])\n",
            "Epoch : [32] Train loss : [0.01660830939986876] Val Score : [0.846806907378336])\n",
            "Epoch : [33] Train loss : [0.017438463933233703] Val Score : [0.8598769209128951])\n",
            "Epoch : [34] Train loss : [0.021122453468186513] Val Score : [0.9209734995691702])\n",
            "Epoch 00035: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [35] Train loss : [0.017578390426933765] Val Score : [0.8189994908759815])\n",
            "Epoch : [36] Train loss : [0.016125372544463192] Val Score : [0.8189994908759815])\n",
            "Epoch : [37] Train loss : [0.01632473730881299] Val Score : [0.846806907378336])\n",
            "Epoch : [38] Train loss : [0.016046759140278612] Val Score : [0.8652615319692264])\n",
            "Epoch : [39] Train loss : [0.01590972440317273] Val Score : [0.812341761023982])\n",
            "Epoch : [40] Train loss : [0.015465492183076484] Val Score : [0.8398593381861659])\n",
            "Epoch : [41] Train loss : [0.01508443889075092] Val Score : [0.8189994908759815])\n",
            "Epoch : [42] Train loss : [0.015400198022169726] Val Score : [0.7977053133319791])\n",
            "Epoch : [43] Train loss : [0.016209866452429975] Val Score : [0.8583586886309732])\n",
            "Epoch : [44] Train loss : [0.015503503382205963] Val Score : [0.7824328807501029])\n",
            "Epoch : [45] Train loss : [0.01800733951053449] Val Score : [0.8598769209128951])\n",
            "Epoch 00046: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [46] Train loss : [0.015419132807957274] Val Score : [0.8189994908759815])\n",
            "Epoch : [47] Train loss : [0.014713004231452942] Val Score : [0.755629357577611])\n",
            "Epoch : [48] Train loss : [0.014582562792514051] Val Score : [0.755629357577611])\n",
            "Epoch : [49] Train loss : [0.014273049775511026] Val Score : [0.7725514640071602])\n",
            "Epoch : [50] Train loss : [0.014891665961061205] Val Score : [0.8041895926750926])\n",
            "Epoch : [51] Train loss : [0.01528803412137287] Val Score : [0.8041895926750926])\n",
            "Epoch : [52] Train loss : [0.014491720923355647] Val Score : [0.7725514640071602])\n",
            "Epoch : [53] Train loss : [0.013937862723001413] Val Score : [0.8041895926750926])\n",
            "Epoch : [54] Train loss : [0.014971872525555747] Val Score : [0.8041895926750926])\n",
            "Epoch : [55] Train loss : [0.014682379750800984] Val Score : [0.8041895926750926])\n",
            "Epoch : [56] Train loss : [0.014102870598435402] Val Score : [0.8041895926750926])\n",
            "Epoch 00057: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [57] Train loss : [0.013526784854808025] Val Score : [0.6664557258707168])\n",
            "Epoch : [58] Train loss : [0.01365581780139889] Val Score : [0.6174185476616381])\n",
            "Epoch : [59] Train loss : [0.013460760270910603] Val Score : [0.7437178496040009])\n",
            "\n",
            "etc col : V7 / Marco F1 Score : 0.9236496787663914\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V8\n",
            "Epoch : [0] Train loss : [0.20525724281157767] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.0592872000166348] Val Score : [0.8580418693769312])\n",
            "Epoch : [2] Train loss : [0.03503427840769291] Val Score : [0.9165787375726882])\n",
            "Epoch : [3] Train loss : [0.037066365991319926] Val Score : [0.7655703273293624])\n",
            "Epoch : [4] Train loss : [0.02942928538790771] Val Score : [0.890501890608512])\n",
            "Epoch : [5] Train loss : [0.027012215262012824] Val Score : [0.8376267560436427])\n",
            "Epoch : [6] Train loss : [0.023015650920569897] Val Score : [0.872984830495149])\n",
            "Epoch : [7] Train loss : [0.028506711391466006] Val Score : [0.8376267560436427])\n",
            "Epoch : [8] Train loss : [0.027505905234387944] Val Score : [0.8844834793761085])\n",
            "Epoch : [9] Train loss : [0.03352562165153878] Val Score : [0.9097393418694286])\n",
            "Epoch : [10] Train loss : [0.026368684401469573] Val Score : [0.9097393418694286])\n",
            "Epoch : [11] Train loss : [0.02318544313311577] Val Score : [0.890501890608512])\n",
            "Epoch : [12] Train loss : [0.022729463210063323] Val Score : [0.890501890608512])\n",
            "Epoch : [13] Train loss : [0.021795468804027354] Val Score : [0.0748993539502772])\n",
            "Epoch 00014: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [14] Train loss : [0.019579889585397074] Val Score : [0.9066829407144783])\n",
            "Epoch : [15] Train loss : [0.01999206481767552] Val Score : [0.8772441968135101])\n",
            "Epoch : [16] Train loss : [0.018251074012368917] Val Score : [0.8927516353661109])\n",
            "Epoch : [17] Train loss : [0.01604133564978838] Val Score : [0.899903286500554])\n",
            "Epoch : [18] Train loss : [0.015537413435855083] Val Score : [0.8927516353661109])\n",
            "Epoch : [19] Train loss : [0.014912608212658338] Val Score : [0.8724347298745778])\n",
            "Epoch : [20] Train loss : [0.015922829375735352] Val Score : [0.8927516353661109])\n",
            "Epoch : [21] Train loss : [0.016014733418290104] Val Score : [0.9137051774467988])\n",
            "Epoch : [22] Train loss : [0.017661941503839835] Val Score : [0.8927516353661109])\n",
            "Epoch : [23] Train loss : [0.01769062870049051] Val Score : [0.9137051774467988])\n",
            "Epoch : [24] Train loss : [0.018169858226818696] Val Score : [0.9165787375726882])\n",
            "Epoch 00025: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [25] Train loss : [0.0166605583924268] Val Score : [0.9034120550289857])\n",
            "Epoch : [26] Train loss : [0.015614362566598825] Val Score : [0.8927516353661109])\n",
            "Epoch : [27] Train loss : [0.015576243201004607] Val Score : [0.8598769209128951])\n",
            "Epoch : [28] Train loss : [0.016647817566990852] Val Score : [0.8331926764657618])\n",
            "Epoch : [29] Train loss : [0.015716924598174437] Val Score : [0.8189994908759815])\n",
            "Epoch : [30] Train loss : [0.01698112048740898] Val Score : [0.8598769209128951])\n",
            "Epoch : [31] Train loss : [0.015469295837517296] Val Score : [0.8598769209128951])\n",
            "Epoch : [32] Train loss : [0.01594753044524363] Val Score : [0.8331926764657618])\n",
            "Epoch : [33] Train loss : [0.01809986461220043] Val Score : [0.8927516353661109])\n",
            "Epoch : [34] Train loss : [0.015227503209773983] Val Score : [0.8189994908759815])\n",
            "Epoch : [35] Train loss : [0.014573552579219853] Val Score : [0.8724347298745778])\n",
            "Epoch 00036: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [36] Train loss : [0.01423419193763818] Val Score : [0.8189994908759815])\n",
            "Epoch : [37] Train loss : [0.013648799620568752] Val Score : [0.8041895926750926])\n",
            "Epoch : [38] Train loss : [0.013781517877110414] Val Score : [0.8041895926750926])\n",
            "Epoch : [39] Train loss : [0.013210476176547152] Val Score : [0.7725514640071602])\n",
            "Epoch : [40] Train loss : [0.013436393346637487] Val Score : [0.8041895926750926])\n",
            "Epoch : [41] Train loss : [0.012825067953339644] Val Score : [0.7725514640071602])\n",
            "Epoch : [42] Train loss : [0.014455848706087895] Val Score : [0.8189994908759815])\n",
            "Epoch : [43] Train loss : [0.013536530214228801] Val Score : [0.8041895926750926])\n",
            "Epoch : [44] Train loss : [0.013734686587538038] Val Score : [0.7887218676684034])\n",
            "Epoch : [45] Train loss : [0.013774430711886712] Val Score : [0.755629357577611])\n",
            "Epoch : [46] Train loss : [0.014229443855583668] Val Score : [0.8724347298745778])\n",
            "Epoch 00047: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [47] Train loss : [0.012368258022304093] Val Score : [0.8041895926750926])\n",
            "Epoch : [48] Train loss : [0.012213190884462424] Val Score : [0.755629357577611])\n",
            "Epoch : [49] Train loss : [0.012466361347053732] Val Score : [0.7379018553027905])\n",
            "Epoch : [50] Train loss : [0.012954914875860726] Val Score : [0.5906717950274928])\n",
            "Epoch : [51] Train loss : [0.013430766694779907] Val Score : [0.7437178496040009])\n",
            "Epoch : [52] Train loss : [0.013058143734399761] Val Score : [0.7617289593661732])\n",
            "Epoch : [53] Train loss : [0.012550669589212962] Val Score : [0.7379018553027905])\n",
            "Epoch : [54] Train loss : [0.013249903385128294] Val Score : [0.8041895926750926])\n",
            "Epoch : [55] Train loss : [0.01343875052407384] Val Score : [0.8041895926750926])\n",
            "Epoch : [56] Train loss : [0.012839981953480415] Val Score : [0.7725514640071602])\n",
            "Epoch : [57] Train loss : [0.01349514676257968] Val Score : [0.755629357577611])\n",
            "Epoch 00058: reducing learning rate of group 0 to 3.1250e-04.\n",
            "Epoch : [58] Train loss : [0.012680553232452698] Val Score : [0.5906717950274928])\n",
            "Epoch : [59] Train loss : [0.01294479173208986] Val Score : [0.7103329465949443])\n",
            "\n",
            "etc col : V8 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V13\n",
            "Epoch : [0] Train loss : [0.18758107721805573] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.05965750079069819] Val Score : [0.9066829407144783])\n",
            "Epoch : [2] Train loss : [0.03705379420093128] Val Score : [0.9165787375726882])\n",
            "Epoch : [3] Train loss : [0.03666791386370148] Val Score : [0.9165787375726882])\n",
            "Epoch : [4] Train loss : [0.028630567315433706] Val Score : [0.8786471773914175])\n",
            "Epoch : [5] Train loss : [0.023979852109083107] Val Score : [0.9165787375726882])\n",
            "Epoch : [6] Train loss : [0.033942219002970626] Val Score : [0.9165787375726882])\n",
            "Epoch : [7] Train loss : [0.032305722923151085] Val Score : [0.6582932198317876])\n",
            "Epoch : [8] Train loss : [0.029961754035736834] Val Score : [0.5053725410586651])\n",
            "Epoch : [9] Train loss : [0.02679567158754383] Val Score : [0.8927516353661109])\n",
            "Epoch : [10] Train loss : [0.024095987102815082] Val Score : [0.8528093037014359])\n",
            "Epoch : [11] Train loss : [0.021924218562032496] Val Score : [0.8598769209128951])\n",
            "Epoch : [12] Train loss : [0.021993720770946572] Val Score : [0.8858506104888013])\n",
            "Epoch : [13] Train loss : [0.023947839359087602] Val Score : [0.8927516353661109])\n",
            "Epoch 00014: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [14] Train loss : [0.021398644761315415] Val Score : [0.8583586886309732])\n",
            "Epoch : [15] Train loss : [0.02023906260728836] Val Score : [0.8528093037014359])\n",
            "Epoch : [16] Train loss : [0.019860168253736838] Val Score : [0.846806907378336])\n",
            "Epoch : [17] Train loss : [0.019301674461790493] Val Score : [0.8331926764657618])\n",
            "Epoch : [18] Train loss : [0.01882351655513048] Val Score : [0.8331926764657618])\n",
            "Epoch : [19] Train loss : [0.018376809943999563] Val Score : [0.8528093037014359])\n",
            "Epoch : [20] Train loss : [0.017866838058190688] Val Score : [0.8598769209128951])\n",
            "Epoch : [21] Train loss : [0.01768210836287056] Val Score : [0.8598769209128951])\n",
            "Epoch : [22] Train loss : [0.01930217444896698] Val Score : [0.8331926764657618])\n",
            "Epoch : [23] Train loss : [0.016915375433330024] Val Score : [0.8528093037014359])\n",
            "Epoch : [24] Train loss : [0.018849797546863556] Val Score : [0.8528093037014359])\n",
            "Epoch 00025: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [25] Train loss : [0.016401933240039007] Val Score : [0.8263811616954475])\n",
            "Epoch : [26] Train loss : [0.01597478101029992] Val Score : [0.8331926764657618])\n",
            "Epoch : [27] Train loss : [0.015829910258097307] Val Score : [0.8198417554594366])\n",
            "Epoch : [28] Train loss : [0.016378290685159818] Val Score : [0.8528093037014359])\n",
            "Epoch : [29] Train loss : [0.01616280372919781] Val Score : [0.8041895926750926])\n",
            "Epoch : [30] Train loss : [0.016748603899031878] Val Score : [0.8189994908759815])\n",
            "Epoch : [31] Train loss : [0.01621546476547207] Val Score : [0.8528093037014359])\n",
            "Epoch : [32] Train loss : [0.01668642195207732] Val Score : [0.8528093037014359])\n",
            "Epoch : [33] Train loss : [0.015462913284344333] Val Score : [0.8528093037014359])\n",
            "Epoch : [34] Train loss : [0.015155046579561062] Val Score : [0.8041895926750926])\n",
            "Epoch : [35] Train loss : [0.014811379302825247] Val Score : [0.8331926764657618])\n",
            "Epoch 00036: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [36] Train loss : [0.015938590413757732] Val Score : [0.8189994908759815])\n",
            "Epoch : [37] Train loss : [0.015314851488385881] Val Score : [0.8041895926750926])\n",
            "Epoch : [38] Train loss : [0.015212648747754949] Val Score : [0.8041895926750926])\n",
            "Epoch : [39] Train loss : [0.014698454444961888] Val Score : [0.8041895926750926])\n",
            "Epoch : [40] Train loss : [0.015444637342755283] Val Score : [0.8041895926750926])\n",
            "Epoch : [41] Train loss : [0.01510816260374018] Val Score : [0.8041895926750926])\n",
            "Epoch : [42] Train loss : [0.014957088910575424] Val Score : [0.8041895926750926])\n",
            "Epoch : [43] Train loss : [0.015260784620685237] Val Score : [0.8041895926750926])\n",
            "Epoch : [44] Train loss : [0.015258492303213902] Val Score : [0.8041895926750926])\n",
            "Epoch : [45] Train loss : [0.015605160434331213] Val Score : [0.8041895926750926])\n",
            "Epoch : [46] Train loss : [0.014398766348936729] Val Score : [0.8189994908759815])\n",
            "Epoch 00047: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [47] Train loss : [0.014332579315773078] Val Score : [0.7887218676684034])\n",
            "Epoch : [48] Train loss : [0.014982645998575858] Val Score : [0.7887218676684034])\n",
            "Epoch : [49] Train loss : [0.014966904717896665] Val Score : [0.8041895926750926])\n",
            "Epoch : [50] Train loss : [0.014469797789518322] Val Score : [0.8041895926750926])\n",
            "Epoch : [51] Train loss : [0.01442862328674112] Val Score : [0.7887218676684034])\n",
            "Epoch : [52] Train loss : [0.014755454513111286] Val Score : [0.6386603696932764])\n",
            "Epoch : [53] Train loss : [0.014696900067584855] Val Score : [0.6174185476616381])\n",
            "Epoch : [54] Train loss : [0.014818452764302492] Val Score : [0.7498242036425005])\n",
            "Epoch : [55] Train loss : [0.014752680768391915] Val Score : [0.7887218676684034])\n",
            "Epoch : [56] Train loss : [0.015794480751667703] Val Score : [0.8041895926750926])\n",
            "Epoch : [57] Train loss : [0.014668032992631197] Val Score : [0.8041895926750926])\n",
            "Epoch 00058: reducing learning rate of group 0 to 3.1250e-04.\n",
            "Epoch : [58] Train loss : [0.014289821830711194] Val Score : [0.6839995781035756])\n",
            "Epoch : [59] Train loss : [0.014023451932838984] Val Score : [0.7498242036425005])\n",
            "\n",
            "etc col : V13 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V15\n",
            "Epoch : [0] Train loss : [0.20142179621117456] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.06176498745168958] Val Score : [0.7997185279009218])\n",
            "Epoch : [2] Train loss : [0.03766748069652489] Val Score : [0.604291644541397])\n",
            "Epoch : [3] Train loss : [0.029862979826118265] Val Score : [0.74464046996434])\n",
            "Epoch : [4] Train loss : [0.029262313220117773] Val Score : [0.9165787375726882])\n",
            "Epoch : [5] Train loss : [0.025739445351064205] Val Score : [0.9097393418694286])\n",
            "Epoch : [6] Train loss : [0.023935762367078235] Val Score : [0.9097393418694286])\n",
            "Epoch : [7] Train loss : [0.022998477598386153] Val Score : [0.9137051774467988])\n",
            "Epoch : [8] Train loss : [0.02716912834772042] Val Score : [0.9236496787663914])\n",
            "Epoch : [9] Train loss : [0.026522010697850158] Val Score : [0.9097393418694286])\n",
            "Epoch : [10] Train loss : [0.02323909809014627] Val Score : [0.9097393418694286])\n",
            "Epoch : [11] Train loss : [0.023603292049041817] Val Score : [0.8938162802174903])\n",
            "Epoch : [12] Train loss : [0.021599833720496724] Val Score : [0.9031202878275757])\n",
            "Epoch : [13] Train loss : [0.023237727848546847] Val Score : [0.9097393418694286])\n",
            "Epoch : [14] Train loss : [0.020368003951651708] Val Score : [0.9031202878275757])\n",
            "Epoch : [15] Train loss : [0.0200370904058218] Val Score : [0.906144477664439])\n",
            "Epoch : [16] Train loss : [0.0212956199954663] Val Score : [0.8938162802174903])\n",
            "Epoch : [17] Train loss : [0.020504196573581015] Val Score : [0.9236496787663914])\n",
            "Epoch : [18] Train loss : [0.021454078810555593] Val Score : [0.9097393418694286])\n",
            "Epoch : [19] Train loss : [0.022291049095136777] Val Score : [0.9165787375726882])\n",
            "Epoch 00020: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [20] Train loss : [0.01765045350683587] Val Score : [0.9236496787663914])\n",
            "Epoch : [21] Train loss : [0.01645990807030882] Val Score : [0.9034120550289857])\n",
            "Epoch : [22] Train loss : [0.01795935590884515] Val Score : [0.9236496787663914])\n",
            "Epoch : [23] Train loss : [0.017580709819282805] Val Score : [0.9034120550289857])\n",
            "Epoch : [24] Train loss : [0.016418511713189737] Val Score : [0.8964462129361583])\n",
            "Epoch : [25] Train loss : [0.016671654036534683] Val Score : [0.8845098845450512])\n",
            "Epoch : [26] Train loss : [0.016422641796192954] Val Score : [0.9034120550289857])\n",
            "Epoch : [27] Train loss : [0.015817226908568825] Val Score : [0.9106263628050926])\n",
            "Epoch : [28] Train loss : [0.01572866817670209] Val Score : [0.899903286500554])\n",
            "Epoch : [29] Train loss : [0.015533026640436478] Val Score : [0.8845098845450512])\n",
            "Epoch : [30] Train loss : [0.016635315625795295] Val Score : [0.9034120550289857])\n",
            "Epoch 00031: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [31] Train loss : [0.015851831529289484] Val Score : [0.8598769209128951])\n",
            "Epoch : [32] Train loss : [0.015388914650040013] Val Score : [0.8598769209128951])\n",
            "Epoch : [33] Train loss : [0.01512467215902039] Val Score : [0.8598769209128951])\n",
            "Epoch : [34] Train loss : [0.01678322714620403] Val Score : [0.8724347298745778])\n",
            "Epoch : [35] Train loss : [0.01648713435445513] Val Score : [0.9073194875902806])\n",
            "Epoch : [36] Train loss : [0.01610329674024667] Val Score : [0.8598769209128951])\n",
            "Epoch : [37] Train loss : [0.01506207776921136] Val Score : [0.8331926764657618])\n",
            "Epoch : [38] Train loss : [0.014770715697003263] Val Score : [0.8598769209128951])\n",
            "Epoch : [39] Train loss : [0.014634876578514065] Val Score : [0.8598769209128951])\n",
            "Epoch : [40] Train loss : [0.015094810631126165] Val Score : [0.8189994908759815])\n",
            "Epoch : [41] Train loss : [0.014829028663890702] Val Score : [0.8598769209128951])\n",
            "Epoch 00042: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [42] Train loss : [0.014204887872827905] Val Score : [0.8331926764657618])\n",
            "Epoch : [43] Train loss : [0.01419526245445013] Val Score : [0.8189994908759815])\n",
            "Epoch : [44] Train loss : [0.014150143334908145] Val Score : [0.7887218676684034])\n",
            "Epoch : [45] Train loss : [0.014441565543945347] Val Score : [0.8041895926750926])\n",
            "Epoch : [46] Train loss : [0.014047407478626286] Val Score : [0.8041895926750926])\n",
            "Epoch : [47] Train loss : [0.0139551943034998] Val Score : [0.7887218676684034])\n",
            "Epoch : [48] Train loss : [0.014423922768660955] Val Score : [0.7887218676684034])\n",
            "Epoch : [49] Train loss : [0.014208300970494747] Val Score : [0.8189994908759815])\n",
            "Epoch : [50] Train loss : [0.015270650719425507] Val Score : [0.8598769209128951])\n",
            "Epoch : [51] Train loss : [0.014073437412402459] Val Score : [0.8041895926750926])\n",
            "Epoch : [52] Train loss : [0.014191449885921819] Val Score : [0.8041895926750926])\n",
            "Epoch 00053: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [53] Train loss : [0.014559948218188115] Val Score : [0.8041895926750926])\n",
            "Epoch : [54] Train loss : [0.01421362188245569] Val Score : [0.7887218676684034])\n",
            "Epoch : [55] Train loss : [0.014270568333034004] Val Score : [0.755629357577611])\n",
            "Epoch : [56] Train loss : [0.013719374513519662] Val Score : [0.755629357577611])\n",
            "Epoch : [57] Train loss : [0.01401436754635402] Val Score : [0.755629357577611])\n",
            "Epoch : [58] Train loss : [0.013542861078998871] Val Score : [0.755629357577611])\n",
            "Epoch : [59] Train loss : [0.01395066109086786] Val Score : [0.7887218676684034])\n",
            "\n",
            "etc col : V15 / Marco F1 Score : 0.9236496787663914\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V19\n",
            "Epoch : [0] Train loss : [0.19066265118973597] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.05869474448263645] Val Score : [0.9137051774467988])\n",
            "Epoch : [2] Train loss : [0.044299490483743806] Val Score : [0.8786471773914175])\n",
            "Epoch : [3] Train loss : [0.03433975311262267] Val Score : [0.8967110829723166])\n",
            "Epoch : [4] Train loss : [0.028076745702752044] Val Score : [0.9165787375726882])\n",
            "Epoch : [5] Train loss : [0.029709873721003532] Val Score : [0.9165787375726882])\n",
            "Epoch : [6] Train loss : [0.030842540519578115] Val Score : [0.9165787375726882])\n",
            "Epoch : [7] Train loss : [0.027174186626715318] Val Score : [0.8376267560436427])\n",
            "Epoch : [8] Train loss : [0.024737046100199223] Val Score : [0.8786471773914175])\n",
            "Epoch : [9] Train loss : [0.02101489874933447] Val Score : [0.8772441968135101])\n",
            "Epoch : [10] Train loss : [0.025163612461515834] Val Score : [0.9034120550289857])\n",
            "Epoch : [11] Train loss : [0.024221323829676424] Val Score : [0.8927516353661109])\n",
            "Epoch : [12] Train loss : [0.023250155416982516] Val Score : [0.8817038840461091])\n",
            "Epoch : [13] Train loss : [0.02603218105754682] Val Score : [0.8927516353661109])\n",
            "Epoch : [14] Train loss : [0.022533197488103594] Val Score : [0.870247282626393])\n",
            "Epoch : [15] Train loss : [0.021920029340045794] Val Score : [0.8817038840461091])\n",
            "Epoch 00016: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [16] Train loss : [0.02090686559677124] Val Score : [0.8331926764657618])\n",
            "Epoch : [17] Train loss : [0.0180640041029879] Val Score : [0.8189994908759815])\n",
            "Epoch : [18] Train loss : [0.01860753766127995] Val Score : [0.8041895926750926])\n",
            "Epoch : [19] Train loss : [0.01758779093090977] Val Score : [0.7887218676684034])\n",
            "Epoch : [20] Train loss : [0.0172585022768804] Val Score : [0.7887218676684034])\n",
            "Epoch : [21] Train loss : [0.020075392244117602] Val Score : [0.8528093037014359])\n",
            "Epoch : [22] Train loss : [0.018821238673159053] Val Score : [0.8460131793934016])\n",
            "Epoch : [23] Train loss : [0.019669693229453906] Val Score : [0.8331926764657618])\n",
            "Epoch : [24] Train loss : [0.02337297983467579] Val Score : [0.8583586886309732])\n",
            "Epoch : [25] Train loss : [0.019076635129749775] Val Score : [0.8189994908759815])\n",
            "Epoch : [26] Train loss : [0.021138344226138934] Val Score : [0.846806907378336])\n",
            "Epoch 00027: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [27] Train loss : [0.017455968207546642] Val Score : [0.8041895926750926])\n",
            "Epoch : [28] Train loss : [0.017183090427092144] Val Score : [0.8041895926750926])\n",
            "Epoch : [29] Train loss : [0.018153997537280833] Val Score : [0.8041895926750926])\n",
            "Epoch : [30] Train loss : [0.016616207281393663] Val Score : [0.8041895926750926])\n",
            "Epoch : [31] Train loss : [0.016631814052483866] Val Score : [0.7887218676684034])\n",
            "Epoch : [32] Train loss : [0.016707578341343572] Val Score : [0.7887218676684034])\n",
            "Epoch : [33] Train loss : [0.018689406237431934] Val Score : [0.8041895926750926])\n",
            "Epoch : [34] Train loss : [0.01763706354956542] Val Score : [0.8041895926750926])\n",
            "Epoch : [35] Train loss : [0.016427702802632536] Val Score : [0.8041895926750926])\n",
            "Epoch : [36] Train loss : [0.016676869575998614] Val Score : [0.7887218676684034])\n",
            "Epoch : [37] Train loss : [0.017216306179761887] Val Score : [0.755629357577611])\n",
            "Epoch 00038: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [38] Train loss : [0.01654403350715126] Val Score : [0.7887218676684034])\n",
            "Epoch : [39] Train loss : [0.016570232675543854] Val Score : [0.755629357577611])\n",
            "Epoch : [40] Train loss : [0.01611456667472209] Val Score : [0.7725514640071602])\n",
            "Epoch : [41] Train loss : [0.016613991864557778] Val Score : [0.755629357577611])\n",
            "Epoch : [42] Train loss : [0.015743984508195093] Val Score : [0.755629357577611])\n",
            "Epoch : [43] Train loss : [0.015304545073636941] Val Score : [0.7049260428710196])\n",
            "Epoch : [44] Train loss : [0.01565086961324726] Val Score : [0.8041895926750926])\n",
            "Epoch : [45] Train loss : [0.01537328546068498] Val Score : [0.755629357577611])\n",
            "Epoch : [46] Train loss : [0.015266824580196823] Val Score : [0.755629357577611])\n",
            "Epoch : [47] Train loss : [0.014946571684309415] Val Score : [0.755629357577611])\n",
            "Epoch : [48] Train loss : [0.015265981866312879] Val Score : [0.755629357577611])\n",
            "Epoch 00049: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [49] Train loss : [0.015568496992013283] Val Score : [0.7379018553027905])\n",
            "Epoch : [50] Train loss : [0.014552837304238762] Val Score : [0.7103329465949443])\n",
            "Epoch : [51] Train loss : [0.015226588118821383] Val Score : [0.7379018553027905])\n",
            "Epoch : [52] Train loss : [0.015292386590902294] Val Score : [0.7887218676684034])\n",
            "Epoch : [53] Train loss : [0.014998708984681539] Val Score : [0.755629357577611])\n",
            "Epoch : [54] Train loss : [0.014581423651959215] Val Score : [0.7379018553027905])\n",
            "Epoch : [55] Train loss : [0.014791419596544333] Val Score : [0.7498242036425005])\n",
            "Epoch : [56] Train loss : [0.014813169238290616] Val Score : [0.7437178496040009])\n",
            "Epoch : [57] Train loss : [0.014737024770251341] Val Score : [0.6889870340395065])\n",
            "Epoch : [58] Train loss : [0.014384271843092782] Val Score : [0.7379018553027905])\n",
            "Epoch : [59] Train loss : [0.01441577130130359] Val Score : [0.755629357577611])\n",
            "Epoch 00060: reducing learning rate of group 0 to 3.1250e-04.\n",
            "\n",
            "etc col : V19 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V20\n",
            "Epoch : [0] Train loss : [0.19308256624000414] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.05994453760130065] Val Score : [0.17900976044594696])\n",
            "Epoch : [2] Train loss : [0.03435086791536638] Val Score : [0.5190082957218438])\n",
            "Epoch : [3] Train loss : [0.03692695551684925] Val Score : [0.872984830495149])\n",
            "Epoch : [4] Train loss : [0.022644181602767537] Val Score : [0.8244378451249526])\n",
            "Epoch : [5] Train loss : [0.025507211286042417] Val Score : [0.9165787375726882])\n",
            "Epoch : [6] Train loss : [0.030819771944412162] Val Score : [0.9097393418694286])\n",
            "Epoch : [7] Train loss : [0.02869484307510512] Val Score : [0.5547763458724986])\n",
            "Epoch : [8] Train loss : [0.02938005913581167] Val Score : [0.8635044815916644])\n",
            "Epoch : [9] Train loss : [0.02548803242721728] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.01906821916678122] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.026094813298966204] Val Score : [0.9165787375726882])\n",
            "Epoch : [12] Train loss : [0.024264338692384108] Val Score : [0.9066829407144783])\n",
            "Epoch : [13] Train loss : [0.021714044069605216] Val Score : [0.8927516353661109])\n",
            "Epoch : [14] Train loss : [0.02249075352613415] Val Score : [0.9034120550289857])\n",
            "Epoch : [15] Train loss : [0.01719400127019201] Val Score : [0.8528093037014359])\n",
            "Epoch : [16] Train loss : [0.017898842559329102] Val Score : [0.9066829407144783])\n",
            "Epoch 00017: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [17] Train loss : [0.018133076639579877] Val Score : [0.8460131793934016])\n",
            "Epoch : [18] Train loss : [0.01675724264766489] Val Score : [0.8598769209128951])\n",
            "Epoch : [19] Train loss : [0.01595016209674733] Val Score : [0.8772441968135101])\n",
            "Epoch : [20] Train loss : [0.015432186956916536] Val Score : [0.8263811616954475])\n",
            "Epoch : [21] Train loss : [0.014984154608100653] Val Score : [0.8189994908759815])\n",
            "Epoch : [22] Train loss : [0.016975008949105228] Val Score : [0.8331926764657618])\n",
            "Epoch : [23] Train loss : [0.015784595028630326] Val Score : [0.8772441968135101])\n",
            "Epoch : [24] Train loss : [0.014946856602494205] Val Score : [0.8331926764657618])\n",
            "Epoch : [25] Train loss : [0.015355613747877734] Val Score : [0.8189994908759815])\n",
            "Epoch : [26] Train loss : [0.015815674593406066] Val Score : [0.8331926764657618])\n",
            "Epoch : [27] Train loss : [0.015542274074895042] Val Score : [0.8331926764657618])\n",
            "Epoch 00028: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [28] Train loss : [0.014418002949761493] Val Score : [0.7887218676684034])\n",
            "Epoch : [29] Train loss : [0.01490662113896438] Val Score : [0.846806907378336])\n",
            "Epoch : [30] Train loss : [0.015125906494046961] Val Score : [0.8041895926750926])\n",
            "Epoch : [31] Train loss : [0.013860065157392196] Val Score : [0.755629357577611])\n",
            "Epoch : [32] Train loss : [0.016278654403452362] Val Score : [0.8041895926750926])\n",
            "Epoch : [33] Train loss : [0.014290899437453066] Val Score : [0.8198417554594366])\n",
            "Epoch : [34] Train loss : [0.014693485972072397] Val Score : [0.8263811616954475])\n",
            "Epoch : [35] Train loss : [0.014556713468794311] Val Score : [0.8041895926750926])\n",
            "Epoch : [36] Train loss : [0.013674718993050712] Val Score : [0.8331926764657618])\n",
            "Epoch : [37] Train loss : [0.013942378839211804] Val Score : [0.8845098845450512])\n",
            "Epoch : [38] Train loss : [0.01311441118429814] Val Score : [0.8598769209128951])\n",
            "Epoch 00039: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [39] Train loss : [0.015173180827072688] Val Score : [0.8598769209128951])\n",
            "Epoch : [40] Train loss : [0.013439888068075691] Val Score : [0.8041895926750926])\n",
            "Epoch : [41] Train loss : [0.013093972578644753] Val Score : [0.7725514640071602])\n",
            "Epoch : [42] Train loss : [0.013241967319377832] Val Score : [0.8331926764657618])\n",
            "Epoch : [43] Train loss : [0.01295146213046142] Val Score : [0.8041895926750926])\n",
            "Epoch : [44] Train loss : [0.014450331684201956] Val Score : [0.8331926764657618])\n",
            "Epoch : [45] Train loss : [0.015216478944889136] Val Score : [0.8598769209128951])\n",
            "Epoch : [46] Train loss : [0.013720892702362366] Val Score : [0.7887218676684034])\n",
            "Epoch : [47] Train loss : [0.013478888930486781] Val Score : [0.8331926764657618])\n",
            "Epoch : [48] Train loss : [0.012933125852474145] Val Score : [0.7887218676684034])\n",
            "Epoch : [49] Train loss : [0.012800324774746383] Val Score : [0.8331926764657618])\n",
            "Epoch 00050: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [50] Train loss : [0.013220889560346092] Val Score : [0.8189994908759815])\n",
            "Epoch : [51] Train loss : [0.012613692453929357] Val Score : [0.730584647838757])\n",
            "Epoch : [52] Train loss : [0.012945224664040975] Val Score : [0.7725514640071602])\n",
            "Epoch : [53] Train loss : [0.013681218959391117] Val Score : [0.8189994908759815])\n",
            "Epoch : [54] Train loss : [0.013408033842486995] Val Score : [0.8189994908759815])\n",
            "Epoch : [55] Train loss : [0.013339355255344085] Val Score : [0.8331926764657618])\n",
            "Epoch : [56] Train loss : [0.013298497535288334] Val Score : [0.846806907378336])\n",
            "Epoch : [57] Train loss : [0.012815713682877166] Val Score : [0.778902752094029])\n",
            "Epoch : [58] Train loss : [0.013128513204199927] Val Score : [0.6889870340395065])\n",
            "Epoch : [59] Train loss : [0.012752706384552377] Val Score : [0.7725514640071602])\n",
            "\n",
            "etc col : V20 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V21\n",
            "Epoch : [0] Train loss : [0.19485179547752654] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.05781470744737557] Val Score : [0.794590332675686])\n",
            "Epoch : [2] Train loss : [0.042359624590192525] Val Score : [0.4973758681967058])\n",
            "Epoch : [3] Train loss : [0.03604743842567716] Val Score : [0.0010881344945152598])\n",
            "Epoch : [4] Train loss : [0.0313992298075131] Val Score : [0.9097393418694286])\n",
            "Epoch : [5] Train loss : [0.027598537371626923] Val Score : [0.9097393418694286])\n",
            "Epoch : [6] Train loss : [0.024762800628585473] Val Score : [0.9031202878275757])\n",
            "Epoch : [7] Train loss : [0.0284317299457533] Val Score : [0.5338212236159476])\n",
            "Epoch : [8] Train loss : [0.02280813947852169] Val Score : [0.9165787375726882])\n",
            "Epoch : [9] Train loss : [0.02065878880343267] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.019448289115514075] Val Score : [0.890501890608512])\n",
            "Epoch : [11] Train loss : [0.02623194589146546] Val Score : [0.7353562550268086])\n",
            "Epoch : [12] Train loss : [0.026474099340183393] Val Score : [0.8844834793761085])\n",
            "Epoch : [13] Train loss : [0.026357878664774553] Val Score : [0.8674887641844412])\n",
            "Epoch : [14] Train loss : [0.019135185716939822] Val Score : [0.8621517488551477])\n",
            "Epoch : [15] Train loss : [0.019172162482781068] Val Score : [0.8674887641844412])\n",
            "Epoch : [16] Train loss : [0.021245461888611317] Val Score : [0.8244378451249526])\n",
            "Epoch : [17] Train loss : [0.01849407237023115] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.018425439750509604] Val Score : [0.9031202878275757])\n",
            "Epoch : [19] Train loss : [0.018858219363859723] Val Score : [0.9165787375726882])\n",
            "Epoch 00020: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [20] Train loss : [0.01959465823269316] Val Score : [0.8927516353661109])\n",
            "Epoch : [21] Train loss : [0.017241329686450108] Val Score : [0.8998944850872257])\n",
            "Epoch : [22] Train loss : [0.018160029846642698] Val Score : [0.8927516353661109])\n",
            "Epoch : [23] Train loss : [0.017123991357428685] Val Score : [0.9137051774467988])\n",
            "Epoch : [24] Train loss : [0.016296012127505883] Val Score : [0.9097393418694286])\n",
            "Epoch : [25] Train loss : [0.016171345420713936] Val Score : [0.9165787375726882])\n",
            "Epoch : [26] Train loss : [0.016098374567393745] Val Score : [0.9034120550289857])\n",
            "Epoch : [27] Train loss : [0.016031403028007065] Val Score : [0.8772441968135101])\n",
            "Epoch : [28] Train loss : [0.017377073743513653] Val Score : [0.8772441968135101])\n",
            "Epoch : [29] Train loss : [0.01637729556698884] Val Score : [0.8887833851083367])\n",
            "Epoch : [30] Train loss : [0.017401795302118574] Val Score : [0.8887833851083367])\n",
            "Epoch 00031: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [31] Train loss : [0.016374894617391483] Val Score : [0.8724347298745778])\n",
            "Epoch : [32] Train loss : [0.01539313340825694] Val Score : [0.8331926764657618])\n",
            "Epoch : [33] Train loss : [0.015434566353048598] Val Score : [0.8331926764657618])\n",
            "Epoch : [34] Train loss : [0.014873384697628873] Val Score : [0.8041895926750926])\n",
            "Epoch : [35] Train loss : [0.015027903020381927] Val Score : [0.8189994908759815])\n",
            "Epoch : [36] Train loss : [0.01494599606043526] Val Score : [0.8189994908759815])\n",
            "Epoch : [37] Train loss : [0.015384264822517122] Val Score : [0.8189994908759815])\n",
            "Epoch : [38] Train loss : [0.01754086438034262] Val Score : [0.8331926764657618])\n",
            "Epoch : [39] Train loss : [0.015905862474547967] Val Score : [0.8331926764657618])\n",
            "Epoch : [40] Train loss : [0.01525492946218167] Val Score : [0.8331926764657618])\n",
            "Epoch : [41] Train loss : [0.016898918165160075] Val Score : [0.8772441968135101])\n",
            "Epoch 00042: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [42] Train loss : [0.015346692209797246] Val Score : [0.8189994908759815])\n",
            "Epoch : [43] Train loss : [0.014336449426731892] Val Score : [0.7887218676684034])\n",
            "Epoch : [44] Train loss : [0.014477944134601526] Val Score : [0.755629357577611])\n",
            "Epoch : [45] Train loss : [0.014849317592701741] Val Score : [0.7725514640071602])\n",
            "Epoch : [46] Train loss : [0.014487325413418668] Val Score : [0.8041895926750926])\n",
            "Epoch : [47] Train loss : [0.015105144785983222] Val Score : [0.8041895926750926])\n",
            "Epoch : [48] Train loss : [0.015140099783561059] Val Score : [0.7725514640071602])\n",
            "Epoch : [49] Train loss : [0.014897730268005813] Val Score : [0.8041895926750926])\n",
            "Epoch : [50] Train loss : [0.015752525002296482] Val Score : [0.7887218676684034])\n",
            "Epoch : [51] Train loss : [0.015965588058211973] Val Score : [0.8041895926750926])\n",
            "Epoch : [52] Train loss : [0.015667149797081947] Val Score : [0.8041895926750926])\n",
            "Epoch 00053: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [53] Train loss : [0.014615414198487997] Val Score : [0.755629357577611])\n",
            "Epoch : [54] Train loss : [0.015170207779322351] Val Score : [0.7379018553027905])\n",
            "Epoch : [55] Train loss : [0.014556414913386106] Val Score : [0.755629357577611])\n",
            "Epoch : [56] Train loss : [0.014362622717661517] Val Score : [0.755629357577611])\n",
            "Epoch : [57] Train loss : [0.014948171962584769] Val Score : [0.7379018553027905])\n",
            "Epoch : [58] Train loss : [0.014346616608755929] Val Score : [0.755629357577611])\n",
            "Epoch : [59] Train loss : [0.014503464036222016] Val Score : [0.7437178496040009])\n",
            "\n",
            "etc col : V21 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V22\n",
            "Epoch : [0] Train loss : [0.20079624439988816] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.06860210107905525] Val Score : [0.8927516353661109])\n",
            "Epoch : [2] Train loss : [0.04146144073456526] Val Score : [0.9031202878275757])\n",
            "Epoch : [3] Train loss : [0.04122379528624671] Val Score : [0.9097393418694286])\n",
            "Epoch : [4] Train loss : [0.0327594465176974] Val Score : [0.9165787375726882])\n",
            "Epoch : [5] Train loss : [0.023359794036618302] Val Score : [0.9165787375726882])\n",
            "Epoch : [6] Train loss : [0.01985944222126688] Val Score : [0.9165787375726882])\n",
            "Epoch : [7] Train loss : [0.022450321620064124] Val Score : [0.9165787375726882])\n",
            "Epoch : [8] Train loss : [0.025208501677427973] Val Score : [0.9165787375726882])\n",
            "Epoch : [9] Train loss : [0.023597978188523223] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.020252005995384285] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.021525036543607712] Val Score : [0.9137051774467988])\n",
            "Epoch : [12] Train loss : [0.019828573933669498] Val Score : [0.9137051774467988])\n",
            "Epoch : [13] Train loss : [0.020421231032482216] Val Score : [0.9137051774467988])\n",
            "Epoch : [14] Train loss : [0.02188733220100403] Val Score : [0.9209734995691702])\n",
            "Epoch : [15] Train loss : [0.02159859080399786] Val Score : [0.9165787375726882])\n",
            "Epoch : [16] Train loss : [0.02545549427824361] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.020093881924237524] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.018866038216011866] Val Score : [0.9106263628050926])\n",
            "Epoch : [19] Train loss : [0.0182423736633999] Val Score : [0.9137051774467988])\n",
            "Epoch : [20] Train loss : [0.018965121757771288] Val Score : [0.9137051774467988])\n",
            "Epoch : [21] Train loss : [0.019366039894521236] Val Score : [0.9165787375726882])\n",
            "Epoch : [22] Train loss : [0.018737195724887506] Val Score : [0.9137051774467988])\n",
            "Epoch : [23] Train loss : [0.020095624960958958] Val Score : [0.9209734995691702])\n",
            "Epoch : [24] Train loss : [0.01970814647419112] Val Score : [0.9137051774467988])\n",
            "Epoch : [25] Train loss : [0.019982842462403432] Val Score : [0.9034120550289857])\n",
            "Epoch 00026: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [26] Train loss : [0.01760125160217285] Val Score : [0.8724347298745778])\n",
            "Epoch : [27] Train loss : [0.015447695074336869] Val Score : [0.8331926764657618])\n",
            "Epoch : [28] Train loss : [0.01612140384635755] Val Score : [0.8331926764657618])\n",
            "Epoch : [29] Train loss : [0.016478910510029112] Val Score : [0.8598769209128951])\n",
            "Epoch : [30] Train loss : [0.016565689950117042] Val Score : [0.8845098845450512])\n",
            "Epoch : [31] Train loss : [0.016860159380095347] Val Score : [0.8189994908759815])\n",
            "Epoch : [32] Train loss : [0.0161153101362288] Val Score : [0.899903286500554])\n",
            "Epoch : [33] Train loss : [0.0161899283661374] Val Score : [0.8598769209128951])\n",
            "Epoch : [34] Train loss : [0.01651005134252565] Val Score : [0.846806907378336])\n",
            "Epoch : [35] Train loss : [0.01594557965706502] Val Score : [0.8598769209128951])\n",
            "Epoch : [36] Train loss : [0.016456228215247393] Val Score : [0.8331926764657618])\n",
            "Epoch 00037: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [37] Train loss : [0.015337152207004172] Val Score : [0.8189994908759815])\n",
            "Epoch : [38] Train loss : [0.015348315172429596] Val Score : [0.8189994908759815])\n",
            "Epoch : [39] Train loss : [0.01532479069594826] Val Score : [0.8331926764657618])\n",
            "Epoch : [40] Train loss : [0.014181620707469327] Val Score : [0.8331926764657618])\n",
            "Epoch : [41] Train loss : [0.01421072959367718] Val Score : [0.8041895926750926])\n",
            "Epoch : [42] Train loss : [0.014231455578867878] Val Score : [0.8041895926750926])\n",
            "Epoch : [43] Train loss : [0.014070817069815738] Val Score : [0.8041895926750926])\n",
            "Epoch : [44] Train loss : [0.013845287862100772] Val Score : [0.8041895926750926])\n",
            "Epoch : [45] Train loss : [0.014139244665524789] Val Score : [0.8189994908759815])\n",
            "Epoch : [46] Train loss : [0.014005717555327075] Val Score : [0.8041895926750926])\n",
            "Epoch : [47] Train loss : [0.01398546395025083] Val Score : [0.8041895926750926])\n",
            "Epoch 00048: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [48] Train loss : [0.014073411135801248] Val Score : [0.7725514640071602])\n",
            "Epoch : [49] Train loss : [0.014586902023958308] Val Score : [0.7725514640071602])\n",
            "Epoch : [50] Train loss : [0.014582817176623004] Val Score : [0.8041895926750926])\n",
            "Epoch : [51] Train loss : [0.013778183276632003] Val Score : [0.755629357577611])\n",
            "Epoch : [52] Train loss : [0.01455718105924981] Val Score : [0.8041895926750926])\n",
            "Epoch : [53] Train loss : [0.013876649218478374] Val Score : [0.755629357577611])\n",
            "Epoch : [54] Train loss : [0.01365362832854901] Val Score : [0.755629357577611])\n",
            "Epoch : [55] Train loss : [0.013375180973006147] Val Score : [0.755629357577611])\n",
            "Epoch : [56] Train loss : [0.01368848221110446] Val Score : [0.755629357577611])\n",
            "Epoch : [57] Train loss : [0.013500987951244627] Val Score : [0.7725514640071602])\n",
            "Epoch : [58] Train loss : [0.014121525787881442] Val Score : [0.755629357577611])\n",
            "Epoch 00059: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [59] Train loss : [0.01444996747055224] Val Score : [0.755629357577611])\n",
            "\n",
            "etc col : V22 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V23\n",
            "Epoch : [0] Train loss : [0.20449195695774897] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.05784551400159087] Val Score : [0.42794682354439556])\n",
            "Epoch : [2] Train loss : [0.03170237570468869] Val Score : [0.8786471773914175])\n",
            "Epoch : [3] Train loss : [0.03164278369929109] Val Score : [0.9236496787663914])\n",
            "Epoch : [4] Train loss : [0.026751158093767508] Val Score : [0.9165787375726882])\n",
            "Epoch : [5] Train loss : [0.032255840088639944] Val Score : [0.8967110829723166])\n",
            "Epoch : [6] Train loss : [0.028915374406746457] Val Score : [0.9165787375726882])\n",
            "Epoch : [7] Train loss : [0.02318362199834415] Val Score : [0.6131975743550268])\n",
            "Epoch : [8] Train loss : [0.022458010353147984] Val Score : [0.9097393418694286])\n",
            "Epoch : [9] Train loss : [0.029820661060512066] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.022507481410035064] Val Score : [0.9137051774467988])\n",
            "Epoch : [11] Train loss : [0.019986862848911966] Val Score : [0.9165787375726882])\n",
            "Epoch : [12] Train loss : [0.02015933926616396] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.021530166933579103] Val Score : [0.9236496787663914])\n",
            "Epoch : [14] Train loss : [0.020026958281440393] Val Score : [0.9137051774467988])\n",
            "Epoch 00015: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [15] Train loss : [0.018261951926563467] Val Score : [0.8887833851083367])\n",
            "Epoch : [16] Train loss : [0.016455800605139563] Val Score : [0.846806907378336])\n",
            "Epoch : [17] Train loss : [0.016505293481584107] Val Score : [0.8331926764657618])\n",
            "Epoch : [18] Train loss : [0.018490522434668883] Val Score : [0.8398593381861659])\n",
            "Epoch : [19] Train loss : [0.016930090596101115] Val Score : [0.8724347298745778])\n",
            "Epoch : [20] Train loss : [0.017382786476186345] Val Score : [0.9137051774467988])\n",
            "Epoch : [21] Train loss : [0.016713078333331004] Val Score : [0.8887833851083367])\n",
            "Epoch : [22] Train loss : [0.01811872169907604] Val Score : [0.8927516353661109])\n",
            "Epoch : [23] Train loss : [0.01616161230153271] Val Score : [0.846806907378336])\n",
            "Epoch : [24] Train loss : [0.01610614139852779] Val Score : [0.8772441968135101])\n",
            "Epoch : [25] Train loss : [0.016961831266858747] Val Score : [0.8598769209128951])\n",
            "Epoch 00026: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [26] Train loss : [0.017382721549698284] Val Score : [0.8598769209128951])\n",
            "Epoch : [27] Train loss : [0.016191941685974598] Val Score : [0.846806907378336])\n",
            "Epoch : [28] Train loss : [0.014787474248026098] Val Score : [0.8189994908759815])\n",
            "Epoch : [29] Train loss : [0.01569836586713791] Val Score : [0.8189994908759815])\n",
            "Epoch : [30] Train loss : [0.016868310381791422] Val Score : [0.8598769209128951])\n",
            "Epoch : [31] Train loss : [0.015635197649576833] Val Score : [0.8189994908759815])\n",
            "Epoch : [32] Train loss : [0.016816316372049705] Val Score : [0.812341761023982])\n",
            "Epoch : [33] Train loss : [0.015335550598267998] Val Score : [0.8598769209128951])\n",
            "Epoch : [34] Train loss : [0.016067814148430313] Val Score : [0.846806907378336])\n",
            "Epoch : [35] Train loss : [0.015874719513314112] Val Score : [0.8189994908759815])\n",
            "Epoch : [36] Train loss : [0.01567375294065901] Val Score : [0.8041895926750926])\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [37] Train loss : [0.014455620332487993] Val Score : [0.8041895926750926])\n",
            "Epoch : [38] Train loss : [0.014837558381259441] Val Score : [0.7725514640071602])\n",
            "Epoch : [39] Train loss : [0.014471363675381457] Val Score : [0.755629357577611])\n",
            "Epoch : [40] Train loss : [0.013923861552029848] Val Score : [0.7437178496040009])\n",
            "Epoch : [41] Train loss : [0.015582254356039422] Val Score : [0.8189994908759815])\n",
            "Epoch : [42] Train loss : [0.014000769704580307] Val Score : [0.8041895926750926])\n",
            "Epoch : [43] Train loss : [0.014268429750310523] Val Score : [0.7887218676684034])\n",
            "Epoch : [44] Train loss : [0.014271271082439594] Val Score : [0.7887218676684034])\n",
            "Epoch : [45] Train loss : [0.015075638823743378] Val Score : [0.8041895926750926])\n",
            "Epoch : [46] Train loss : [0.015236206552279847] Val Score : [0.7437178496040009])\n",
            "Epoch : [47] Train loss : [0.01645451265254191] Val Score : [0.7725514640071602])\n",
            "Epoch 00048: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [48] Train loss : [0.015493582069341625] Val Score : [0.7887218676684034])\n",
            "Epoch : [49] Train loss : [0.014065856247075967] Val Score : [0.7049260428710196])\n",
            "Epoch : [50] Train loss : [0.014367155531155211] Val Score : [0.7498242036425005])\n",
            "Epoch : [51] Train loss : [0.01453013704823596] Val Score : [0.7103329465949443])\n",
            "Epoch : [52] Train loss : [0.014841466011213405] Val Score : [0.5906717950274928])\n",
            "Epoch : [53] Train loss : [0.014462655210601432] Val Score : [0.7049260428710196])\n",
            "Epoch : [54] Train loss : [0.013694535807839461] Val Score : [0.5906717950274928])\n",
            "Epoch : [55] Train loss : [0.014348981968526329] Val Score : [0.7379018553027905])\n",
            "Epoch : [56] Train loss : [0.013554982974060945] Val Score : [0.7498242036425005])\n",
            "Epoch : [57] Train loss : [0.013917336506502969] Val Score : [0.6174185476616381])\n",
            "Epoch : [58] Train loss : [0.014580743586910623] Val Score : [0.6174185476616381])\n",
            "Epoch 00059: reducing learning rate of group 0 to 3.1250e-04.\n",
            "Epoch : [59] Train loss : [0.013737373586211885] Val Score : [0.5320032001215638])\n",
            "\n",
            "etc col : V23 / Marco F1 Score : 0.9236496787663914\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V24\n",
            "Epoch : [0] Train loss : [0.19554341744099343] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.06270657054015569] Val Score : [0.5089845707910685])\n",
            "Epoch : [2] Train loss : [0.034502102328198295] Val Score : [0.8933283131184154])\n",
            "Epoch : [3] Train loss : [0.031182845256158283] Val Score : [0.9034120550289857])\n",
            "Epoch : [4] Train loss : [0.03234861604869366] Val Score : [0.8287186884323108])\n",
            "Epoch : [5] Train loss : [0.025899375921913555] Val Score : [0.9066829407144783])\n",
            "Epoch : [6] Train loss : [0.025345831045082638] Val Score : [0.8498417276308385])\n",
            "Epoch : [7] Train loss : [0.023548356789563383] Val Score : [0.8598769209128951])\n",
            "Epoch : [8] Train loss : [0.025746791756578853] Val Score : [0.8331926764657618])\n",
            "Epoch : [9] Train loss : [0.02898839076182672] Val Score : [0.8724347298745778])\n",
            "Epoch : [10] Train loss : [0.025204194044428214] Val Score : [0.8598769209128951])\n",
            "Epoch : [11] Train loss : [0.02649071001048599] Val Score : [0.9034120550289857])\n",
            "Epoch : [12] Train loss : [0.02495671808719635] Val Score : [0.8927516353661109])\n",
            "Epoch : [13] Train loss : [0.02578145478452955] Val Score : [0.9034120550289857])\n",
            "Epoch : [14] Train loss : [0.021130267131541456] Val Score : [0.899903286500554])\n",
            "Epoch : [15] Train loss : [0.022681979728596553] Val Score : [0.896129704996047])\n",
            "Epoch : [16] Train loss : [0.02657152965132679] Val Score : [0.9137051774467988])\n",
            "Epoch : [17] Train loss : [0.022081099982772554] Val Score : [0.8724347298745778])\n",
            "Epoch : [18] Train loss : [0.019186668896249363] Val Score : [0.8598769209128951])\n",
            "Epoch : [19] Train loss : [0.019396627587931498] Val Score : [0.8724347298745778])\n",
            "Epoch : [20] Train loss : [0.01942852059645312] Val Score : [0.8724347298745778])\n",
            "Epoch : [21] Train loss : [0.021012899332812855] Val Score : [0.9073194875902806])\n",
            "Epoch : [22] Train loss : [0.019927825379584516] Val Score : [0.8598769209128951])\n",
            "Epoch : [23] Train loss : [0.01959997176059655] Val Score : [0.9137051774467988])\n",
            "Epoch : [24] Train loss : [0.020516392109649523] Val Score : [0.9066829407144783])\n",
            "Epoch : [25] Train loss : [0.02280953593019928] Val Score : [0.9137051774467988])\n",
            "Epoch : [26] Train loss : [0.02068357036582061] Val Score : [0.8724347298745778])\n",
            "Epoch : [27] Train loss : [0.020226391830614636] Val Score : [0.8887833851083367])\n",
            "Epoch 00028: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [28] Train loss : [0.017636964496757303] Val Score : [0.8189994908759815])\n",
            "Epoch : [29] Train loss : [0.01811160280236176] Val Score : [0.8189994908759815])\n",
            "Epoch : [30] Train loss : [0.019157709686883857] Val Score : [0.8041895926750926])\n",
            "Epoch : [31] Train loss : [0.01767971832305193] Val Score : [0.8189994908759815])\n",
            "Epoch : [32] Train loss : [0.01829682769519942] Val Score : [0.8189994908759815])\n",
            "Epoch : [33] Train loss : [0.01769507197397096] Val Score : [0.8331926764657618])\n",
            "Epoch : [34] Train loss : [0.01859280639993293] Val Score : [0.8189994908759815])\n",
            "Epoch : [35] Train loss : [0.01742236515773194] Val Score : [0.8041895926750926])\n",
            "Epoch : [36] Train loss : [0.017646266413586482] Val Score : [0.8189994908759815])\n",
            "Epoch : [37] Train loss : [0.01756882986852101] Val Score : [0.8189994908759815])\n",
            "Epoch : [38] Train loss : [0.01835141464003495] Val Score : [0.8724347298745778])\n",
            "Epoch 00039: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [39] Train loss : [0.01670442215566124] Val Score : [0.7725514640071602])\n",
            "Epoch : [40] Train loss : [0.016883932187088897] Val Score : [0.7725514640071602])\n",
            "Epoch : [41] Train loss : [0.017163976627801145] Val Score : [0.755629357577611])\n",
            "Epoch : [42] Train loss : [0.016739372164011] Val Score : [0.7725514640071602])\n",
            "Epoch : [43] Train loss : [0.016490415669977665] Val Score : [0.755629357577611])\n",
            "Epoch : [44] Train loss : [0.01619694541607584] Val Score : [0.8041895926750926])\n",
            "Epoch : [45] Train loss : [0.016558286068694934] Val Score : [0.8041895926750926])\n",
            "Epoch : [46] Train loss : [0.017334917028035437] Val Score : [0.8041895926750926])\n",
            "Epoch : [47] Train loss : [0.018196092386330878] Val Score : [0.8041895926750926])\n",
            "Epoch : [48] Train loss : [0.01779057231864759] Val Score : [0.7725514640071602])\n",
            "Epoch : [49] Train loss : [0.016456577128597667] Val Score : [0.8041895926750926])\n",
            "Epoch 00050: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [50] Train loss : [0.016117095282035216] Val Score : [0.755629357577611])\n",
            "Epoch : [51] Train loss : [0.01686409275446619] Val Score : [0.755629357577611])\n",
            "Epoch : [52] Train loss : [0.01696831706379141] Val Score : [0.7887218676684034])\n",
            "Epoch : [53] Train loss : [0.016616186858820065] Val Score : [0.755629357577611])\n",
            "Epoch : [54] Train loss : [0.016877835350377218] Val Score : [0.7725514640071602])\n",
            "Epoch : [55] Train loss : [0.016433771034436568] Val Score : [0.755629357577611])\n",
            "Epoch : [56] Train loss : [0.015853521347578083] Val Score : [0.6426374167237955])\n",
            "Epoch : [57] Train loss : [0.016488167523805584] Val Score : [0.755629357577611])\n",
            "Epoch : [58] Train loss : [0.015952044765331914] Val Score : [0.755629357577611])\n",
            "Epoch : [59] Train loss : [0.016269970751766647] Val Score : [0.755629357577611])\n",
            "\n",
            "etc col : V24 / Marco F1 Score : 0.9137051774467988\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V25\n",
            "Epoch : [0] Train loss : [0.2095659955271653] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.06090965574341161] Val Score : [0.331521912641148])\n",
            "Epoch : [2] Train loss : [0.038990821689367294] Val Score : [0.8786471773914175])\n",
            "Epoch : [3] Train loss : [0.028821805358997414] Val Score : [0.8844834793761085])\n",
            "Epoch : [4] Train loss : [0.02844061835535935] Val Score : [0.9097393418694286])\n",
            "Epoch : [5] Train loss : [0.023043750120060786] Val Score : [0.9097393418694286])\n",
            "Epoch : [6] Train loss : [0.030289788730442524] Val Score : [0.890501890608512])\n",
            "Epoch : [7] Train loss : [0.02485046362770455] Val Score : [0.9165787375726882])\n",
            "Epoch : [8] Train loss : [0.022816172667912075] Val Score : [0.7573184229436457])\n",
            "Epoch : [9] Train loss : [0.02724661332155977] Val Score : [0.5837829182079857])\n",
            "Epoch : [10] Train loss : [0.022953192304287637] Val Score : [0.9031202878275757])\n",
            "Epoch : [11] Train loss : [0.021233392347182547] Val Score : [0.9165787375726882])\n",
            "Epoch : [12] Train loss : [0.01888414898089] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.020337435816015517] Val Score : [0.9165787375726882])\n",
            "Epoch : [14] Train loss : [0.020229986203568324] Val Score : [0.9165787375726882])\n",
            "Epoch : [15] Train loss : [0.02247922801013504] Val Score : [0.9097393418694286])\n",
            "Epoch : [16] Train loss : [0.01912447557385479] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.017442691938153336] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.017305702104100158] Val Score : [0.9137051774467988])\n",
            "Epoch 00019: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [19] Train loss : [0.020617085908140455] Val Score : [0.8817038840461091])\n",
            "Epoch : [20] Train loss : [0.019979869880314385] Val Score : [0.9236496787663914])\n",
            "Epoch : [21] Train loss : [0.01826726452314428] Val Score : [0.8652615319692264])\n",
            "Epoch : [22] Train loss : [0.01775713324812906] Val Score : [0.9236496787663914])\n",
            "Epoch : [23] Train loss : [0.015861423619623696] Val Score : [0.8964462129361583])\n",
            "Epoch : [24] Train loss : [0.01583922707608768] Val Score : [0.8652615319692264])\n",
            "Epoch : [25] Train loss : [0.015895469380276545] Val Score : [0.9034120550289857])\n",
            "Epoch : [26] Train loss : [0.016375679722321883] Val Score : [0.8398593381861659])\n",
            "Epoch : [27] Train loss : [0.016440218979758874] Val Score : [0.8598769209128951])\n",
            "Epoch : [28] Train loss : [0.015504739114216395] Val Score : [0.8817038840461091])\n",
            "Epoch : [29] Train loss : [0.016989578226847307] Val Score : [0.8460131793934016])\n",
            "Epoch : [30] Train loss : [0.017613046004303863] Val Score : [0.870247282626393])\n",
            "Epoch : [31] Train loss : [0.01748976849817804] Val Score : [0.8583586886309732])\n",
            "Epoch 00032: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [32] Train loss : [0.016239555552601814] Val Score : [0.8189994908759815])\n",
            "Epoch : [33] Train loss : [0.015579946405653442] Val Score : [0.8331926764657618])\n",
            "Epoch : [34] Train loss : [0.016198393423110247] Val Score : [0.846806907378336])\n",
            "Epoch : [35] Train loss : [0.015900378381567343] Val Score : [0.8724347298745778])\n",
            "Epoch : [36] Train loss : [0.01698780818177121] Val Score : [0.8189994908759815])\n",
            "Epoch : [37] Train loss : [0.016156092419156005] Val Score : [0.8331926764657618])\n",
            "Epoch : [38] Train loss : [0.016321941278874874] Val Score : [0.8331926764657618])\n",
            "Epoch : [39] Train loss : [0.015115859585681133] Val Score : [0.8331926764657618])\n",
            "Epoch : [40] Train loss : [0.014770216375057186] Val Score : [0.846806907378336])\n",
            "Epoch : [41] Train loss : [0.015649858995207717] Val Score : [0.8724347298745778])\n",
            "Epoch : [42] Train loss : [0.015546979316111122] Val Score : [0.846806907378336])\n",
            "Epoch 00043: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [43] Train loss : [0.015059032344392367] Val Score : [0.8331926764657618])\n",
            "Epoch : [44] Train loss : [0.01464392923350845] Val Score : [0.8189994908759815])\n",
            "Epoch : [45] Train loss : [0.015194435337824481] Val Score : [0.846806907378336])\n",
            "Epoch : [46] Train loss : [0.015438395219721965] Val Score : [0.8189994908759815])\n",
            "Epoch : [47] Train loss : [0.014632678790284055] Val Score : [0.846806907378336])\n",
            "Epoch : [48] Train loss : [0.014042515507233995] Val Score : [0.8189994908759815])\n",
            "Epoch : [49] Train loss : [0.014067201808627163] Val Score : [0.7887218676684034])\n",
            "Epoch : [50] Train loss : [0.014409136891897236] Val Score : [0.8189994908759815])\n",
            "Epoch : [51] Train loss : [0.014083662669041328] Val Score : [0.8041895926750926])\n",
            "Epoch : [52] Train loss : [0.014123370804424797] Val Score : [0.8189994908759815])\n",
            "Epoch : [53] Train loss : [0.014049056518290724] Val Score : [0.7887218676684034])\n",
            "Epoch 00054: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [54] Train loss : [0.014087940167103494] Val Score : [0.778902752094029])\n",
            "Epoch : [55] Train loss : [0.014012215858591455] Val Score : [0.6839995781035756])\n",
            "Epoch : [56] Train loss : [0.014115242886223964] Val Score : [0.8189994908759815])\n",
            "Epoch : [57] Train loss : [0.013923398684710264] Val Score : [0.8189994908759815])\n",
            "Epoch : [58] Train loss : [0.014453780238649674] Val Score : [0.8041895926750926])\n",
            "Epoch : [59] Train loss : [0.014194409296448742] Val Score : [0.7887218676684034])\n",
            "\n",
            "etc col : V25 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V26\n",
            "Epoch : [0] Train loss : [0.1848364807665348] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.05734331879232611] Val Score : [0.697743660770528])\n",
            "Epoch : [2] Train loss : [0.038458604498633316] Val Score : [0.54204592959581])\n",
            "Epoch : [3] Train loss : [0.03467147371598652] Val Score : [0.4983164951154058])\n",
            "Epoch : [4] Train loss : [0.028292724064418247] Val Score : [0.8927516353661109])\n",
            "Epoch : [5] Train loss : [0.03610269272966044] Val Score : [0.9165787375726882])\n",
            "Epoch : [6] Train loss : [0.02656653310571398] Val Score : [0.9137051774467988])\n",
            "Epoch : [7] Train loss : [0.024684730917215347] Val Score : [0.9137051774467988])\n",
            "Epoch : [8] Train loss : [0.028590052521654537] Val Score : [0.9165787375726882])\n",
            "Epoch : [9] Train loss : [0.029550815533314432] Val Score : [0.890501890608512])\n",
            "Epoch : [10] Train loss : [0.02657110204121896] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.021886205034596578] Val Score : [0.8927516353661109])\n",
            "Epoch : [12] Train loss : [0.02577129192650318] Val Score : [0.8845098845450512])\n",
            "Epoch : [13] Train loss : [0.024905853904783726] Val Score : [0.890501890608512])\n",
            "Epoch : [14] Train loss : [0.023015431527580534] Val Score : [0.9137051774467988])\n",
            "Epoch : [15] Train loss : [0.019990024156868458] Val Score : [0.899903286500554])\n",
            "Epoch : [16] Train loss : [0.021390854247978756] Val Score : [0.8724347298745778])\n",
            "Epoch 00017: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [17] Train loss : [0.021615275447922095] Val Score : [0.8724347298745778])\n",
            "Epoch : [18] Train loss : [0.019726241007447243] Val Score : [0.8189994908759815])\n",
            "Epoch : [19] Train loss : [0.019296545668372085] Val Score : [0.8724347298745778])\n",
            "Epoch : [20] Train loss : [0.021490769726889476] Val Score : [0.8724347298745778])\n",
            "Epoch : [21] Train loss : [0.018344061050031866] Val Score : [0.899903286500554])\n",
            "Epoch : [22] Train loss : [0.018902903954897608] Val Score : [0.8189994908759815])\n",
            "Epoch : [23] Train loss : [0.019696138000914028] Val Score : [0.846806907378336])\n",
            "Epoch : [24] Train loss : [0.018091765099338124] Val Score : [0.8189994908759815])\n",
            "Epoch : [25] Train loss : [0.020568844064005783] Val Score : [0.8724347298745778])\n",
            "Epoch : [26] Train loss : [0.019601699097880294] Val Score : [0.8724347298745778])\n",
            "Epoch : [27] Train loss : [0.01976005227438041] Val Score : [0.8331926764657618])\n",
            "Epoch 00028: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [28] Train loss : [0.01796699714447771] Val Score : [0.8189994908759815])\n",
            "Epoch : [29] Train loss : [0.018406798796994344] Val Score : [0.8189994908759815])\n",
            "Epoch : [30] Train loss : [0.017051289789378643] Val Score : [0.7887218676684034])\n",
            "Epoch : [31] Train loss : [0.017772565994943892] Val Score : [0.8041895926750926])\n",
            "Epoch : [32] Train loss : [0.01748919061252049] Val Score : [0.8331926764657618])\n",
            "Epoch : [33] Train loss : [0.01839898127530302] Val Score : [0.8189994908759815])\n",
            "Epoch : [34] Train loss : [0.018255170035575117] Val Score : [0.7887218676684034])\n",
            "Epoch : [35] Train loss : [0.018051541144294397] Val Score : [0.8331926764657618])\n",
            "Epoch : [36] Train loss : [0.017587086717997278] Val Score : [0.8189994908759815])\n",
            "Epoch : [37] Train loss : [0.01717214592333351] Val Score : [0.8331926764657618])\n",
            "Epoch : [38] Train loss : [0.01735067700168916] Val Score : [0.8189994908759815])\n",
            "Epoch 00039: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [39] Train loss : [0.017220272150422846] Val Score : [0.755629357577611])\n",
            "Epoch : [40] Train loss : [0.01771513213004385] Val Score : [0.7887218676684034])\n",
            "Epoch : [41] Train loss : [0.017558489660067216] Val Score : [0.7437178496040009])\n",
            "Epoch : [42] Train loss : [0.017139777275068418] Val Score : [0.7887218676684034])\n",
            "Epoch : [43] Train loss : [0.01746853454304593] Val Score : [0.755629357577611])\n",
            "Epoch : [44] Train loss : [0.01805823921625103] Val Score : [0.8041895926750926])\n",
            "Epoch : [45] Train loss : [0.017521074573908533] Val Score : [0.8041895926750926])\n",
            "Epoch : [46] Train loss : [0.01692215313336679] Val Score : [0.7437178496040009])\n",
            "Epoch : [47] Train loss : [0.01702199556997844] Val Score : [0.7379018553027905])\n",
            "Epoch : [48] Train loss : [0.016903470802520002] Val Score : [0.8041895926750926])\n",
            "Epoch : [49] Train loss : [0.01661598775535822] Val Score : [0.755629357577611])\n",
            "Epoch 00050: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [50] Train loss : [0.01676497289112636] Val Score : [0.7498242036425005])\n",
            "Epoch : [51] Train loss : [0.016556653061083386] Val Score : [0.6174185476616381])\n",
            "Epoch : [52] Train loss : [0.01670215797743627] Val Score : [0.755629357577611])\n",
            "Epoch : [53] Train loss : [0.016752417465405806] Val Score : [0.7103329465949443])\n",
            "Epoch : [54] Train loss : [0.016753337745155607] Val Score : [0.6174185476616381])\n",
            "Epoch : [55] Train loss : [0.01688167213329247] Val Score : [0.7103329465949443])\n",
            "Epoch : [56] Train loss : [0.01683483099831002] Val Score : [0.7379018553027905])\n",
            "Epoch : [57] Train loss : [0.01642030038471733] Val Score : [0.7498242036425005])\n",
            "Epoch : [58] Train loss : [0.016575275122054985] Val Score : [0.755629357577611])\n",
            "Epoch : [59] Train loss : [0.016479129769972393] Val Score : [0.6792674379032821])\n",
            "\n",
            "etc col : V26 / Marco F1 Score : 0.9137051774467988\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V27\n",
            "Epoch : [0] Train loss : [0.19323948504669325] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.05119633887495313] Val Score : [0.2804654819382078])\n",
            "Epoch : [2] Train loss : [0.033763179289443154] Val Score : [0.8470287373843977])\n",
            "Epoch : [3] Train loss : [0.03215890657156706] Val Score : [0.9031202878275757])\n",
            "Epoch : [4] Train loss : [0.025069112357284342] Val Score : [0.890501890608512])\n",
            "Epoch : [5] Train loss : [0.02486828767827579] Val Score : [0.9097393418694286])\n",
            "Epoch : [6] Train loss : [0.024030710304422036] Val Score : [0.9097393418694286])\n",
            "Epoch : [7] Train loss : [0.02264775495444025] Val Score : [0.9097393418694286])\n",
            "Epoch : [8] Train loss : [0.021445241224552904] Val Score : [0.9097393418694286])\n",
            "Epoch : [9] Train loss : [0.020743073895573616] Val Score : [0.9097393418694286])\n",
            "Epoch : [10] Train loss : [0.023160056078008244] Val Score : [0.9031202878275757])\n",
            "Epoch : [11] Train loss : [0.023109468365354196] Val Score : [0.8660300854960024])\n",
            "Epoch : [12] Train loss : [0.02518814043807132] Val Score : [0.9097393418694286])\n",
            "Epoch : [13] Train loss : [0.021820328464465483] Val Score : [0.9236496787663914])\n",
            "Epoch : [14] Train loss : [0.024729555738823756] Val Score : [0.9097393418694286])\n",
            "Epoch : [15] Train loss : [0.02131184775914465] Val Score : [0.9236496787663914])\n",
            "Epoch : [16] Train loss : [0.019933666501726423] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.033343385106750896] Val Score : [0.547692673578974])\n",
            "Epoch : [18] Train loss : [0.024876511123563563] Val Score : [0.9097393418694286])\n",
            "Epoch : [19] Train loss : [0.022728141131145612] Val Score : [0.9097393418694286])\n",
            "Epoch : [20] Train loss : [0.02027634291776589] Val Score : [0.9097393418694286])\n",
            "Epoch : [21] Train loss : [0.019387812885854925] Val Score : [0.9097393418694286])\n",
            "Epoch : [22] Train loss : [0.01771702038656388] Val Score : [0.9236496787663914])\n",
            "Epoch : [23] Train loss : [0.018643914588860104] Val Score : [0.9165787375726882])\n",
            "Epoch : [24] Train loss : [0.019296327073659216] Val Score : [0.9236496787663914])\n",
            "Epoch 00025: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [25] Train loss : [0.01614548811422927] Val Score : [0.8724347298745778])\n",
            "Epoch : [26] Train loss : [0.01515148300677538] Val Score : [0.8772441968135101])\n",
            "Epoch : [27] Train loss : [0.01642147997128112] Val Score : [0.846806907378336])\n",
            "Epoch : [28] Train loss : [0.015492683609149285] Val Score : [0.9106263628050926])\n",
            "Epoch : [29] Train loss : [0.01653414186356323] Val Score : [0.8652615319692264])\n",
            "Epoch : [30] Train loss : [0.015517704654484987] Val Score : [0.9034120550289857])\n",
            "Epoch : [31] Train loss : [0.015741718467324972] Val Score : [0.8724347298745778])\n",
            "Epoch : [32] Train loss : [0.02165177185088396] Val Score : [0.8844834793761085])\n",
            "Epoch : [33] Train loss : [0.018336201419255564] Val Score : [0.899903286500554])\n",
            "Epoch : [34] Train loss : [0.014343789778649807] Val Score : [0.8897162026625655])\n",
            "Epoch : [35] Train loss : [0.01405037853068539] Val Score : [0.8598769209128951])\n",
            "Epoch 00036: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [36] Train loss : [0.012937855707215411] Val Score : [0.8189994908759815])\n",
            "Epoch : [37] Train loss : [0.013830962590873241] Val Score : [0.846806907378336])\n",
            "Epoch : [38] Train loss : [0.014719042793980666] Val Score : [0.846806907378336])\n",
            "Epoch : [39] Train loss : [0.013490342535078526] Val Score : [0.8189994908759815])\n",
            "Epoch : [40] Train loss : [0.013644240264381682] Val Score : [0.8598769209128951])\n",
            "Epoch : [41] Train loss : [0.013475636086825813] Val Score : [0.846806907378336])\n",
            "Epoch : [42] Train loss : [0.014448918934379305] Val Score : [0.846806907378336])\n",
            "Epoch : [43] Train loss : [0.012781197471278054] Val Score : [0.8041895926750926])\n",
            "Epoch : [44] Train loss : [0.013972570254866565] Val Score : [0.8724347298745778])\n",
            "Epoch : [45] Train loss : [0.013893000116305692] Val Score : [0.8598769209128951])\n",
            "Epoch : [46] Train loss : [0.01289397943764925] Val Score : [0.7887218676684034])\n",
            "Epoch 00047: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [47] Train loss : [0.01271527340369565] Val Score : [0.755629357577611])\n",
            "Epoch : [48] Train loss : [0.01314654660278133] Val Score : [0.8041895926750926])\n",
            "Epoch : [49] Train loss : [0.012888461950102023] Val Score : [0.755629357577611])\n",
            "Epoch : [50] Train loss : [0.013244517746248416] Val Score : [0.7379018553027905])\n",
            "Epoch : [51] Train loss : [0.013327943626791239] Val Score : [0.8189994908759815])\n",
            "Epoch : [52] Train loss : [0.012411166714238269] Val Score : [0.8041895926750926])\n",
            "Epoch : [53] Train loss : [0.012486245283590896] Val Score : [0.7379018553027905])\n",
            "Epoch : [54] Train loss : [0.012145106215029955] Val Score : [0.755629357577611])\n",
            "Epoch : [55] Train loss : [0.011954556019710643] Val Score : [0.8189994908759815])\n",
            "Epoch : [56] Train loss : [0.012645188186849867] Val Score : [0.8189994908759815])\n",
            "Epoch : [57] Train loss : [0.012463303748518229] Val Score : [0.7379018553027905])\n",
            "Epoch 00058: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [58] Train loss : [0.011944695641951901] Val Score : [0.7437178496040009])\n",
            "Epoch : [59] Train loss : [0.012230376047747476] Val Score : [0.7498242036425005])\n",
            "\n",
            "etc col : V27 / Marco F1 Score : 0.9236496787663914\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V28\n",
            "Epoch : [0] Train loss : [0.18782633276922361] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.05884423106908798] Val Score : [0.3474271794602398])\n",
            "Epoch : [2] Train loss : [0.03890335253838982] Val Score : [0.7331432493795871])\n",
            "Epoch : [3] Train loss : [0.030752708204090595] Val Score : [0.5752370096002138])\n",
            "Epoch : [4] Train loss : [0.029900860706610338] Val Score : [0.5966253027265187])\n",
            "Epoch : [5] Train loss : [0.029984033400458947] Val Score : [0.6346887404024459])\n",
            "Epoch : [6] Train loss : [0.028201441280543804] Val Score : [0.74464046996434])\n",
            "Epoch : [7] Train loss : [0.02877858094871044] Val Score : [0.9165787375726882])\n",
            "Epoch : [8] Train loss : [0.027965363381164416] Val Score : [0.9097393418694286])\n",
            "Epoch : [9] Train loss : [0.03222262832735266] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.028500862419605255] Val Score : [0.890501890608512])\n",
            "Epoch : [11] Train loss : [0.021985835262707303] Val Score : [0.8927516353661109])\n",
            "Epoch : [12] Train loss : [0.022057353918041502] Val Score : [0.899903286500554])\n",
            "Epoch : [13] Train loss : [0.021522442011960914] Val Score : [0.9137051774467988])\n",
            "Epoch : [14] Train loss : [0.023515646079821245] Val Score : [0.8998944850872257])\n",
            "Epoch : [15] Train loss : [0.021383768745831082] Val Score : [0.9137051774467988])\n",
            "Epoch : [16] Train loss : [0.020843702501484325] Val Score : [0.8598769209128951])\n",
            "Epoch : [17] Train loss : [0.021136679420513765] Val Score : [0.8598769209128951])\n",
            "Epoch : [18] Train loss : [0.021485154650041034] Val Score : [0.8927516353661109])\n",
            "Epoch 00019: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [19] Train loss : [0.019768236338027885] Val Score : [0.8598769209128951])\n",
            "Epoch : [20] Train loss : [0.01757678243198565] Val Score : [0.8189994908759815])\n",
            "Epoch : [21] Train loss : [0.022776735946536064] Val Score : [0.8598769209128951])\n",
            "Epoch : [22] Train loss : [0.017163887952587435] Val Score : [0.8331926764657618])\n",
            "Epoch : [23] Train loss : [0.018315329682081938] Val Score : [0.8331926764657618])\n",
            "Epoch : [24] Train loss : [0.01681808921109353] Val Score : [0.8189994908759815])\n",
            "Epoch : [25] Train loss : [0.01646625656368477] Val Score : [0.8189994908759815])\n",
            "Epoch : [26] Train loss : [0.01671292113938502] Val Score : [0.8598769209128951])\n",
            "Epoch : [27] Train loss : [0.017798077248569046] Val Score : [0.8189994908759815])\n",
            "Epoch : [28] Train loss : [0.018088402692228556] Val Score : [0.8189994908759815])\n",
            "Epoch : [29] Train loss : [0.01607547820146595] Val Score : [0.8041895926750926])\n",
            "Epoch 00030: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [30] Train loss : [0.015359014073120696] Val Score : [0.8189994908759815])\n",
            "Epoch : [31] Train loss : [0.015434526572270053] Val Score : [0.7725514640071602])\n",
            "Epoch : [32] Train loss : [0.01686420338228345] Val Score : [0.8041895926750926])\n",
            "Epoch : [33] Train loss : [0.015323614302490438] Val Score : [0.7887218676684034])\n",
            "Epoch : [34] Train loss : [0.016511128417083194] Val Score : [0.755629357577611])\n",
            "Epoch : [35] Train loss : [0.016097929794341326] Val Score : [0.755629357577611])\n",
            "Epoch : [36] Train loss : [0.018311657809785435] Val Score : [0.8041895926750926])\n",
            "Epoch : [37] Train loss : [0.015663513115474155] Val Score : [0.7725514640071602])\n",
            "Epoch : [38] Train loss : [0.01666661032608577] Val Score : [0.7725514640071602])\n",
            "Epoch : [39] Train loss : [0.01846867966066514] Val Score : [0.8189994908759815])\n",
            "Epoch : [40] Train loss : [0.01706690008619002] Val Score : [0.7725514640071602])\n",
            "Epoch 00041: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [41] Train loss : [0.015640282205172946] Val Score : [0.755629357577611])\n",
            "Epoch : [42] Train loss : [0.014994471001305751] Val Score : [0.6664557258707168])\n",
            "Epoch : [43] Train loss : [0.014789999861802374] Val Score : [0.6839995781035756])\n",
            "Epoch : [44] Train loss : [0.015452130498098475] Val Score : [0.7437178496040009])\n",
            "Epoch : [45] Train loss : [0.01599037061844553] Val Score : [0.7498242036425005])\n",
            "Epoch : [46] Train loss : [0.016014127592955316] Val Score : [0.755629357577611])\n",
            "Epoch : [47] Train loss : [0.016683782716946944] Val Score : [0.8189994908759815])\n",
            "Epoch : [48] Train loss : [0.015417793566094977] Val Score : [0.7725514640071602])\n",
            "Epoch : [49] Train loss : [0.015059401813362325] Val Score : [0.755629357577611])\n",
            "Epoch : [50] Train loss : [0.015553755552640982] Val Score : [0.755629357577611])\n",
            "Epoch : [51] Train loss : [0.016326385882816145] Val Score : [0.7887218676684034])\n",
            "Epoch 00052: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [52] Train loss : [0.015559063093470675] Val Score : [0.7498242036425005])\n",
            "Epoch : [53] Train loss : [0.015132689782019173] Val Score : [0.5906717950274928])\n",
            "Epoch : [54] Train loss : [0.01506248429151518] Val Score : [0.6174185476616381])\n",
            "Epoch : [55] Train loss : [0.0150967219046184] Val Score : [0.6174185476616381])\n",
            "Epoch : [56] Train loss : [0.014667475729116372] Val Score : [0.562253919707516])\n",
            "Epoch : [57] Train loss : [0.014938439109495707] Val Score : [0.5906717950274928])\n",
            "Epoch : [58] Train loss : [0.014824950402336461] Val Score : [0.6174185476616381])\n",
            "Epoch : [59] Train loss : [0.014765952514218432] Val Score : [0.5906717950274928])\n",
            "\n",
            "etc col : V28 / Marco F1 Score : 0.9137051774467988\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V29\n",
            "Epoch : [0] Train loss : [0.18197314973388398] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.05648052719022546] Val Score : [0.8998944850872257])\n",
            "Epoch : [2] Train loss : [0.029977593570947647] Val Score : [0.9097393418694286])\n",
            "Epoch : [3] Train loss : [0.027019081504217217] Val Score : [0.9097393418694286])\n",
            "Epoch : [4] Train loss : [0.027324218835149492] Val Score : [0.9031202878275757])\n",
            "Epoch : [5] Train loss : [0.024068254977464676] Val Score : [0.008045561816978544])\n",
            "Epoch : [6] Train loss : [0.026390836308045045] Val Score : [0.8998856821259607])\n",
            "Epoch : [7] Train loss : [0.020994295100016252] Val Score : [0.9097393418694286])\n",
            "Epoch : [8] Train loss : [0.02187875671578305] Val Score : [0.9097393418694286])\n",
            "Epoch : [9] Train loss : [0.019009022175201347] Val Score : [0.9066829407144783])\n",
            "Epoch : [10] Train loss : [0.01859092459614788] Val Score : [0.9097393418694286])\n",
            "Epoch : [11] Train loss : [0.02162101718464068] Val Score : [0.9097393418694286])\n",
            "Epoch : [12] Train loss : [0.018955222197941372] Val Score : [0.9097393418694286])\n",
            "Epoch : [13] Train loss : [0.0167264378895717] Val Score : [0.9097393418694286])\n",
            "Epoch 00014: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [14] Train loss : [0.015970532516283647] Val Score : [0.8927516353661109])\n",
            "Epoch : [15] Train loss : [0.016311864368617535] Val Score : [0.8927516353661109])\n",
            "Epoch : [16] Train loss : [0.0155546920640128] Val Score : [0.9066829407144783])\n",
            "Epoch : [17] Train loss : [0.01426612725481391] Val Score : [0.9066829407144783])\n",
            "Epoch : [18] Train loss : [0.01676703936287335] Val Score : [0.9066829407144783])\n",
            "Epoch : [19] Train loss : [0.015734047096754824] Val Score : [0.8964462129361583])\n",
            "Epoch : [20] Train loss : [0.016919092940432683] Val Score : [0.8858506104888013])\n",
            "Epoch : [21] Train loss : [0.016222743517053977] Val Score : [0.8817038840461091])\n",
            "Epoch : [22] Train loss : [0.016347808364246572] Val Score : [0.8528093037014359])\n",
            "Epoch : [23] Train loss : [0.01708423998206854] Val Score : [0.9066829407144783])\n",
            "Epoch : [24] Train loss : [0.01785470119544438] Val Score : [0.8927516353661109])\n",
            "Epoch 00025: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [25] Train loss : [0.015037658025643654] Val Score : [0.812341761023982])\n",
            "Epoch : [26] Train loss : [0.014049006825579064] Val Score : [0.8263811616954475])\n",
            "Epoch : [27] Train loss : [0.013718458291675364] Val Score : [0.812341761023982])\n",
            "Epoch : [28] Train loss : [0.012591813624437367] Val Score : [0.812341761023982])\n",
            "Epoch : [29] Train loss : [0.013118549516158444] Val Score : [0.812341761023982])\n",
            "Epoch : [30] Train loss : [0.01285783959818738] Val Score : [0.812341761023982])\n",
            "Epoch : [31] Train loss : [0.013566320296376944] Val Score : [0.812341761023982])\n",
            "Epoch : [32] Train loss : [0.013806362902479512] Val Score : [0.7977053133319791])\n",
            "Epoch : [33] Train loss : [0.013709006764526879] Val Score : [0.7977053133319791])\n",
            "Epoch : [34] Train loss : [0.013825760688632727] Val Score : [0.812341761023982])\n",
            "Epoch : [35] Train loss : [0.013839471553053175] Val Score : [0.7977053133319791])\n",
            "Epoch 00036: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [36] Train loss : [0.013077487969504935] Val Score : [0.812341761023982])\n",
            "Epoch : [37] Train loss : [0.012891039052712066] Val Score : [0.812341761023982])\n",
            "Epoch : [38] Train loss : [0.01292119680770806] Val Score : [0.812341761023982])\n",
            "Epoch : [39] Train loss : [0.013033284007438592] Val Score : [0.7664820642650774])\n",
            "Epoch : [40] Train loss : [0.01375941333494016] Val Score : [0.7977053133319791])\n",
            "Epoch : [41] Train loss : [0.012966140838606017] Val Score : [0.812341761023982])\n",
            "Epoch : [42] Train loss : [0.012541902384587697] Val Score : [0.8263811616954475])\n",
            "Epoch : [43] Train loss : [0.013680074297423874] Val Score : [0.8263811616954475])\n",
            "Epoch : [44] Train loss : [0.01271287358498999] Val Score : [0.8263811616954475])\n",
            "Epoch : [45] Train loss : [0.012142133699463946] Val Score : [0.7824328807501029])\n",
            "Epoch : [46] Train loss : [0.012278786860406399] Val Score : [0.7977053133319791])\n",
            "Epoch 00047: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [47] Train loss : [0.012466196436434984] Val Score : [0.7498066104078762])\n",
            "Epoch : [48] Train loss : [0.01201983361638018] Val Score : [0.7498066104078762])\n",
            "Epoch : [49] Train loss : [0.012455306215477841] Val Score : [0.7977053133319791])\n",
            "Epoch : [50] Train loss : [0.01273454852136118] Val Score : [0.7664820642650774])\n",
            "Epoch : [51] Train loss : [0.011714460128652198] Val Score : [0.7437178496040009])\n",
            "Epoch : [52] Train loss : [0.0119686523186309] Val Score : [0.7323559630611931])\n",
            "Epoch : [53] Train loss : [0.011980863421091012] Val Score : [0.7664820642650774])\n",
            "Epoch : [54] Train loss : [0.011907071473875217] Val Score : [0.7379018553027905])\n",
            "Epoch : [55] Train loss : [0.012262042279222183] Val Score : [0.694902201909525])\n",
            "Epoch : [56] Train loss : [0.012374714881713902] Val Score : [0.7498066104078762])\n",
            "Epoch : [57] Train loss : [0.012946109620055981] Val Score : [0.7977053133319791])\n",
            "Epoch 00058: reducing learning rate of group 0 to 3.1250e-04.\n",
            "Epoch : [58] Train loss : [0.012571784401578563] Val Score : [0.7824328807501029])\n",
            "Epoch : [59] Train loss : [0.011596393372331346] Val Score : [0.7049260428710196])\n",
            "\n",
            "etc col : V29 / Marco F1 Score : 0.9097393418694286\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V30\n",
            "Epoch : [0] Train loss : [0.189544039113181] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.0612606339688812] Val Score : [0.8583586886309732])\n",
            "Epoch : [2] Train loss : [0.03298657267753567] Val Score : [0.9097393418694286])\n",
            "Epoch : [3] Train loss : [0.027315091607826098] Val Score : [0.9097393418694286])\n",
            "Epoch : [4] Train loss : [0.02452798999313797] Val Score : [0.9097393418694286])\n",
            "Epoch : [5] Train loss : [0.0236507828480431] Val Score : [0.9097393418694286])\n",
            "Epoch : [6] Train loss : [0.024853146634995937] Val Score : [0.9165787375726882])\n",
            "Epoch : [7] Train loss : [0.02251920849084854] Val Score : [0.9137051774467988])\n",
            "Epoch : [8] Train loss : [0.021375573772404875] Val Score : [0.9034120550289857])\n",
            "Epoch : [9] Train loss : [0.02316617060984884] Val Score : [0.9137051774467988])\n",
            "Epoch : [10] Train loss : [0.02619903494736978] Val Score : [0.9137051774467988])\n",
            "Epoch : [11] Train loss : [0.024989369857524122] Val Score : [0.9137051774467988])\n",
            "Epoch : [12] Train loss : [0.021400169602462223] Val Score : [0.9137051774467988])\n",
            "Epoch : [13] Train loss : [0.022569237143865654] Val Score : [0.9137051774467988])\n",
            "Epoch : [14] Train loss : [0.022407865284809043] Val Score : [0.9137051774467988])\n",
            "Epoch : [15] Train loss : [0.023305983149579594] Val Score : [0.9137051774467988])\n",
            "Epoch : [16] Train loss : [0.020901504770985672] Val Score : [0.8652615319692264])\n",
            "Epoch : [17] Train loss : [0.02095544577709266] Val Score : [0.9137051774467988])\n",
            "Epoch 00018: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [18] Train loss : [0.019379808035280024] Val Score : [0.8598769209128951])\n",
            "Epoch : [19] Train loss : [0.018371521894420897] Val Score : [0.8331926764657618])\n",
            "Epoch : [20] Train loss : [0.018186663144401143] Val Score : [0.8598769209128951])\n",
            "Epoch : [21] Train loss : [0.01818193175962993] Val Score : [0.8652615319692264])\n",
            "Epoch : [22] Train loss : [0.01845299213060311] Val Score : [0.8331926764657618])\n",
            "Epoch : [23] Train loss : [0.016879959431077753] Val Score : [0.8331926764657618])\n",
            "Epoch : [24] Train loss : [0.016839498254869665] Val Score : [0.8331926764657618])\n",
            "Epoch : [25] Train loss : [0.01573524797069175] Val Score : [0.8331926764657618])\n",
            "Epoch : [26] Train loss : [0.016577111623649086] Val Score : [0.8331926764657618])\n",
            "Epoch : [27] Train loss : [0.016607042202459916] Val Score : [0.8598769209128951])\n",
            "Epoch : [28] Train loss : [0.015476548911205359] Val Score : [0.8041895926750926])\n",
            "Epoch 00029: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [29] Train loss : [0.01600470220936196] Val Score : [0.8041895926750926])\n",
            "Epoch : [30] Train loss : [0.015029344907296556] Val Score : [0.8041895926750926])\n",
            "Epoch : [31] Train loss : [0.015044536175472396] Val Score : [0.8041895926750926])\n",
            "Epoch : [32] Train loss : [0.015462023937808616] Val Score : [0.8041895926750926])\n",
            "Epoch : [33] Train loss : [0.015464309669498886] Val Score : [0.7725514640071602])\n",
            "Epoch : [34] Train loss : [0.01515873528218695] Val Score : [0.8041895926750926])\n",
            "Epoch : [35] Train loss : [0.015584816690534353] Val Score : [0.8189994908759815])\n",
            "Epoch : [36] Train loss : [0.015976005965577706] Val Score : [0.8041895926750926])\n",
            "Epoch : [37] Train loss : [0.01535609650558659] Val Score : [0.8041895926750926])\n",
            "Epoch : [38] Train loss : [0.01476195634209684] Val Score : [0.8041895926750926])\n",
            "Epoch : [39] Train loss : [0.01483440911397338] Val Score : [0.8041895926750926])\n",
            "Epoch 00040: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [40] Train loss : [0.015104088533137525] Val Score : [0.7887218676684034])\n",
            "Epoch : [41] Train loss : [0.014485453588089772] Val Score : [0.8041895926750926])\n",
            "Epoch : [42] Train loss : [0.014636508721326078] Val Score : [0.7725514640071602])\n",
            "Epoch : [43] Train loss : [0.014687139274818557] Val Score : [0.8041895926750926])\n",
            "Epoch : [44] Train loss : [0.013927942141890526] Val Score : [0.7725514640071602])\n",
            "Epoch : [45] Train loss : [0.014491261847849404] Val Score : [0.7725514640071602])\n",
            "Epoch : [46] Train loss : [0.01481813658028841] Val Score : [0.755629357577611])\n",
            "Epoch : [47] Train loss : [0.014976402545081717] Val Score : [0.7725514640071602])\n",
            "Epoch : [48] Train loss : [0.013915330504200287] Val Score : [0.7725514640071602])\n",
            "Epoch : [49] Train loss : [0.014049370507044452] Val Score : [0.755629357577611])\n",
            "Epoch : [50] Train loss : [0.014362032259149211] Val Score : [0.7725514640071602])\n",
            "Epoch 00051: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [51] Train loss : [0.01390574746099966] Val Score : [0.755629357577611])\n",
            "Epoch : [52] Train loss : [0.013820420418466841] Val Score : [0.755629357577611])\n",
            "Epoch : [53] Train loss : [0.014087895064481668] Val Score : [0.7379018553027905])\n",
            "Epoch : [54] Train loss : [0.014177691324480943] Val Score : [0.7725514640071602])\n",
            "Epoch : [55] Train loss : [0.013763686242912496] Val Score : [0.755629357577611])\n",
            "Epoch : [56] Train loss : [0.014151167523648058] Val Score : [0.7379018553027905])\n",
            "Epoch : [57] Train loss : [0.013847952375986747] Val Score : [0.755629357577611])\n",
            "Epoch : [58] Train loss : [0.013669332289802176] Val Score : [0.7437178496040009])\n",
            "Epoch : [59] Train loss : [0.013729510097099202] Val Score : [0.7437178496040009])\n",
            "\n",
            "etc col : V30 / Marco F1 Score : 0.9137051774467988\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evalution"
      ],
      "metadata": {
        "id": "_MFNAKnKpCHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check(result, ts, val):\n",
        "\n",
        "  pred_result = []\n",
        "\n",
        "  for i in result:\n",
        "\n",
        "    if i >= ts:\n",
        "\n",
        "      i = 1\n",
        "\n",
        "    else:\n",
        "\n",
        "      i = 0\n",
        "\n",
        "    pred_result.append(i)\n",
        "\n",
        "  if val == True:\n",
        "\n",
        "    val_score = f1_score(y_val, pred_result, average='macro')\n",
        "    recall = recall_score(y_val, pred_result)\n",
        "    precision = precision_score(y_val, pred_result)\n",
        "\n",
        "    print(f'Marco F1 Score : {val_score}\\n')\n",
        "    print(f'Recall : {recall}\\n')\n",
        "    print(f'Precision : {precision}\\n')\n",
        "\n",
        "    print(classification_report(y_val, pred_result))\n",
        "\n",
        "  return pred_result"
      ],
      "metadata": {
        "id": "tvSbyHAh4mGk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_val = check(result_val, 18, val=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jPsytCf5YL0",
        "outputId": "3ae3ab96-f22d-4487-bfe6-eef3ed3e0caa"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marco F1 Score : 0.9137051774467988\n",
            "\n",
            "Recall : 0.8\n",
            "\n",
            "Precision : 0.8571428571428571\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     28432\n",
            "           1       0.86      0.80      0.83        30\n",
            "\n",
            "    accuracy                           1.00     28462\n",
            "   macro avg       0.93      0.90      0.91     28462\n",
            "weighted avg       1.00      1.00      1.00     28462\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix = confusion_matrix(y_val, pred_val)\n",
        "sns.heatmap(cf_matrix, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "2ik01IURFu15",
        "outputId": "1cbbf959-9108-4b22-aa2f-49865c96f28d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD4CAYAAAAn3bdmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWZUlEQVR4nO3deXxW1Z3H8c8vQVrEBVCLQFBcsB1sR1QKVNTBpQg4Dtr6UqyV1IKhCipqLai1uHWqrxa1tuoYlYodC1KXQt0AkY4dlU1AFkFJUUpSBFkEK0whyW/+yME+IEmekOXhHL9vX+eV+/zudh5f4cePc8+919wdERGJQ16uOyAiItlT0hYRiYiStohIRJS0RUQioqQtIhKRZo19gu3rVmh6inxGi/an5LoLshcq31Zm9T1GXXLOPgcfWe/zNTVV2iIiEWn0SltEpElVVuS6B41KSVtE0lJRnuseNColbRFJintlrrvQqJS0RSQtlUraIiLxUKUtIhIRXYgUEYmIKm0RkXi4Zo+IiEREFyJFRCKi4RERkYjoQqSISERUaYuIREQXIkVEIqILkSIi8XDXmLaISDw0pi0iEhENj4iIRESVtohIRCq257oHjUpJW0TSouEREZGIJD48orexi0haKiuzbzUws45mNsPM3jazJWZ2dYjfYmZlZrYgtP4Z+9xgZiVm9o6ZnZUR7xtiJWY2KiN+hJnNCvEnzax5bV9PSVtE0tJASRsoB65z9y5AT2CYmXUJ6+5x966hvQAQ1g0EjgX6Ag+YWb6Z5QP3A/2ALsBFGce5KxzraGAjMLi2Tilpi0hSvGJ71q3G47ivdvd5YfljYCnQoYZdBgAT3P0f7v4eUAJ0D63E3Ve4+zZgAjDAzAw4HXgq7D8OOLe276ekLSJp8crsW5bMrBNwPDArhIab2UIzG2tmrUOsA7AqY7fSEKsufhDwkbuX7xKvkZK2iKSlDsMjZlZkZnMzWtGuhzOz/YCngRHuvhl4EDgK6AqsBsY05dfT7BERSUsdKmh3LwaKq1tvZvtQlbCfcPdnwj5rMtY/DDwXPpYBHTN2LwgxqomvB1qZWbNQbWduXy1V2iKSloabPWLAo8BSd787I94uY7PzgMVheTIw0My+YGZHAJ2B2cAcoHOYKdKcqouVk93dgRnA+WH/QmBSbV9PlbaIpKXh5mn3Ai4BFpnZghC7karZH10BB94HhgK4+xIzmwi8TdXMk2EeHjloZsOBKUA+MNbdl4TjjQQmmNkdwHyq/pKokVUl+8azfd2Kxj2BRKlF+1Ny3QXZC5VvK7P6HmPr8/dmnXNanD2i3udraqq0RSQtid8RqaQtImnRs0dERCKiSltEJCKqtEVEIqJKW0QkIuXltW8TMSVtEUlLI09jzjUlbRFJi8a0RUQioqQtIhIRXYgUEYlIRUWue9ColLRFJC0aHhERiYiStohIRDSmLSISD6/UPG0RkXhoeEREJCKaPSIiEhFV2iIiEUk8aett7NVYveZDLh0+kv+4uIgBFw/ltxP/8JltPv77Jwz70Wi+VXgFAy4eyrPPT633eTdt/pghV99I/wsHM+TqG9m0+eOd1i9a+g7HnXo2U2f8ud7nktzLy8tjzuwpTHp2XK67kg737FuElLSr0Sw/n+uvvIzJTxTzu+J7mPDMc/zlvZU7bTP+6T9yVKfDeGbcA/zm13fx8189zPbt27M6/ux5C7npjjGfiT/y24n07NaVF558lJ7duvLof0/8dF1FRQX3PPAbTvr6CfX7crLXuOrKISxbtjzX3UhLZWX2LUJK2tU45OA2dPny0QC0bLkvRx7ekTUfrt9pGzPjky1bcXe2bP0/Djxgf/Lz8wEY+8RTXDj4Ks4bdDm/fuS3WZ93xp/fYEC/MwEY0O9MXnn1jU/X/e6pyXyzdy/atG5V368ne4EOHdrRv98ZjB07PtddSUulZ98iVGvSNrOvmNlIM7svtJFm9i9N0bm9RdnqNSxd/hf+9dgv7xT/zrfPYcX7qzhtwMWcN+hyRo34AXl5ebw2603+WlrGhEd+ydOP3c/b75Qwd8GirM61fuNHHHJwGwAOPqg16zd+BMCaD9cx/dXXufC8sxv2y0nO3D3mVkbdcAeVkVZ8e62KiuxbhGq8EGlmI4GLgAnA7BAuAMab2QR3v7Oa/YqAIoAHxtzBkEEXNVyPm9iWLVu55qY7GHnVUPZr2XKnda/NfpOvdD6Ssb+6k1Vlq7lsxI2ceNyxvD5nHq/Pnsf53xtedYytW1m56m906/o1LrpsBNu2bWfL1q1s2vwx3y4cBsC1V3yfXj1O3On4ZoaZAXDXLx/imsu/T16e/nGUgrP7n8nateuYN38R/3bqN3LdnaR44n8J1jZ7ZDBwrLvvNFBrZncDS4DdJm13LwaKAbavWxHnv0GA7eXljLjpDs7ucxrf7N3rM+uffX4aQ757AWbGYQXt6dDuUN5bWQoOQy65kAvO7f+ZfcY/fC9QNaY96YVp/PTH1+20/qDWrfhw3QYOObgNH67bQJtWBwKwZNlyrh9d9b9746bN/PmNOeTn53PGqSc19NeWJnDSSd0459/70K/v6Xzxi1/ggAP2Z9xj91H4vaty3bX4RTrska3ayrZKoP1u4u3CumS5Oz/52b0ceXhHCgd+a7fbtGt7CDPfXADAug0bef+vpRS0P5STup/As89PZcuWrUDV0MaOYY7a9D65J5NefBmASS++zGmnVFVhU556jKlPj2Pq0+Po0/tkfvzDYUrYEbvpx3fS6chuHH1MTy7+7hXMmPGaEnZD8crsW4Rqq7RHANPNbDmwKsQOA44Ghjdmx3Jt/sIl/PGl6XQ+qtOnQxhXDy1k9ZoPAbjwvLP5wfe+w00/HcN5l1yOu3PNFd+ndasD6dXjRFasXMXFQ68FYN8WX+RnP7meg7K4gDjkkgu47ub/5JnnptD+0C8x5vYbG+9LiqQo8UrbvJa5imaWB3QHOoRQGTDH3bMaxY95eEQaT4v2p+S6C7IXKt9WZvU9xic/GZh1zml524R6n6+p1XpHpLtXAjOboC8iIvUX6bBHtnQbu4ikJfHhEc0fE5GkeGVl1q0mZtbRzGaY2dtmtsTMrg7xNmY2zcyWh5+tQ9zCvSwlZrbQzE7IOFZh2H65mRVmxE80s0Vhn/tsxxzfGihpi0haGu6OyHLgOnfvAvQEhplZF2AUMN3dOwPTw2eAfkDn0IqAB6EqyQOjgR5UXR8cvSPRh20uy9ivb22dUtIWkbQ0UNJ299XuPi8sfwwspWpCxgBgxxO+xgHnhuUBwONeZSbQyszaAWcB09x9g7tvBKYBfcO6A9x9plfNCHk841jV0pi2iKSlDrenZ969HRSHmwN33a4TcDwwC2jr7qvDqg+AtmG5A/+cGg1QGmI1xUt3E6+RkraIJKUu74jMvHu7Oma2H/A0MMLdN2cOO7u7m1mTXvnU8IiIpKUBn/JnZvtQlbCfcPdnQnhNGNog/Fwb4mVAx4zdC0KspnjBbuI1UtIWkbQ00PO0w0yOR4Gl7n53xqrJwI4ZIIXApIz4oDCLpCewKQyjTAH6mFnrcAGyDzAlrNtsZj3DuQZlHKtaGh4RkbQ03DztXsAlwCIzWxBiN1L1oLyJZjYYWAlcENa9APQHSoAtwKUA7r7BzG4H5oTtbnP3DWH5CuAxoAXwYmg1UtIWkbQ0UNJ29/8Fqps3fcZutndgWDXHGguM3U18LvDVuvRLSVtEkuIVuo1dRCQeid/GrqQtIkmpy5S/GClpi0halLRFRCKS9pC2kraIpMXL087aStoikpa0c7aStoikRRciRURiokpbRCQeqrRFRGKiSltEJB5enuseNC4lbRFJiqvSFhGJiJK2iEg8VGmLiERESVtEJCJeUd17C9KgpC0iSVGlLSISEa9UpS0iEg1V2iIiEXFXpS0iEg1V2iIiEanU7BERkXjoQqSISESUtEVEIuJpP05bSVtE0qJKW0QkIpryJyISkYrEZ4/k5boDIiINyd2ybrUxs7FmttbMFmfEbjGzMjNbEFr/jHU3mFmJmb1jZmdlxPuGWImZjcqIH2Fms0L8STNrXluflLRFJCleaVm3LDwG9N1N/B537xraCwBm1gUYCBwb9nnAzPLNLB+4H+gHdAEuCtsC3BWOdTSwERhcW4eUtEUkKe7Zt9qP5a8CG7I89QBggrv/w93fA0qA7qGVuPsKd98GTAAGmJkBpwNPhf3HAefWdhIlbRFJSl0qbTMrMrO5Ga0oy9MMN7OFYfikdYh1AFZlbFMaYtXFDwI+cv/0VcQ74jVS0haRpFRU5mXd3L3Y3btltOIsTvEgcBTQFVgNjGnUL7QLzR4RkaQ09s017r5mx7KZPQw8Fz6WAR0zNi0IMaqJrwdamVmzUG1nbl8tVdoikpRKt6zbnjCzdhkfzwN2zCyZDAw0sy+Y2RFAZ2A2MAfoHGaKNKfqYuVkd3dgBnB+2L8QmFTb+VVpi0hSGvLmGjMbD/QGDjazUmA00NvMugIOvA8MrTqvLzGzicDbQDkwzN0rwnGGA1OAfGCsuy8JpxgJTDCzO4D5wKO19skb+d8S29etSPxJALInWrQ/JdddkL1Q+bayemfceR0HZJ1zTlg1Kbo7cRq90tYfThFpSns67BELDY+ISFIqKtO+VKekLSJJSX08VklbRJKi4RERkYjo0awiIhFJ/GXsStoikhZHlbaISDTKNTwiIhIPVdoiIhHRmLaISERUaYuIRESVtohIRCpUaYuIxCO79/XGS0lbRJJSqUpbRCQeemCUiEhEdCFSRCQilabhERGRaFTkugONTElbRJKi2SMiIhHR7BERkYho9oiISEQ0PCIiEhFN+RMRiUiFKm0RkXio0hYRiYiStohIRBJ/RaSStoikJfVKOy/XHRARaUgVdWi1MbOxZrbWzBZnxNqY2TQzWx5+tg5xM7P7zKzEzBaa2QkZ+xSG7ZebWWFG/EQzWxT2uc+s9genKGmLSFIqLfuWhceAvrvERgHT3b0zMD18BugHdA6tCHgQqpI8MBroAXQHRu9I9GGbyzL22/Vcn6GkLSJJqaxDq427vwps2CU8ABgXlscB52bEH/cqM4FWZtYOOAuY5u4b3H0jMA3oG9Yd4O4z3d2BxzOOVS0lbRFJSl2StpkVmdncjFaUxSnauvvqsPwB0DYsdwBWZWxXGmI1xUt3E6+RLkSKSFLq8uwRdy8Givf4XO5uZk36uBNV2iKSlAYe096dNWFog/BzbYiXAR0ztisIsZriBbuJ10hJW0SS0pCzR6oxGdgxA6QQmJQRHxRmkfQENoVhlClAHzNrHS5A9gGmhHWbzaxnmDUyKONY1dLwiIgkpbIBH85qZuOB3sDBZlZK1SyQO4GJZjYYWAlcEDZ/AegPlABbgEsB3H2Dmd0OzAnb3ebuOy5uXkHVDJUWwIuh1UhJW0SS0pA317j7RdWsOmM32zowrJrjjAXG7iY+F/hqXfqkpC0iSdFLEEREIpL6bexK2iKSlPKmnYHX5JS0RSQpaadsJW0RSYyGR0REItKQU/72RkraIpKUtFO2kraIJEbDIyIiEalIvNZW0haRpKjSFhGJiKvSFhGJR+qVth7N2kQOPPAAnpxQzOJF/8OihX+iZ48Tc90lyYGCgva8PPX3LHxrBm8teIUrhw/eaf01I4ZSvq2Mgw5qXc0RpDaVeNYtRqq0m8g9d9/GlCkzuHBgEfvssw/77tsi112SHCgvL+f6H93K/AWL2W+/lsye9RIvT3+VpUuXU1DQnm+eeSorV5bWfiCpVpypOHuqtJvAAQfszykn92Dsb8YDsH37djZt2pzjXkkufPDBWuYvWAzA3//+CcuWLadD+0MBGPOLWxh140+pesKn7KlyPOsWIyXtJnDEEYexbt16Hn3kHubMnsJD//VzVdrC4YcX0PW4rzJr9nzOOacPZWWrWbjw7Vx3K3peh/9itMdJ28wurWHdp284rqz8ZE9PkYxm+fkcf/zXeOihx/l697P45JMtjPzR8Fx3S3KoZct9mfjkw1z7w9GUl5dzw8grueXWX+S6W0moy9vYY1SfSvvW6la4e7G7d3P3bnl5LetxijSUlq2mtHQ1s+fMB+CZZ57n+K5fy3GvJFeaNWvG7598mPHjn+UPf3iRo47qRKdOhzFv7jRK3p1JQUE75syaQtu2h+S6q1FKvdKu8UKkmS2sbhXQtuG7k6Y1az6ktPRvHHPMUbz77l84/fSTWbr03Vx3S3Lk4eIxLF1Wwr2/LAZg8eJltC847tP1Je/OpMc3+rF+/cZcdTFqsVbQ2apt9khb4Cxg198eA15vlB4l6uprbubxcb+iefN9eO+9vzJ4yLW57pLkQK+Tvs4l3z2fhYveZu6cqQDcfPOdvPjSKznuWToqEr+QW1vSfg7Yz90X7LrCzP7UKD1K1FtvLaHnN/rnuhuSY6+9PodmzTvUuM3Rx/Rsot6kKdb519mqMWm7++Aa1n2n4bsjIlI/sY5VZ0s314hIUj7vY9oiIlH5XA+PiIjERsMjIiIR+bzPHhERiYqGR0REIqILkSIiEUl9TFtP+RORpDTkSxDM7H0zW2RmC8xsboi1MbNpZrY8/Gwd4mZm95lZiZktNLMTMo5TGLZfbmaF9fl+StoikhR3z7pl6TR37+ru3cLnUcB0d+8MTA+fAfoBnUMrAh6EqiQPjAZ6AN2B0TsS/Z5Q0haRpFTgWbc9NAAYF5bHAedmxB/3KjOBVmbWjqrnN01z9w3uvhGYBvTd05MraYtIUhr4HZEOTDWzN82sKMTauvvqsPwB/3ziaQdgVca+pSFWXXyP6EKkiCSlLq9rC4m4KCNU7O7FGZ9PdvcyM/sSMM3Mlu1yLjezJr3yqaQtIkmpyzztkKCLa1hfFn6uNbNnqRqTXmNm7dx9dRj+WBs2LwM6ZuxeEGJlQO9d4n/KupO70PCIiCSlod5cY2YtzWz/HctAH2AxMBnYMQOkEJgUlicDg8Iskp7ApjCMMgXoY2atwwXIPiG2R1Rpi0hSGvA29rbAs2YGVbnyd+7+kpnNASaa2WBgJXBB2P4FoD9QAmwBLgVw9w1mdjswJ2x3m7tv2NNOWV3Gf/ZEs+Yd0p7pLiINpnxbmdX3GL06nJ51znmt7JV6n6+pqdIWkaTo2SMiIhFp7NGDXFPSFpGkqNIWEYlI6g+MUtIWkaRUeNoPZ1XSFpGkaExbRCQiGtMWEYmIxrRFRCJSqeEREZF4qNIWEYmIZo+IiEREwyMiIhHR8IiISERUaYuIRESVtohIRCq8ItddaFRK2iKSFN3GLiISEd3GLiISEVXaIiIR0ewREZGIaPaIiEhEdBu7iEhENKYtIhIRjWmLiERElbaISEQ0T1tEJCKqtEVEIqLZIyIiEdGFSBGRiGh4REQkIrojUkQkIqq0RUQikvqYtqX+t9LexMyK3L041/2QvYt+L6Qu8nLdgc+Zolx3QPZK+r2QrClpi4hERElbRCQiStpNS+OWsjv6vZCs6UKkiEhEVGmLiERESVtEJCJK2k3EzPqa2TtmVmJmo3LdH8k9MxtrZmvNbHGu+yLxUNJuAmaWD9wP9AO6ABeZWZfc9kr2Ao8BfXPdCYmLknbT6A6UuPsKd98GTAAG5LhPkmPu/iqwIdf9kLgoaTeNDsCqjM+lISYiUidK2iIiEVHSbhplQMeMzwUhJiJSJ0raTWMO0NnMjjCz5sBAYHKO+yQiEVLSbgLuXg4MB6YAS4GJ7r4kt72SXDOz8cAbwJfNrNTMBue6T7L3023sIiIRUaUtIhIRJW0RkYgoaYuIRERJW0QkIkraIiIRUdIWEYmIkraISET+H3XAHc+of/hfAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "M8c0IedopEGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test = check(result_test, 18, val=False)"
      ],
      "metadata": {
        "id": "WNBewGZxGMUI"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "2AxD3czQpFdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('./sample_submission.csv')"
      ],
      "metadata": {
        "id": "-9R_uDJSGbX7"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit['Class'] = pred_test\n",
        "submit.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JTk-Uq9TGl_O",
        "outputId": "4452b6a9-b802-4c65-844a-2fff90876f95"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID  Class\n",
              "0  AAAA0x1      0\n",
              "1  AAAA0x2      0\n",
              "2  AAAA0x5      0\n",
              "3  AAAA0x7      0\n",
              "4  AAAA0xc      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbe1c801-e4ea-4afa-b814-06e87137fc30\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAAA0x1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAAA0x2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAAA0x5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAAA0x7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAAA0xc</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbe1c801-e4ea-4afa-b814-06e87137fc30')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fbe1c801-e4ea-4afa-b814-06e87137fc30 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fbe1c801-e4ea-4afa-b814-06e87137fc30');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit.to_csv('./E_Auto_Encoder_14.csv', index=False)"
      ],
      "metadata": {
        "id": "J01N6tyOGnOT"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ozMT3eyOCBJg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}