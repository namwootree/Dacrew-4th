{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setting"
      ],
      "metadata": {
        "id": "TKId0SH-oQ-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library"
      ],
      "metadata": {
        "id": "tqkHJMatoTQG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Uwe-PUxx1Flz"
      },
      "outputs": [],
      "source": [
        "# 데이터 다루기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "# 전처리\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.decomposition import PCA, KernelPCA, SparsePCA, TruncatedSVD, IncrementalPCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
        "\n",
        "# 모델링\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score # 재현율\n",
        "from sklearn.metrics import precision_score # 정밀도\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 기타\n",
        "import os\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "B7YGq6Py1HFA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.optim import Optimizer, AdamW\n",
        "from torch.optim.lr_scheduler import LambdaLR, CyclicLR, OneCycleLR"
      ],
      "metadata": {
        "id": "U-Df5snx1IVE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "1saXz_tA1KFq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU"
      ],
      "metadata": {
        "id": "Jx1fv0oNobYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWXlBCmpoN-R",
        "outputId": "2dce7553-0e7f-426d-cb72-2e6f14d9fcf2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Feb 13 07:15:33 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   29C    P0    49W / 400W |   1590MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A     30469      C                                    1587MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')"
      ],
      "metadata": {
        "id": "VKVUFl5Z1Li8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixed Random Seed"
      ],
      "metadata": {
        "id": "jpHKZdrzodHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(42) # Seed 고정"
      ],
      "metadata": {
        "id": "uJJcsV1r1Mt1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data Set"
      ],
      "metadata": {
        "id": "6UuYP97soe3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goolge Drive Mount"
      ],
      "metadata": {
        "id": "AStlM68DogNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeVZI9271PKV",
        "outputId": "31653b9f-b8f1-4728-a029-3dc6793204a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unzip File"
      ],
      "metadata": {
        "id": "ubzOI9QioiFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip --qq '/content/drive/MyDrive/머신러닝 엔지니어링/데이콘/사기거래/data/사기거래.zip'"
      ],
      "metadata": {
        "id": "Hcg3DfOl1Qlr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load CSV"
      ],
      "metadata": {
        "id": "1fzNvNFIojiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/train.csv')\n",
        "val = pd.read_csv('/content/val.csv')\n",
        "test = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "EwSXD0ex1R0q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, df, eval_mode):\n",
        "        self.df = df\n",
        "        self.eval_mode = eval_mode\n",
        "        if self.eval_mode:\n",
        "            self.labels = self.df['Class'].values\n",
        "            self.df = self.df.drop(columns=['Class']).values\n",
        "        else:\n",
        "            self.df = self.df.values\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        if self.eval_mode:\n",
        "            x = torch.from_numpy(self.df[index]).type(torch.FloatTensor)\n",
        "            y = torch.FloatTensor([self.labels[index]])\n",
        "            return x, y\n",
        "            #self.x = self.df[index]\n",
        "            #self.y = self.labels[index]\n",
        "            #return torch.Tensor(self.x), self.y\n",
        "        else:\n",
        "            self.x = self.df[index]\n",
        "            return torch.Tensor(self.x)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "metadata": {
        "id": "adZTW_tb3RpH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "B1mUo_-zon3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection"
      ],
      "metadata": {
        "id": "9vOfjM8oopiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.drop(columns=['ID']) \n",
        "\n",
        "X_val = val.drop(columns=['ID', 'Class']) \n",
        "y_val = val['Class']\n",
        "\n",
        "X_test = test.drop(columns=['ID'])"
      ],
      "metadata": {
        "id": "1th0Lc6h1TTk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[['V3', 'V4', 'V9', 'V10', 'V11',\n",
        "                   'V12', 'V14', 'V16', 'V17', 'V18']]\n",
        "\n",
        "X_val = X_val[['V3', 'V4', 'V9', 'V10', 'V11',\n",
        "               'V12', 'V14', 'V16', 'V17', 'V18']]\n",
        "\n",
        "X_test = X_test[['V3', 'V4', 'V9', 'V10', 'V11',\n",
        "                 'V12', 'V14', 'V16', 'V17', 'V18']]"
      ],
      "metadata": {
        "id": "suWUzg_w1UO4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_drop_cols = list(X_train.columns) + ['ID']\n",
        "\n",
        "list_etc_cols = list(train.drop(columns=list_drop_cols))"
      ],
      "metadata": {
        "id": "n5MQTkr_1Vsr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list_etc_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoPjhwYcGHIy",
        "outputId": "1ebf223a-4038-4533-83cf-18fb1cd589d3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "njK9HQKrozKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Function"
      ],
      "metadata": {
        "id": "hwoYANqco6kP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        self.Encoder = nn.Sequential(\n",
        "            nn.Linear(473,256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256,128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128,64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64,32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "        self.Decoder = nn.Sequential(\n",
        "            nn.Linear(32,64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64,128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128,256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256,473),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.Encoder(x)\n",
        "        x = self.Decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "NBYFd8UN3TgD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.scheduler = scheduler\n",
        "        self.device = device\n",
        "        # Loss Function\n",
        "        self.criterion = nn.L1Loss().to(self.device)\n",
        "        \n",
        "    def fit(self):\n",
        "        self.model.to(self.device)\n",
        "        best_score = 0\n",
        "        avg = 1\n",
        "        for epoch in range(50):\n",
        "            self.model.train()\n",
        "            train_loss = []\n",
        "            for x in iter(self.train_loader):\n",
        "                x = x.float().to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                _x = self.model(x)\n",
        "                loss = self.criterion(x, _x)\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                train_loss.append(loss.item())\n",
        "\n",
        "            score = self.validation(self.model, 0.95)\n",
        "            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n",
        "\n",
        "            if self.scheduler is not None:\n",
        "                self.scheduler.step(score)\n",
        "\n",
        "            if best_score <= score and avg > np.mean(train_loss):\n",
        "                best_score = score\n",
        "                avg = np.mean(train_loss)\n",
        "                torch.save(model.module.state_dict(), './best_model.pth', _use_new_zipfile_serialization=False)\n",
        "    \n",
        "    def validation(self, eval_model, thr):\n",
        "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "        eval_model.eval()\n",
        "        pred = []\n",
        "        true = []\n",
        "        with torch.no_grad():\n",
        "            for x, y in iter(self.val_loader):\n",
        "                x = x.float().to(self.device)\n",
        "\n",
        "                _x = self.model(x)\n",
        "                diff = cos(x, _x).cpu().tolist()\n",
        "                batch_pred = np.where(np.array(diff)<thr, 1, 0).tolist()\n",
        "                pred += batch_pred\n",
        "                true += y.tolist()\n",
        "\n",
        "        return f1_score(true, pred, average='macro')"
      ],
      "metadata": {
        "id": "XXsRIChU3ge-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(model, thr, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "    pred = []\n",
        "    with torch.no_grad():\n",
        "        for x in iter(test_loader):\n",
        "            x = x.float().to(device)\n",
        "            _x = model(x)\n",
        "            \n",
        "            diff = cos(x, _x).cpu().tolist()\n",
        "            batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n",
        "            pred += batch_pred\n",
        "    return pred"
      ],
      "metadata": {
        "id": "-rCC4zAp3iSq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "nO-3riEao_Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_val = np.zeros(val.shape[0])\n",
        "result_test = np.zeros(test.shape[0])\n",
        "\n",
        "y_val = val[['Class']]\n",
        "\n",
        "for etc_col in list_etc_cols:\n",
        "\n",
        "  X_train = pd.concat([X_train, train[[etc_col]]], axis=1)\n",
        "  X_val = pd.concat([X_val, val[[etc_col]]], axis=1)\n",
        "  X_test = pd.concat([X_test, test[[etc_col]]], axis=1)\n",
        "\n",
        "  scaler = RobustScaler(quantile_range=(45.0, 55.0))\n",
        "\n",
        "  scaled_train = scaler.fit_transform(X_train)\n",
        "\n",
        "  scaled_val = scaler.transform(X_val)\n",
        "  scaled_test = scaler.transform(X_test)\n",
        "\n",
        "  scaled_train = pd.DataFrame(scaled_train)\n",
        "  scaled_val = pd.DataFrame(scaled_val)\n",
        "  scaled_test = pd.DataFrame(scaled_test)\n",
        "\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "\n",
        "  scaled_train = scaler.fit_transform(scaled_train)\n",
        "  scaled_val = scaler.transform(scaled_val)\n",
        "  scaled_test = scaler.transform(scaled_test)\n",
        "\n",
        "  scaled_train = pd.DataFrame(scaled_train)\n",
        "  scaled_val = pd.DataFrame(scaled_val)\n",
        "  scaled_test = pd.DataFrame(scaled_test)\n",
        "\n",
        "  main_columns = list(scaled_train.columns)\n",
        "\n",
        "  com_main = list(combinations(main_columns, 5))\n",
        "\n",
        "  for com in com_main:\n",
        "\n",
        "    x = com[0]\n",
        "    y = com[1]\n",
        "    z = com[2]\n",
        "    w = com[3]\n",
        "    v = com[-1]\n",
        "\n",
        "    scaled_train[f'{x}_{y}_{z}_{w}_{v}_mean'] = (scaled_train[x] + scaled_train[y] + scaled_train[z] + scaled_train[w] + scaled_train[v]) / 5\n",
        "    scaled_val[f'{x}_{y}_{z}_{w}_{v}_mean'] = (scaled_val[x] + scaled_val[y] + scaled_val[z] + scaled_val[w] + scaled_val[v]) / 5\n",
        "    scaled_test[f'{x}_{y}_{z}_{w}_{v}_mean'] = (scaled_test[x] + scaled_test[y] + scaled_test[z] + scaled_test[w] + scaled_test[v]) / 5\n",
        "  \n",
        "  dimesion_reducer = SparseRandomProjection(n_components=473, eps=0.1, random_state=42)\n",
        "\n",
        "\n",
        "  reduced_train = dimesion_reducer.fit_transform(scaled_train)\n",
        "  reduced_val = dimesion_reducer.transform(scaled_val)\n",
        "  reduced_test = dimesion_reducer.transform(scaled_test)\n",
        "\n",
        "  reduced_train = pd.DataFrame(reduced_train)\n",
        "  reduced_val = pd.DataFrame(reduced_val)\n",
        "  reduced_test = pd.DataFrame(reduced_test)\n",
        "\n",
        "  print()\n",
        "  print('-'*100)\n",
        "  print()\n",
        "  print(f'{etc_col}')\n",
        "\n",
        "  train_dataset = MyDataset(df=reduced_train, eval_mode=False)\n",
        "  train_loader = DataLoader(train_dataset, batch_size=2**13, shuffle=True, num_workers=6)\n",
        "\n",
        "  reduced_val=pd.concat([reduced_val, val[['Class']]], axis=1)\n",
        "  val_dataset = MyDataset(df=reduced_val, eval_mode=True)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=2**13, shuffle=False, num_workers=6)\n",
        "\n",
        "  model = nn.DataParallel(AutoEncoder())\n",
        "  model.eval()\n",
        "  optimizer = torch.optim.Adam(params = model.parameters(), lr = 1e-2)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
        "\n",
        "  trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n",
        "  trainer.fit()\n",
        "\n",
        "  model = AutoEncoder()\n",
        "  model.load_state_dict(torch.load('./best_model.pth'))\n",
        "  model = nn.DataParallel(model)\n",
        "  model.eval()\n",
        "\n",
        "  reduced_val = reduced_val.drop(columns=['Class'])\n",
        "  val_dataset = MyDataset(reduced_val, False)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=2**13, shuffle=False, num_workers=6)\n",
        "\n",
        "  pred_val = prediction(model, 0.95, val_loader, device)\n",
        "  result_val += pred_val\n",
        "\n",
        "  val_score = f1_score(y_val, pred_val, average='macro')\n",
        "  print(f'\\netc col : {etc_col} / Marco F1 Score : {val_score}\\n')\n",
        "\n",
        "  test_dataset = MyDataset(reduced_test, False)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=2**13, shuffle=False, num_workers=6)\n",
        "\n",
        "  pred_test = prediction(model, 0.95, test_loader, device)\n",
        "  result_test += pred_test\n",
        "\n",
        "  X_train = X_train.drop(columns=etc_col)\n",
        "  X_val = X_val.drop(columns=etc_col)\n",
        "  X_test = X_test.drop(columns=etc_col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OVQIg-J2Gao",
        "outputId": "da6f2dc0-900a-483e-dd91-38c1bd822770"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V1\n",
            "Epoch : [0] Train loss : [0.2593641957002027] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.09207890581871782] Val Score : [0.6065088431643744])\n",
            "Epoch : [2] Train loss : [0.0870957872165101] Val Score : [0.9031202878275757])\n",
            "Epoch : [3] Train loss : [0.07211106989000525] Val Score : [0.856966968023358])\n",
            "Epoch : [4] Train loss : [0.0516464106206383] Val Score : [0.8041895926750926])\n",
            "Epoch : [5] Train loss : [0.04192636374916349] Val Score : [0.8682891659486169])\n",
            "Epoch : [6] Train loss : [0.04889251850545406] Val Score : [0.9165787375726882])\n",
            "Epoch : [7] Train loss : [0.03921990642057998] Val Score : [0.9034120550289857])\n",
            "Epoch : [8] Train loss : [0.049907365680805275] Val Score : [0.9165787375726882])\n",
            "Epoch : [9] Train loss : [0.03166851866990328] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.03039593289473227] Val Score : [0.899903286500554])\n",
            "Epoch : [11] Train loss : [0.03084025252610445] Val Score : [0.9097393418694286])\n",
            "Epoch : [12] Train loss : [0.04582328282828842] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.04977047336953027] Val Score : [0.8528093037014359])\n",
            "Epoch : [14] Train loss : [0.03802777773567608] Val Score : [0.9034120550289857])\n",
            "Epoch : [15] Train loss : [0.03226030897349119] Val Score : [0.9165787375726882])\n",
            "Epoch : [16] Train loss : [0.0354758192385946] Val Score : [0.7379018553027905])\n",
            "Epoch : [17] Train loss : [0.035512718105954785] Val Score : [0.8772441968135101])\n",
            "Epoch 00018: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [18] Train loss : [0.028340048821909086] Val Score : [0.8331926764657618])\n",
            "Epoch : [19] Train loss : [0.026575047256691114] Val Score : [0.8041895926750926])\n",
            "Epoch : [20] Train loss : [0.02432770494903837] Val Score : [0.8331926764657618])\n",
            "Epoch : [21] Train loss : [0.027096675442797796] Val Score : [0.7725514640071602])\n",
            "Epoch : [22] Train loss : [0.024780011469764367] Val Score : [0.8331926764657618])\n",
            "Epoch : [23] Train loss : [0.02365236516509737] Val Score : [0.7379018553027905])\n",
            "Epoch : [24] Train loss : [0.022397038792925223] Val Score : [0.5320032001215638])\n",
            "Epoch : [25] Train loss : [0.023840887205941335] Val Score : [0.562253919707516])\n",
            "Epoch : [26] Train loss : [0.021373925198401724] Val Score : [0.5320032001215638])\n",
            "Epoch : [27] Train loss : [0.025900688687605516] Val Score : [0.7887218676684034])\n",
            "Epoch : [28] Train loss : [0.02467309177986213] Val Score : [0.8331926764657618])\n",
            "Epoch 00029: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [29] Train loss : [0.022491557390562127] Val Score : [0.7379018553027905])\n",
            "Epoch : [30] Train loss : [0.022993782801287516] Val Score : [0.5320032001215638])\n",
            "Epoch : [31] Train loss : [0.022186658212116787] Val Score : [0.7887218676684034])\n",
            "Epoch : [32] Train loss : [0.02106010235313858] Val Score : [0.5320032001215638])\n",
            "Epoch : [33] Train loss : [0.02041998745075294] Val Score : [0.5320032001215638])\n",
            "Epoch : [34] Train loss : [0.020592023884611472] Val Score : [0.7437178496040009])\n",
            "Epoch : [35] Train loss : [0.020117298433823243] Val Score : [0.5320032001215638])\n",
            "Epoch : [36] Train loss : [0.02095392346382141] Val Score : [0.6426374167237955])\n",
            "Epoch : [37] Train loss : [0.02050983812659979] Val Score : [0.7379018553027905])\n",
            "Epoch : [38] Train loss : [0.020890959804611548] Val Score : [0.7725514640071602])\n",
            "Epoch : [39] Train loss : [0.0227303309366107] Val Score : [0.7437178496040009])\n",
            "Epoch 00040: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [40] Train loss : [0.01869359545941864] Val Score : [0.4997363518121419])\n",
            "Epoch : [41] Train loss : [0.020876994356513023] Val Score : [0.4997363518121419])\n",
            "Epoch : [42] Train loss : [0.020333760950182165] Val Score : [0.4997363518121419])\n",
            "Epoch : [43] Train loss : [0.01872368063777685] Val Score : [0.4997363518121419])\n",
            "Epoch : [44] Train loss : [0.019305618878986155] Val Score : [0.4997363518121419])\n",
            "Epoch : [45] Train loss : [0.01987014604466302] Val Score : [0.4997363518121419])\n",
            "Epoch : [46] Train loss : [0.018591293399887427] Val Score : [0.755629357577611])\n",
            "Epoch : [47] Train loss : [0.021590080511357104] Val Score : [0.4997363518121419])\n",
            "Epoch : [48] Train loss : [0.019765184660043036] Val Score : [0.4997363518121419])\n",
            "Epoch : [49] Train loss : [0.018536842428147793] Val Score : [0.7725514640071602])\n",
            "\n",
            "etc col : V1 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V2\n",
            "Epoch : [0] Train loss : [0.25087106068219456] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.10520070205841746] Val Score : [0.4589788964262114])\n",
            "Epoch : [2] Train loss : [0.07085731811821461] Val Score : [0.8470287373843977])\n",
            "Epoch : [3] Train loss : [0.06095320571746145] Val Score : [0.660365522073326])\n",
            "Epoch : [4] Train loss : [0.03825163096189499] Val Score : [0.872984830495149])\n",
            "Epoch : [5] Train loss : [0.047891023834901195] Val Score : [0.8967110829723166])\n",
            "Epoch : [6] Train loss : [0.048632303651954444] Val Score : [0.9165787375726882])\n",
            "Epoch : [7] Train loss : [0.04731066218976464] Val Score : [0.9165787375726882])\n",
            "Epoch : [8] Train loss : [0.04411358293145895] Val Score : [0.9097393418694286])\n",
            "Epoch : [9] Train loss : [0.029760759323835373] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.03385051353169339] Val Score : [0.8927516353661109])\n",
            "Epoch : [11] Train loss : [0.03834817425480911] Val Score : [0.9137051774467988])\n",
            "Epoch : [12] Train loss : [0.03167124265538795] Val Score : [0.872984830495149])\n",
            "Epoch : [13] Train loss : [0.03501438229743924] Val Score : [0.0035465233735341513])\n",
            "Epoch : [14] Train loss : [0.030465145329279558] Val Score : [0.9165787375726882])\n",
            "Epoch : [15] Train loss : [0.028479514244411672] Val Score : [0.8772441968135101])\n",
            "Epoch : [16] Train loss : [0.030691145254032954] Val Score : [0.9106263628050926])\n",
            "Epoch : [17] Train loss : [0.0282103099993297] Val Score : [0.899903286500554])\n",
            "Epoch 00018: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [18] Train loss : [0.02450452678437744] Val Score : [0.846806907378336])\n",
            "Epoch : [19] Train loss : [0.027987371464925154] Val Score : [0.846806907378336])\n",
            "Epoch : [20] Train loss : [0.023084500272359167] Val Score : [0.899903286500554])\n",
            "Epoch : [21] Train loss : [0.02601545849548919] Val Score : [0.9209734995691702])\n",
            "Epoch : [22] Train loss : [0.026729718382869447] Val Score : [0.9165787375726882])\n",
            "Epoch : [23] Train loss : [0.025582002076719488] Val Score : [0.9137051774467988])\n",
            "Epoch : [24] Train loss : [0.023110054965530123] Val Score : [0.9106263628050926])\n",
            "Epoch : [25] Train loss : [0.022491886812661375] Val Score : [0.8598769209128951])\n",
            "Epoch : [26] Train loss : [0.023082278003650054] Val Score : [0.8189994908759815])\n",
            "Epoch : [27] Train loss : [0.021743552227105414] Val Score : [0.899903286500554])\n",
            "Epoch : [28] Train loss : [0.02494207743023123] Val Score : [0.8598769209128951])\n",
            "Epoch : [29] Train loss : [0.026928133996469632] Val Score : [0.8887833851083367])\n",
            "Epoch : [30] Train loss : [0.034014033685837476] Val Score : [0.899903286500554])\n",
            "Epoch : [31] Train loss : [0.024645067618361542] Val Score : [0.8598769209128951])\n",
            "Epoch : [32] Train loss : [0.02363552020064422] Val Score : [0.8598769209128951])\n",
            "Epoch 00033: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [33] Train loss : [0.01892285993588822] Val Score : [0.8189994908759815])\n",
            "Epoch : [34] Train loss : [0.02065670277391161] Val Score : [0.7379018553027905])\n",
            "Epoch : [35] Train loss : [0.02363380670015301] Val Score : [0.7379018553027905])\n",
            "Epoch : [36] Train loss : [0.020118262485734055] Val Score : [0.8041895926750926])\n",
            "Epoch : [37] Train loss : [0.021056745467441424] Val Score : [0.755629357577611])\n",
            "Epoch : [38] Train loss : [0.02287230920046568] Val Score : [0.8041895926750926])\n",
            "Epoch : [39] Train loss : [0.021451693028211594] Val Score : [0.8189994908759815])\n",
            "Epoch : [40] Train loss : [0.020756199822894165] Val Score : [0.7379018553027905])\n",
            "Epoch : [41] Train loss : [0.020029136911034584] Val Score : [0.8041895926750926])\n",
            "Epoch : [42] Train loss : [0.020356383440749987] Val Score : [0.8041895926750926])\n",
            "Epoch : [43] Train loss : [0.020211436253573214] Val Score : [0.8041895926750926])\n",
            "Epoch 00044: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [44] Train loss : [0.01987501233816147] Val Score : [0.7379018553027905])\n",
            "Epoch : [45] Train loss : [0.0188406053930521] Val Score : [0.5320032001215638])\n",
            "Epoch : [46] Train loss : [0.018680659255811145] Val Score : [0.4997363518121419])\n",
            "Epoch : [47] Train loss : [0.018969174208385602] Val Score : [0.7437178496040009])\n",
            "Epoch : [48] Train loss : [0.01829557666288955] Val Score : [0.7887218676684034])\n",
            "Epoch : [49] Train loss : [0.018804216225232397] Val Score : [0.755629357577611])\n",
            "\n",
            "etc col : V2 / Marco F1 Score : 0.9209734995691702\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V5\n",
            "Epoch : [0] Train loss : [0.2145861562873636] Val Score : [0.5062698487969729])\n",
            "Epoch : [1] Train loss : [0.13852893188595772] Val Score : [0.8331926764657618])\n",
            "Epoch : [2] Train loss : [0.1235994387950216] Val Score : [0.0010529271374420891])\n",
            "Epoch : [3] Train loss : [0.10446503731821265] Val Score : [0.8652615319692264])\n",
            "Epoch : [4] Train loss : [0.07215037489576] Val Score : [0.8724347298745778])\n",
            "Epoch : [5] Train loss : [0.044997290042894225] Val Score : [0.9137051774467988])\n",
            "Epoch : [6] Train loss : [0.03803629680935826] Val Score : [0.8598769209128951])\n",
            "Epoch : [7] Train loss : [0.04728885340903487] Val Score : [0.9097393418694286])\n",
            "Epoch : [8] Train loss : [0.03784473652818373] Val Score : [0.9137051774467988])\n",
            "Epoch : [9] Train loss : [0.03336667109813009] Val Score : [0.9137051774467988])\n",
            "Epoch : [10] Train loss : [0.028840366218771254] Val Score : [0.8598769209128951])\n",
            "Epoch : [11] Train loss : [0.028622501928891455] Val Score : [0.9097393418694286])\n",
            "Epoch : [12] Train loss : [0.027781157488269464] Val Score : [0.8598769209128951])\n",
            "Epoch : [13] Train loss : [0.034574592752116065] Val Score : [0.9097393418694286])\n",
            "Epoch : [14] Train loss : [0.029021079252873148] Val Score : [0.8598769209128951])\n",
            "Epoch : [15] Train loss : [0.027962330728769302] Val Score : [0.846806907378336])\n",
            "Epoch : [16] Train loss : [0.03077751863747835] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.03221177549234459] Val Score : [0.9137051774467988])\n",
            "Epoch : [18] Train loss : [0.025896096735128334] Val Score : [0.9165787375726882])\n",
            "Epoch : [19] Train loss : [0.02578831637012107] Val Score : [0.8189994908759815])\n",
            "Epoch : [20] Train loss : [0.03680521555777107] Val Score : [0.9097393418694286])\n",
            "Epoch : [21] Train loss : [0.025550621960844313] Val Score : [0.8927516353661109])\n",
            "Epoch : [22] Train loss : [0.02734070923179388] Val Score : [0.8772441968135101])\n",
            "Epoch : [23] Train loss : [0.03128668798932007] Val Score : [0.8887833851083367])\n",
            "Epoch : [24] Train loss : [0.02395474218896457] Val Score : [0.8927516353661109])\n",
            "Epoch : [25] Train loss : [0.025419877842068672] Val Score : [0.9137051774467988])\n",
            "Epoch : [26] Train loss : [0.023330738634935448] Val Score : [0.8598769209128951])\n",
            "Epoch : [27] Train loss : [0.025711686217359135] Val Score : [0.8189994908759815])\n",
            "Epoch 00028: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [28] Train loss : [0.021011277234980037] Val Score : [0.8041895926750926])\n",
            "Epoch : [29] Train loss : [0.020800354358341013] Val Score : [0.8041895926750926])\n",
            "Epoch : [30] Train loss : [0.02016768617821591] Val Score : [0.7437178496040009])\n",
            "Epoch : [31] Train loss : [0.019101063454789773] Val Score : [0.7887218676684034])\n",
            "Epoch : [32] Train loss : [0.017839506002409116] Val Score : [0.755629357577611])\n",
            "Epoch : [33] Train loss : [0.01858897680150611] Val Score : [0.8041895926750926])\n",
            "Epoch : [34] Train loss : [0.01992611028254032] Val Score : [0.8041895926750926])\n",
            "Epoch : [35] Train loss : [0.020044298177318915] Val Score : [0.7379018553027905])\n",
            "Epoch : [36] Train loss : [0.020949154560055052] Val Score : [0.8041895926750926])\n",
            "Epoch : [37] Train loss : [0.018080878869763443] Val Score : [0.7887218676684034])\n",
            "Epoch : [38] Train loss : [0.01776787851537977] Val Score : [0.755629357577611])\n",
            "Epoch 00039: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [39] Train loss : [0.019855440727302005] Val Score : [0.7379018553027905])\n",
            "Epoch : [40] Train loss : [0.018397032682384764] Val Score : [0.7725514640071602])\n",
            "Epoch : [41] Train loss : [0.01699168168540512] Val Score : [0.755629357577611])\n",
            "Epoch : [42] Train loss : [0.01785322731094701] Val Score : [0.562253919707516])\n",
            "Epoch : [43] Train loss : [0.01773797973458256] Val Score : [0.7248066240067507])\n",
            "Epoch : [44] Train loss : [0.01849855123353856] Val Score : [0.7248066240067507])\n",
            "Epoch : [45] Train loss : [0.0173354766198567] Val Score : [0.755629357577611])\n",
            "Epoch : [46] Train loss : [0.017346194945275784] Val Score : [0.7379018553027905])\n",
            "Epoch : [47] Train loss : [0.01639825983771256] Val Score : [0.6664557258707168])\n",
            "Epoch : [48] Train loss : [0.01627093566847699] Val Score : [0.7379018553027905])\n",
            "Epoch : [49] Train loss : [0.016111267131886313] Val Score : [0.755629357577611])\n",
            "Epoch 00050: reducing learning rate of group 0 to 1.2500e-03.\n",
            "\n",
            "etc col : V5 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V6\n",
            "Epoch : [0] Train loss : [0.2473738534109933] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.11709832453301974] Val Score : [0.0010529271374420891])\n",
            "Epoch : [2] Train loss : [0.08327332724417959] Val Score : [0.3790291916510269])\n",
            "Epoch : [3] Train loss : [0.0722912246627467] Val Score : [0.899903286500554])\n",
            "Epoch : [4] Train loss : [0.05315521492489746] Val Score : [0.9034120550289857])\n",
            "Epoch : [5] Train loss : [0.043096295690962245] Val Score : [0.8598769209128951])\n",
            "Epoch : [6] Train loss : [0.04554603328662259] Val Score : [0.9165787375726882])\n",
            "Epoch : [7] Train loss : [0.046364717451589446] Val Score : [0.9097393418694286])\n",
            "Epoch : [8] Train loss : [0.03247072973421642] Val Score : [0.8887833851083367])\n",
            "Epoch : [9] Train loss : [0.031002292010400976] Val Score : [0.9137051774467988])\n",
            "Epoch : [10] Train loss : [0.028317498974502087] Val Score : [0.9034120550289857])\n",
            "Epoch : [11] Train loss : [0.02941457767571722] Val Score : [0.9165787375726882])\n",
            "Epoch : [12] Train loss : [0.03218438316668783] Val Score : [0.9137051774467988])\n",
            "Epoch : [13] Train loss : [0.037110276121113984] Val Score : [0.9165787375726882])\n",
            "Epoch : [14] Train loss : [0.0273860969713756] Val Score : [0.8598769209128951])\n",
            "Epoch : [15] Train loss : [0.03654788687293019] Val Score : [0.9137051774467988])\n",
            "Epoch : [16] Train loss : [0.030290533788502216] Val Score : [0.8331926764657618])\n",
            "Epoch : [17] Train loss : [0.029367830737360885] Val Score : [0.9137051774467988])\n",
            "Epoch 00018: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [18] Train loss : [0.026089740517948354] Val Score : [0.899903286500554])\n",
            "Epoch : [19] Train loss : [0.022622871611799513] Val Score : [0.8927516353661109])\n",
            "Epoch : [20] Train loss : [0.03012944624892303] Val Score : [0.8598769209128951])\n",
            "Epoch : [21] Train loss : [0.029870488015668734] Val Score : [0.9165787375726882])\n",
            "Epoch : [22] Train loss : [0.03242293865020786] Val Score : [0.899903286500554])\n",
            "Epoch : [23] Train loss : [0.02828265699957098] Val Score : [0.8927516353661109])\n",
            "Epoch : [24] Train loss : [0.025703854326690947] Val Score : [0.8772441968135101])\n",
            "Epoch : [25] Train loss : [0.023492115549743176] Val Score : [0.899903286500554])\n",
            "Epoch : [26] Train loss : [0.023048407531210353] Val Score : [0.8041895926750926])\n",
            "Epoch : [27] Train loss : [0.026513739622064998] Val Score : [0.8598769209128951])\n",
            "Epoch : [28] Train loss : [0.023539658901946887] Val Score : [0.8598769209128951])\n",
            "Epoch 00029: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [29] Train loss : [0.02193010545202664] Val Score : [0.8041895926750926])\n",
            "Epoch : [30] Train loss : [0.020143579159464155] Val Score : [0.8598769209128951])\n",
            "Epoch : [31] Train loss : [0.01962309144437313] Val Score : [0.8041895926750926])\n",
            "Epoch : [32] Train loss : [0.02156936377286911] Val Score : [0.755629357577611])\n",
            "Epoch : [33] Train loss : [0.019929604338748113] Val Score : [0.7379018553027905])\n",
            "Epoch : [34] Train loss : [0.018734948576561043] Val Score : [0.7725514640071602])\n",
            "Epoch : [35] Train loss : [0.01896416688604014] Val Score : [0.8041895926750926])\n",
            "Epoch : [36] Train loss : [0.018982787749597003] Val Score : [0.755629357577611])\n",
            "Epoch : [37] Train loss : [0.01905146028314318] Val Score : [0.755629357577611])\n",
            "Epoch : [38] Train loss : [0.018616173549422195] Val Score : [0.846806907378336])\n",
            "Epoch : [39] Train loss : [0.01954657318336623] Val Score : [0.8189994908759815])\n",
            "Epoch 00040: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [40] Train loss : [0.018400614415960654] Val Score : [0.7379018553027905])\n",
            "Epoch : [41] Train loss : [0.018931853584945202] Val Score : [0.7379018553027905])\n",
            "Epoch : [42] Train loss : [0.018074478022754192] Val Score : [0.7103329465949443])\n",
            "Epoch : [43] Train loss : [0.01796144579670259] Val Score : [0.7887218676684034])\n",
            "Epoch : [44] Train loss : [0.01922026582594429] Val Score : [0.755629357577611])\n",
            "Epoch : [45] Train loss : [0.017820119192557677] Val Score : [0.7379018553027905])\n",
            "Epoch : [46] Train loss : [0.019343463038759574] Val Score : [0.562253919707516])\n",
            "Epoch : [47] Train loss : [0.018184709894870008] Val Score : [0.6889870340395065])\n",
            "Epoch : [48] Train loss : [0.018189767641680583] Val Score : [0.5320032001215638])\n",
            "Epoch : [49] Train loss : [0.018704294227063656] Val Score : [0.7725514640071602])\n",
            "\n",
            "etc col : V6 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V7\n",
            "Epoch : [0] Train loss : [0.23305892146059445] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.11678478946643216] Val Score : [0.035757459829023105])\n",
            "Epoch : [2] Train loss : [0.07715763550783906] Val Score : [0.8598769209128951])\n",
            "Epoch : [3] Train loss : [0.07888467157525676] Val Score : [0.9034120550289857])\n",
            "Epoch : [4] Train loss : [0.04729061866445201] Val Score : [0.899903286500554])\n",
            "Epoch : [5] Train loss : [0.039886193349957466] Val Score : [0.8927516353661109])\n",
            "Epoch : [6] Train loss : [0.045380910858511925] Val Score : [0.14817490649326068])\n",
            "Epoch : [7] Train loss : [0.03604618566376822] Val Score : [0.9137051774467988])\n",
            "Epoch : [8] Train loss : [0.03581032968525376] Val Score : [0.9165787375726882])\n",
            "Epoch : [9] Train loss : [0.030669356297169412] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.028433648204164847] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.029954605735838413] Val Score : [0.9165787375726882])\n",
            "Epoch : [12] Train loss : [0.026058738252946308] Val Score : [0.8189994908759815])\n",
            "Epoch : [13] Train loss : [0.026758480151849135] Val Score : [0.9137051774467988])\n",
            "Epoch : [14] Train loss : [0.027704114626560892] Val Score : [0.9137051774467988])\n",
            "Epoch : [15] Train loss : [0.03229360681559358] Val Score : [0.899903286500554])\n",
            "Epoch : [16] Train loss : [0.037772124633193016] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.04229836405387947] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.032924506946333816] Val Score : [0.9165787375726882])\n",
            "Epoch : [19] Train loss : [0.030809506374810423] Val Score : [0.9165787375726882])\n",
            "Epoch 00020: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [20] Train loss : [0.03210254332848957] Val Score : [0.8927516353661109])\n",
            "Epoch : [21] Train loss : [0.02483737442110266] Val Score : [0.8041895926750926])\n",
            "Epoch : [22] Train loss : [0.022280546836555004] Val Score : [0.8528093037014359])\n",
            "Epoch : [23] Train loss : [0.023011636787227223] Val Score : [0.8927516353661109])\n",
            "Epoch : [24] Train loss : [0.02225648279168776] Val Score : [0.8598769209128951])\n",
            "Epoch : [25] Train loss : [0.028347195791346685] Val Score : [0.8598769209128951])\n",
            "Epoch : [26] Train loss : [0.020192986620324] Val Score : [0.9137051774467988])\n",
            "Epoch : [27] Train loss : [0.02253403341663735] Val Score : [0.899903286500554])\n",
            "Epoch : [28] Train loss : [0.02195692528039217] Val Score : [0.9137051774467988])\n",
            "Epoch : [29] Train loss : [0.02416226440774543] Val Score : [0.8927516353661109])\n",
            "Epoch : [30] Train loss : [0.022469006744878634] Val Score : [0.8652615319692264])\n",
            "Epoch 00031: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [31] Train loss : [0.02094064386827605] Val Score : [0.8331926764657618])\n",
            "Epoch : [32] Train loss : [0.019253244756587913] Val Score : [0.8189994908759815])\n",
            "Epoch : [33] Train loss : [0.019096427730151584] Val Score : [0.8331926764657618])\n",
            "Epoch : [34] Train loss : [0.018852569295891693] Val Score : [0.8331926764657618])\n",
            "Epoch : [35] Train loss : [0.01965294698519366] Val Score : [0.7725514640071602])\n",
            "Epoch : [36] Train loss : [0.018913134799471924] Val Score : [0.8331926764657618])\n",
            "Epoch : [37] Train loss : [0.01911606440054519] Val Score : [0.7887218676684034])\n",
            "Epoch : [38] Train loss : [0.019270690956286023] Val Score : [0.8331926764657618])\n",
            "Epoch : [39] Train loss : [0.018695584099207605] Val Score : [0.8331926764657618])\n",
            "Epoch : [40] Train loss : [0.019555887473481044] Val Score : [0.8331926764657618])\n",
            "Epoch : [41] Train loss : [0.019184645265340805] Val Score : [0.755629357577611])\n",
            "Epoch 00042: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [42] Train loss : [0.018315105033772334] Val Score : [0.7437178496040009])\n",
            "Epoch : [43] Train loss : [0.017590029564286982] Val Score : [0.7887218676684034])\n",
            "Epoch : [44] Train loss : [0.017575635308665887] Val Score : [0.7498242036425005])\n",
            "Epoch : [45] Train loss : [0.017897565050848892] Val Score : [0.755629357577611])\n",
            "Epoch : [46] Train loss : [0.017596740807805742] Val Score : [0.562253919707516])\n",
            "Epoch : [47] Train loss : [0.0175761061587504] Val Score : [0.4997363518121419])\n",
            "Epoch : [48] Train loss : [0.017526484626744474] Val Score : [0.7887218676684034])\n",
            "Epoch : [49] Train loss : [0.017356534621545246] Val Score : [0.7379018553027905])\n",
            "\n",
            "etc col : V7 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V8\n",
            "Epoch : [0] Train loss : [0.22588040200727327] Val Score : [0.755629357577611])\n",
            "Epoch : [1] Train loss : [0.129448409059218] Val Score : [0.9236496787663914])\n",
            "Epoch : [2] Train loss : [0.10887360546205725] Val Score : [0.7379018553027905])\n",
            "Epoch : [3] Train loss : [0.0624755857778447] Val Score : [0.9236496787663914])\n",
            "Epoch : [4] Train loss : [0.037322936712631156] Val Score : [0.9236496787663914])\n",
            "Epoch : [5] Train loss : [0.036955711032663076] Val Score : [0.9137051774467988])\n",
            "Epoch : [6] Train loss : [0.032409753783472946] Val Score : [0.9165787375726882])\n",
            "Epoch : [7] Train loss : [0.03336078194635255] Val Score : [0.8041895926750926])\n",
            "Epoch : [8] Train loss : [0.03103624896279403] Val Score : [0.7887218676684034])\n",
            "Epoch : [9] Train loss : [0.03435892492000546] Val Score : [0.8331926764657618])\n",
            "Epoch : [10] Train loss : [0.03672256054622786] Val Score : [0.8041895926750926])\n",
            "Epoch : [11] Train loss : [0.04000128659286669] Val Score : [0.8887833851083367])\n",
            "Epoch : [12] Train loss : [0.03688241567994867] Val Score : [0.8331926764657618])\n",
            "Epoch 00013: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [13] Train loss : [0.033416424212711196] Val Score : [0.7379018553027905])\n",
            "Epoch : [14] Train loss : [0.02705256893698658] Val Score : [0.7379018553027905])\n",
            "Epoch : [15] Train loss : [0.032454842435462136] Val Score : [0.8331926764657618])\n",
            "Epoch : [16] Train loss : [0.03104383192424263] Val Score : [0.8041895926750926])\n",
            "Epoch : [17] Train loss : [0.02891883174223559] Val Score : [0.8041895926750926])\n",
            "Epoch : [18] Train loss : [0.03214409588170903] Val Score : [0.7379018553027905])\n",
            "Epoch : [19] Train loss : [0.03002785119627203] Val Score : [0.7379018553027905])\n",
            "Epoch : [20] Train loss : [0.027728776846613203] Val Score : [0.755629357577611])\n",
            "Epoch : [21] Train loss : [0.0299754532586251] Val Score : [0.8041895926750926])\n",
            "Epoch : [22] Train loss : [0.026597109091069018] Val Score : [0.8331926764657618])\n",
            "Epoch : [23] Train loss : [0.026778815580265864] Val Score : [0.7379018553027905])\n",
            "Epoch 00024: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [24] Train loss : [0.026354036426969936] Val Score : [0.5320032001215638])\n",
            "Epoch : [25] Train loss : [0.02475961670279503] Val Score : [0.4997363518121419])\n",
            "Epoch : [26] Train loss : [0.023682958180350915] Val Score : [0.562253919707516])\n",
            "Epoch : [27] Train loss : [0.021052377564566477] Val Score : [0.755629357577611])\n",
            "Epoch : [28] Train loss : [0.020925498301429406] Val Score : [0.562253919707516])\n",
            "Epoch : [29] Train loss : [0.02212424057402781] Val Score : [0.4997363518121419])\n",
            "Epoch : [30] Train loss : [0.021322015007691725] Val Score : [0.4997363518121419])\n",
            "Epoch : [31] Train loss : [0.020978380792907307] Val Score : [0.4997363518121419])\n",
            "Epoch : [32] Train loss : [0.02262971576835428] Val Score : [0.4997363518121419])\n",
            "Epoch : [33] Train loss : [0.022741431104285375] Val Score : [0.4997363518121419])\n",
            "Epoch : [34] Train loss : [0.02399128595633166] Val Score : [0.6839995781035756])\n",
            "Epoch 00035: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [35] Train loss : [0.021882832183369567] Val Score : [0.4997363518121419])\n",
            "Epoch : [36] Train loss : [0.020384866079049452] Val Score : [0.7437178496040009])\n",
            "Epoch : [37] Train loss : [0.0212290690147451] Val Score : [0.7049260428710196])\n",
            "Epoch : [38] Train loss : [0.019479384512773583] Val Score : [0.4997363518121419])\n",
            "Epoch : [39] Train loss : [0.02040401047893933] Val Score : [0.4997363518121419])\n",
            "Epoch : [40] Train loss : [0.019883003751082078] Val Score : [0.4997363518121419])\n",
            "Epoch : [41] Train loss : [0.02092243611280407] Val Score : [0.4997363518121419])\n",
            "Epoch : [42] Train loss : [0.019801810516842773] Val Score : [0.4997363518121419])\n",
            "Epoch : [43] Train loss : [0.019688105742846216] Val Score : [0.4997363518121419])\n",
            "Epoch : [44] Train loss : [0.02101066961352314] Val Score : [0.4997363518121419])\n",
            "Epoch : [45] Train loss : [0.019073557374732836] Val Score : [0.4997363518121419])\n",
            "Epoch 00046: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [46] Train loss : [0.01985542755573988] Val Score : [0.4997363518121419])\n",
            "Epoch : [47] Train loss : [0.021327513669218336] Val Score : [0.4997363518121419])\n",
            "Epoch : [48] Train loss : [0.019188677093812397] Val Score : [0.4997363518121419])\n",
            "Epoch : [49] Train loss : [0.019435920619538853] Val Score : [0.4997363518121419])\n",
            "\n",
            "etc col : V8 / Marco F1 Score : 0.9236496787663914\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V13\n",
            "Epoch : [0] Train loss : [0.23019428444760187] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.12475859293980258] Val Score : [0.6067386435725407])\n",
            "Epoch : [2] Train loss : [0.0832366192979472] Val Score : [0.7196466561760486])\n",
            "Epoch : [3] Train loss : [0.06867017091384955] Val Score : [0.755629357577611])\n",
            "Epoch : [4] Train loss : [0.051716431443180354] Val Score : [0.9165787375726882])\n",
            "Epoch : [5] Train loss : [0.04129446085010256] Val Score : [0.755629357577611])\n",
            "Epoch : [6] Train loss : [0.037281145341694355] Val Score : [0.7725514640071602])\n",
            "Epoch : [7] Train loss : [0.03891422546335629] Val Score : [0.8189994908759815])\n",
            "Epoch : [8] Train loss : [0.036115934274026325] Val Score : [0.8189994908759815])\n",
            "Epoch : [9] Train loss : [0.040298319953892915] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.037264538263635974] Val Score : [0.8331926764657618])\n",
            "Epoch : [11] Train loss : [0.03558897506445646] Val Score : [0.8189994908759815])\n",
            "Epoch : [12] Train loss : [0.03876627955053534] Val Score : [0.8331926764657618])\n",
            "Epoch : [13] Train loss : [0.028612975430275713] Val Score : [0.7379018553027905])\n",
            "Epoch : [14] Train loss : [0.028982109257153103] Val Score : [0.8041895926750926])\n",
            "Epoch : [15] Train loss : [0.03613566407667739] Val Score : [0.8652615319692264])\n",
            "Epoch 00016: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [16] Train loss : [0.027886400797537396] Val Score : [0.7379018553027905])\n",
            "Epoch : [17] Train loss : [0.025530601452503885] Val Score : [0.8189994908759815])\n",
            "Epoch : [18] Train loss : [0.02614324739468949] Val Score : [0.8598769209128951])\n",
            "Epoch : [19] Train loss : [0.026051009073853493] Val Score : [0.7379018553027905])\n",
            "Epoch : [20] Train loss : [0.03054622041859797] Val Score : [0.7437178496040009])\n",
            "Epoch : [21] Train loss : [0.027742366439529827] Val Score : [0.8041895926750926])\n",
            "Epoch : [22] Train loss : [0.024464260653725693] Val Score : [0.7248066240067507])\n",
            "Epoch : [23] Train loss : [0.02543749793299607] Val Score : [0.8041895926750926])\n",
            "Epoch : [24] Train loss : [0.025595007597335746] Val Score : [0.7437178496040009])\n",
            "Epoch : [25] Train loss : [0.025731750098722323] Val Score : [0.7887218676684034])\n",
            "Epoch : [26] Train loss : [0.02436818727957351] Val Score : [0.7887218676684034])\n",
            "Epoch 00027: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [27] Train loss : [0.023266815846519812] Val Score : [0.7248066240067507])\n",
            "Epoch : [28] Train loss : [0.02332194588546242] Val Score : [0.4997363518121419])\n",
            "Epoch : [29] Train loss : [0.02267047869307654] Val Score : [0.5320032001215638])\n",
            "Epoch : [30] Train loss : [0.023680626547762325] Val Score : [0.7379018553027905])\n",
            "Epoch : [31] Train loss : [0.023650649136730602] Val Score : [0.7437178496040009])\n",
            "Epoch : [32] Train loss : [0.022596198799354688] Val Score : [0.7379018553027905])\n",
            "Epoch : [33] Train loss : [0.02225660745586668] Val Score : [0.4997363518121419])\n",
            "Epoch : [34] Train loss : [0.022603989312691346] Val Score : [0.7498242036425005])\n",
            "Epoch : [35] Train loss : [0.02229323623968022] Val Score : [0.5320032001215638])\n",
            "Epoch : [36] Train loss : [0.022611282765865326] Val Score : [0.5320032001215638])\n",
            "Epoch : [37] Train loss : [0.022673278248735836] Val Score : [0.7379018553027905])\n",
            "Epoch 00038: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [38] Train loss : [0.021402171812951565] Val Score : [0.4997363518121419])\n",
            "Epoch : [39] Train loss : [0.02087370732000896] Val Score : [0.4997363518121419])\n",
            "Epoch : [40] Train loss : [0.02060168595718486] Val Score : [0.4997363518121419])\n",
            "Epoch : [41] Train loss : [0.020348484893994673] Val Score : [0.4997363518121419])\n",
            "Epoch : [42] Train loss : [0.02105532865971327] Val Score : [0.4997363518121419])\n",
            "Epoch : [43] Train loss : [0.021335992562983717] Val Score : [0.4997363518121419])\n",
            "Epoch : [44] Train loss : [0.02043750642665795] Val Score : [0.4997363518121419])\n",
            "Epoch : [45] Train loss : [0.020806835565183843] Val Score : [0.4997363518121419])\n",
            "Epoch : [46] Train loss : [0.021049186188195432] Val Score : [0.4997363518121419])\n",
            "Epoch : [47] Train loss : [0.02113161515444517] Val Score : [0.4997363518121419])\n",
            "Epoch : [48] Train loss : [0.020776703554604734] Val Score : [0.4997363518121419])\n",
            "Epoch 00049: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [49] Train loss : [0.020216846705547402] Val Score : [0.4997363518121419])\n",
            "\n",
            "etc col : V13 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V15\n",
            "Epoch : [0] Train loss : [0.23028402190123284] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.08244443392114979] Val Score : [0.4774466005699928])\n",
            "Epoch : [2] Train loss : [0.08824635297060013] Val Score : [0.7379018553027905])\n",
            "Epoch : [3] Train loss : [0.05637555143662861] Val Score : [0.9137051774467988])\n",
            "Epoch : [4] Train loss : [0.05220473477882998] Val Score : [0.9066829407144783])\n",
            "Epoch : [5] Train loss : [0.04066987668297121] Val Score : [0.19988752782621358])\n",
            "Epoch : [6] Train loss : [0.04357381391205958] Val Score : [0.9165787375726882])\n",
            "Epoch : [7] Train loss : [0.03962821380368301] Val Score : [0.9165787375726882])\n",
            "Epoch : [8] Train loss : [0.044151329435408115] Val Score : [0.9066829407144783])\n",
            "Epoch : [9] Train loss : [0.035019761483584134] Val Score : [0.8927516353661109])\n",
            "Epoch : [10] Train loss : [0.03109219005065305] Val Score : [0.899903286500554])\n",
            "Epoch : [11] Train loss : [0.037849427733038156] Val Score : [0.9137051774467988])\n",
            "Epoch : [12] Train loss : [0.03647229181868689] Val Score : [0.8041895926750926])\n",
            "Epoch : [13] Train loss : [0.029190067867083207] Val Score : [0.9034120550289857])\n",
            "Epoch : [14] Train loss : [0.028040877809481963] Val Score : [0.8927516353661109])\n",
            "Epoch : [15] Train loss : [0.039777419795947414] Val Score : [0.899903286500554])\n",
            "Epoch : [16] Train loss : [0.03174845821091107] Val Score : [0.846806907378336])\n",
            "Epoch : [17] Train loss : [0.033770465957266946] Val Score : [0.9137051774467988])\n",
            "Epoch 00018: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [18] Train loss : [0.027222266287675927] Val Score : [0.8331926764657618])\n",
            "Epoch : [19] Train loss : [0.030499590826886042] Val Score : [0.899903286500554])\n",
            "Epoch : [20] Train loss : [0.02409866571958576] Val Score : [0.8331926764657618])\n",
            "Epoch : [21] Train loss : [0.025048429146409035] Val Score : [0.7725514640071602])\n",
            "Epoch : [22] Train loss : [0.023809642397931645] Val Score : [0.8331926764657618])\n",
            "Epoch : [23] Train loss : [0.024589672684669495] Val Score : [0.7725514640071602])\n",
            "Epoch : [24] Train loss : [0.023032328646097864] Val Score : [0.8041895926750926])\n",
            "Epoch : [25] Train loss : [0.02265757229179144] Val Score : [0.846806907378336])\n",
            "Epoch : [26] Train loss : [0.021789460709052428] Val Score : [0.8189994908759815])\n",
            "Epoch : [27] Train loss : [0.02576408428805215] Val Score : [0.7887218676684034])\n",
            "Epoch : [28] Train loss : [0.022572369181684086] Val Score : [0.755629357577611])\n",
            "Epoch 00029: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [29] Train loss : [0.021478496491909027] Val Score : [0.846806907378336])\n",
            "Epoch : [30] Train loss : [0.022786307414727553] Val Score : [0.8041895926750926])\n",
            "Epoch : [31] Train loss : [0.020531627615647658] Val Score : [0.7887218676684034])\n",
            "Epoch : [32] Train loss : [0.02479418194187539] Val Score : [0.755629357577611])\n",
            "Epoch : [33] Train loss : [0.02147307193705014] Val Score : [0.7248066240067507])\n",
            "Epoch : [34] Train loss : [0.02062118665448257] Val Score : [0.8189994908759815])\n",
            "Epoch : [35] Train loss : [0.02127861018691744] Val Score : [0.7725514640071602])\n",
            "Epoch : [36] Train loss : [0.02057900931686163] Val Score : [0.8041895926750926])\n",
            "Epoch : [37] Train loss : [0.02053790499589273] Val Score : [0.755629357577611])\n",
            "Epoch : [38] Train loss : [0.020645704519535815] Val Score : [0.8331926764657618])\n",
            "Epoch : [39] Train loss : [0.020374963326113566] Val Score : [0.7379018553027905])\n",
            "Epoch 00040: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [40] Train loss : [0.02075213273721082] Val Score : [0.7887218676684034])\n",
            "Epoch : [41] Train loss : [0.019491584838501046] Val Score : [0.8041895926750926])\n",
            "Epoch : [42] Train loss : [0.018794873463256017] Val Score : [0.7379018553027905])\n",
            "Epoch : [43] Train loss : [0.019412068650126457] Val Score : [0.5320032001215638])\n",
            "Epoch : [44] Train loss : [0.019027366835091795] Val Score : [0.562253919707516])\n",
            "Epoch : [45] Train loss : [0.019945100748113224] Val Score : [0.6426374167237955])\n",
            "Epoch : [46] Train loss : [0.020265764689871242] Val Score : [0.7437178496040009])\n",
            "Epoch : [47] Train loss : [0.019425532381449426] Val Score : [0.5320032001215638])\n",
            "Epoch : [48] Train loss : [0.019438276067376137] Val Score : [0.4997363518121419])\n",
            "Epoch : [49] Train loss : [0.01940986407654626] Val Score : [0.562253919707516])\n",
            "\n",
            "etc col : V15 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V19\n",
            "Epoch : [0] Train loss : [0.2943721551980291] Val Score : [0.14487900006703597])\n",
            "Epoch : [1] Train loss : [0.1290840996163232] Val Score : [0.4743265627339058])\n",
            "Epoch : [2] Train loss : [0.1081185843795538] Val Score : [0.0010529271374420891])\n",
            "Epoch : [3] Train loss : [0.06047486061496394] Val Score : [0.9137051774467988])\n",
            "Epoch : [4] Train loss : [0.05009724332817963] Val Score : [0.8598769209128951])\n",
            "Epoch : [5] Train loss : [0.04996343861733164] Val Score : [0.9165787375726882])\n",
            "Epoch : [6] Train loss : [0.04219620807894638] Val Score : [0.7725514640071602])\n",
            "Epoch : [7] Train loss : [0.0359994876863701] Val Score : [0.8652615319692264])\n",
            "Epoch : [8] Train loss : [0.033556632298444] Val Score : [0.8927516353661109])\n",
            "Epoch : [9] Train loss : [0.04116205112742526] Val Score : [0.8041895926750926])\n",
            "Epoch : [10] Train loss : [0.03202616476586887] Val Score : [0.8041895926750926])\n",
            "Epoch : [11] Train loss : [0.033076854688780646] Val Score : [0.8927516353661109])\n",
            "Epoch : [12] Train loss : [0.035936810209282806] Val Score : [0.8189994908759815])\n",
            "Epoch : [13] Train loss : [0.034926479549280236] Val Score : [0.8189994908759815])\n",
            "Epoch : [14] Train loss : [0.033180172954286845] Val Score : [0.8041895926750926])\n",
            "Epoch : [15] Train loss : [0.0342419066333345] Val Score : [0.846806907378336])\n",
            "Epoch : [16] Train loss : [0.035997409905706136] Val Score : [0.8528093037014359])\n",
            "Epoch 00017: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [17] Train loss : [0.025392921242330755] Val Score : [0.8189994908759815])\n",
            "Epoch : [18] Train loss : [0.025891979091933796] Val Score : [0.7887218676684034])\n",
            "Epoch : [19] Train loss : [0.02605034171470574] Val Score : [0.7887218676684034])\n",
            "Epoch : [20] Train loss : [0.025845541219626154] Val Score : [0.7725514640071602])\n",
            "Epoch : [21] Train loss : [0.027259834110736847] Val Score : [0.755629357577611])\n",
            "Epoch : [22] Train loss : [0.028134571920548166] Val Score : [0.8189994908759815])\n",
            "Epoch : [23] Train loss : [0.026135098322161605] Val Score : [0.8041895926750926])\n",
            "Epoch : [24] Train loss : [0.025316831788846424] Val Score : [0.7379018553027905])\n",
            "Epoch : [25] Train loss : [0.025287961587309837] Val Score : [0.7379018553027905])\n",
            "Epoch : [26] Train loss : [0.026229520993573324] Val Score : [0.7379018553027905])\n",
            "Epoch : [27] Train loss : [0.025128791773957864] Val Score : [0.755629357577611])\n",
            "Epoch 00028: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [28] Train loss : [0.02208420421395983] Val Score : [0.7379018553027905])\n",
            "Epoch : [29] Train loss : [0.022006376247320856] Val Score : [0.5906717950274928])\n",
            "Epoch : [30] Train loss : [0.02375760953873396] Val Score : [0.7498242036425005])\n",
            "Epoch : [31] Train loss : [0.021215849023844515] Val Score : [0.4997363518121419])\n",
            "Epoch : [32] Train loss : [0.023006846463041648] Val Score : [0.4997363518121419])\n",
            "Epoch : [33] Train loss : [0.024935565356697355] Val Score : [0.4997363518121419])\n",
            "Epoch : [34] Train loss : [0.02321161875235183] Val Score : [0.5906717950274928])\n",
            "Epoch : [35] Train loss : [0.020830526016652584] Val Score : [0.7103329465949443])\n",
            "Epoch : [36] Train loss : [0.0214763857158167] Val Score : [0.6174185476616381])\n",
            "Epoch : [37] Train loss : [0.02092808684600251] Val Score : [0.4997363518121419])\n",
            "Epoch : [38] Train loss : [0.02032641214983804] Val Score : [0.4997363518121419])\n",
            "Epoch 00039: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [39] Train loss : [0.02112808371228831] Val Score : [0.6426374167237955])\n",
            "Epoch : [40] Train loss : [0.02144201805016824] Val Score : [0.5906717950274928])\n",
            "Epoch : [41] Train loss : [0.020102869054036483] Val Score : [0.5906717950274928])\n",
            "Epoch : [42] Train loss : [0.020015933950032507] Val Score : [0.4997363518121419])\n",
            "Epoch : [43] Train loss : [0.019913934836430208] Val Score : [0.4997363518121419])\n",
            "Epoch : [44] Train loss : [0.019553166015871933] Val Score : [0.4997363518121419])\n",
            "Epoch : [45] Train loss : [0.019867556435721263] Val Score : [0.4997363518121419])\n",
            "Epoch : [46] Train loss : [0.019802408692027842] Val Score : [0.4997363518121419])\n",
            "Epoch : [47] Train loss : [0.019993086345493793] Val Score : [0.4997363518121419])\n",
            "Epoch : [48] Train loss : [0.019724511275334016] Val Score : [0.4997363518121419])\n",
            "Epoch : [49] Train loss : [0.019974184754703726] Val Score : [0.4997363518121419])\n",
            "Epoch 00050: reducing learning rate of group 0 to 6.2500e-04.\n",
            "\n",
            "etc col : V19 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V20\n",
            "Epoch : [0] Train loss : [0.22472347106252397] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.1374129748770169] Val Score : [0.09765746684129625])\n",
            "Epoch : [2] Train loss : [0.05884174470390592] Val Score : [0.1799667334448262])\n",
            "Epoch : [3] Train loss : [0.04520758906645434] Val Score : [0.8244378451249526])\n",
            "Epoch : [4] Train loss : [0.04026977132473673] Val Score : [0.9165787375726882])\n",
            "Epoch : [5] Train loss : [0.03366991278848478] Val Score : [0.8331926764657618])\n",
            "Epoch : [6] Train loss : [0.03883925931794303] Val Score : [0.755629357577611])\n",
            "Epoch : [7] Train loss : [0.06003736411886556] Val Score : [0.9165787375726882])\n",
            "Epoch : [8] Train loss : [0.037877150545162816] Val Score : [0.8927516353661109])\n",
            "Epoch : [9] Train loss : [0.03411694589470114] Val Score : [0.7379018553027905])\n",
            "Epoch : [10] Train loss : [0.03655425153140511] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.03511383956564324] Val Score : [0.7887218676684034])\n",
            "Epoch : [12] Train loss : [0.029842950270644257] Val Score : [0.8331926764657618])\n",
            "Epoch : [13] Train loss : [0.031397068207817416] Val Score : [0.9034120550289857])\n",
            "Epoch : [14] Train loss : [0.033079487936837335] Val Score : [0.7379018553027905])\n",
            "Epoch : [15] Train loss : [0.03511392617864268] Val Score : [0.8041895926750926])\n",
            "Epoch 00016: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [16] Train loss : [0.032866476236709526] Val Score : [0.6839995781035756])\n",
            "Epoch : [17] Train loss : [0.02364081796258688] Val Score : [0.6619424283038114])\n",
            "Epoch : [18] Train loss : [0.027749086064951762] Val Score : [0.7437178496040009])\n",
            "Epoch : [19] Train loss : [0.029568587562867572] Val Score : [0.8041895926750926])\n",
            "Epoch : [20] Train loss : [0.02827567992998021] Val Score : [0.8041895926750926])\n",
            "Epoch : [21] Train loss : [0.024053732864558697] Val Score : [0.8331926764657618])\n",
            "Epoch : [22] Train loss : [0.025348077794270858] Val Score : [0.562253919707516])\n",
            "Epoch : [23] Train loss : [0.023901665982391154] Val Score : [0.7725514640071602])\n",
            "Epoch : [24] Train loss : [0.022192319189863547] Val Score : [0.6889870340395065])\n",
            "Epoch : [25] Train loss : [0.02488093570406948] Val Score : [0.7379018553027905])\n",
            "Epoch : [26] Train loss : [0.02541890594043902] Val Score : [0.4997363518121419])\n",
            "Epoch 00027: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [27] Train loss : [0.02298233804426023] Val Score : [0.4997363518121419])\n",
            "Epoch : [28] Train loss : [0.02332853858492204] Val Score : [0.5320032001215638])\n",
            "Epoch : [29] Train loss : [0.022840890900364945] Val Score : [0.4997363518121419])\n",
            "Epoch : [30] Train loss : [0.023083985384021486] Val Score : [0.4997363518121419])\n",
            "Epoch : [31] Train loss : [0.025560840166040828] Val Score : [0.5320032001215638])\n",
            "Epoch : [32] Train loss : [0.022755161726049015] Val Score : [0.6174185476616381])\n",
            "Epoch : [33] Train loss : [0.019923560454377105] Val Score : [0.6889870340395065])\n",
            "Epoch : [34] Train loss : [0.021353100825633322] Val Score : [0.5320032001215638])\n",
            "Epoch : [35] Train loss : [0.02037914908890213] Val Score : [0.5320032001215638])\n",
            "Epoch : [36] Train loss : [0.01864186567919595] Val Score : [0.5320032001215638])\n",
            "Epoch : [37] Train loss : [0.02242475202573197] Val Score : [0.7887218676684034])\n",
            "Epoch 00038: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [38] Train loss : [0.02233843199376549] Val Score : [0.7437178496040009])\n",
            "Epoch : [39] Train loss : [0.019773580666099275] Val Score : [0.4997363518121419])\n",
            "Epoch : [40] Train loss : [0.020112300823841776] Val Score : [0.4997363518121419])\n",
            "Epoch : [41] Train loss : [0.019222419442875043] Val Score : [0.4997363518121419])\n",
            "Epoch : [42] Train loss : [0.020023922435939312] Val Score : [0.4997363518121419])\n",
            "Epoch : [43] Train loss : [0.018897546056125845] Val Score : [0.4997363518121419])\n",
            "Epoch : [44] Train loss : [0.02034861208604915] Val Score : [0.4997363518121419])\n",
            "Epoch : [45] Train loss : [0.01958322338759899] Val Score : [0.4997363518121419])\n",
            "Epoch : [46] Train loss : [0.018452405663473264] Val Score : [0.7437178496040009])\n",
            "Epoch : [47] Train loss : [0.018331402114459446] Val Score : [0.4997363518121419])\n",
            "Epoch : [48] Train loss : [0.019228991786284105] Val Score : [0.4997363518121419])\n",
            "Epoch 00049: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [49] Train loss : [0.020642589112477645] Val Score : [0.4997363518121419])\n",
            "\n",
            "etc col : V20 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V21\n",
            "Epoch : [0] Train loss : [0.21708511401500022] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.13323212574635232] Val Score : [0.8189994908759815])\n",
            "Epoch : [2] Train loss : [0.07902911544910499] Val Score : [0.9165787375726882])\n",
            "Epoch : [3] Train loss : [0.06716890899198395] Val Score : [0.003196062946930931])\n",
            "Epoch : [4] Train loss : [0.07868687861732074] Val Score : [0.9097393418694286])\n",
            "Epoch : [5] Train loss : [0.06529133420969759] Val Score : [0.896129704996047])\n",
            "Epoch : [6] Train loss : [0.051951216267687936] Val Score : [0.9165787375726882])\n",
            "Epoch : [7] Train loss : [0.05559364307139601] Val Score : [0.8376267560436427])\n",
            "Epoch : [8] Train loss : [0.043067634504820616] Val Score : [0.9066829407144783])\n",
            "Epoch : [9] Train loss : [0.029368929032768522] Val Score : [0.899903286500554])\n",
            "Epoch : [10] Train loss : [0.03604186312960727] Val Score : [0.899903286500554])\n",
            "Epoch : [11] Train loss : [0.028273703663476875] Val Score : [0.846806907378336])\n",
            "Epoch : [12] Train loss : [0.028037210261183127] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.025959518871137073] Val Score : [0.8652615319692264])\n",
            "Epoch 00014: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [14] Train loss : [0.0262282703604017] Val Score : [0.8331926764657618])\n",
            "Epoch : [15] Train loss : [0.027305797673761845] Val Score : [0.8331926764657618])\n",
            "Epoch : [16] Train loss : [0.02653627989015409] Val Score : [0.8041895926750926])\n",
            "Epoch : [17] Train loss : [0.025487055469836508] Val Score : [0.8887833851083367])\n",
            "Epoch : [18] Train loss : [0.027789535400058542] Val Score : [0.8189994908759815])\n",
            "Epoch : [19] Train loss : [0.02639252838811704] Val Score : [0.8927516353661109])\n",
            "Epoch : [20] Train loss : [0.02268792875111103] Val Score : [0.8331926764657618])\n",
            "Epoch : [21] Train loss : [0.022836167764450823] Val Score : [0.755629357577611])\n",
            "Epoch : [22] Train loss : [0.022663233003446033] Val Score : [0.755629357577611])\n",
            "Epoch : [23] Train loss : [0.022503816123519624] Val Score : [0.7379018553027905])\n",
            "Epoch : [24] Train loss : [0.020844201956476485] Val Score : [0.8331926764657618])\n",
            "Epoch 00025: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [25] Train loss : [0.02028635729636465] Val Score : [0.755629357577611])\n",
            "Epoch : [26] Train loss : [0.022706947023315088] Val Score : [0.7379018553027905])\n",
            "Epoch : [27] Train loss : [0.022046370431780815] Val Score : [0.7379018553027905])\n",
            "Epoch : [28] Train loss : [0.022286799071090563] Val Score : [0.8189994908759815])\n",
            "Epoch : [29] Train loss : [0.023085734540862695] Val Score : [0.8041895926750926])\n",
            "Epoch : [30] Train loss : [0.020567804308874265] Val Score : [0.5320032001215638])\n",
            "Epoch : [31] Train loss : [0.02068005103085722] Val Score : [0.7725514640071602])\n",
            "Epoch : [32] Train loss : [0.020616543479263783] Val Score : [0.7725514640071602])\n",
            "Epoch : [33] Train loss : [0.020333175813513144] Val Score : [0.8041895926750926])\n",
            "Epoch : [34] Train loss : [0.01977452782115766] Val Score : [0.8041895926750926])\n",
            "Epoch : [35] Train loss : [0.019886179428015436] Val Score : [0.5320032001215638])\n",
            "Epoch 00036: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [36] Train loss : [0.020070362836122513] Val Score : [0.755629357577611])\n",
            "Epoch : [37] Train loss : [0.019193258668695177] Val Score : [0.4997363518121419])\n",
            "Epoch : [38] Train loss : [0.018229646342141286] Val Score : [0.8041895926750926])\n",
            "Epoch : [39] Train loss : [0.018938158505729268] Val Score : [0.8041895926750926])\n",
            "Epoch : [40] Train loss : [0.01838268086846386] Val Score : [0.7725514640071602])\n",
            "Epoch : [41] Train loss : [0.01858254083033119] Val Score : [0.5320032001215638])\n",
            "Epoch : [42] Train loss : [0.019792132611785616] Val Score : [0.5320032001215638])\n",
            "Epoch : [43] Train loss : [0.01888239663094282] Val Score : [0.7437178496040009])\n",
            "Epoch : [44] Train loss : [0.01894688074077879] Val Score : [0.730584647838757])\n",
            "Epoch : [45] Train loss : [0.01943183597177267] Val Score : [0.7049260428710196])\n",
            "Epoch : [46] Train loss : [0.018772158239568983] Val Score : [0.7725514640071602])\n",
            "Epoch 00047: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [47] Train loss : [0.018346372060477734] Val Score : [0.755629357577611])\n",
            "Epoch : [48] Train loss : [0.017862404829689434] Val Score : [0.7437178496040009])\n",
            "Epoch : [49] Train loss : [0.018230306915938854] Val Score : [0.4997363518121419])\n",
            "\n",
            "etc col : V21 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V22\n",
            "Epoch : [0] Train loss : [0.224594134837389] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.1294668401990618] Val Score : [0.8724347298745778])\n",
            "Epoch : [2] Train loss : [0.06909631937742233] Val Score : [0.8189994908759815])\n",
            "Epoch : [3] Train loss : [0.044596168877823014] Val Score : [0.9137051774467988])\n",
            "Epoch : [4] Train loss : [0.036182121240666935] Val Score : [0.9137051774467988])\n",
            "Epoch : [5] Train loss : [0.03723117775682892] Val Score : [0.8422634702634115])\n",
            "Epoch : [6] Train loss : [0.040507852365928035] Val Score : [0.856966968023358])\n",
            "Epoch : [7] Train loss : [0.050866255802767615] Val Score : [0.7985426766884692])\n",
            "Epoch : [8] Train loss : [0.04393548145890236] Val Score : [0.8927516353661109])\n",
            "Epoch : [9] Train loss : [0.04564855859747955] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.04029293797378029] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.031838045588561466] Val Score : [0.9137051774467988])\n",
            "Epoch : [12] Train loss : [0.03469240412648235] Val Score : [0.8927516353661109])\n",
            "Epoch : [13] Train loss : [0.029139809975666658] Val Score : [0.9165787375726882])\n",
            "Epoch : [14] Train loss : [0.03914420160331896] Val Score : [0.9097393418694286])\n",
            "Epoch : [15] Train loss : [0.02784655788647277] Val Score : [0.9137051774467988])\n",
            "Epoch : [16] Train loss : [0.0276828333735466] Val Score : [0.9066829407144783])\n",
            "Epoch : [17] Train loss : [0.02838030510715076] Val Score : [0.9137051774467988])\n",
            "Epoch : [18] Train loss : [0.02894076585237469] Val Score : [0.9137051774467988])\n",
            "Epoch : [19] Train loss : [0.026695791498890946] Val Score : [0.8528093037014359])\n",
            "Epoch : [20] Train loss : [0.025584057239549502] Val Score : [0.9137051774467988])\n",
            "Epoch 00021: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [21] Train loss : [0.023430689238011837] Val Score : [0.8528093037014359])\n",
            "Epoch : [22] Train loss : [0.023210306651890278] Val Score : [0.8528093037014359])\n",
            "Epoch : [23] Train loss : [0.024888615123927593] Val Score : [0.7887218676684034])\n",
            "Epoch : [24] Train loss : [0.02295330898570163] Val Score : [0.899903286500554])\n",
            "Epoch : [25] Train loss : [0.022210254466959407] Val Score : [0.8331926764657618])\n",
            "Epoch : [26] Train loss : [0.02276402006724051] Val Score : [0.8041895926750926])\n",
            "Epoch : [27] Train loss : [0.023853623175195286] Val Score : [0.846806907378336])\n",
            "Epoch : [28] Train loss : [0.022713365565453256] Val Score : [0.8331926764657618])\n",
            "Epoch : [29] Train loss : [0.022931529874248163] Val Score : [0.7887218676684034])\n",
            "Epoch : [30] Train loss : [0.02065755027745451] Val Score : [0.8041895926750926])\n",
            "Epoch : [31] Train loss : [0.020164872785764083] Val Score : [0.755629357577611])\n",
            "Epoch 00032: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [32] Train loss : [0.020319690395678793] Val Score : [0.7379018553027905])\n",
            "Epoch : [33] Train loss : [0.019395000035209314] Val Score : [0.8331926764657618])\n",
            "Epoch : [34] Train loss : [0.02059497670935733] Val Score : [0.7379018553027905])\n",
            "Epoch : [35] Train loss : [0.020077339240482876] Val Score : [0.7725514640071602])\n",
            "Epoch : [36] Train loss : [0.02022133581340313] Val Score : [0.755629357577611])\n",
            "Epoch : [37] Train loss : [0.019880424785826887] Val Score : [0.7887218676684034])\n",
            "Epoch : [38] Train loss : [0.020396773969488486] Val Score : [0.7887218676684034])\n",
            "Epoch : [39] Train loss : [0.01892164336251361] Val Score : [0.7379018553027905])\n",
            "Epoch : [40] Train loss : [0.022910327384514467] Val Score : [0.7887218676684034])\n",
            "Epoch : [41] Train loss : [0.01890532299876213] Val Score : [0.755629357577611])\n",
            "Epoch : [42] Train loss : [0.018872070791465894] Val Score : [0.7887218676684034])\n",
            "Epoch 00043: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [43] Train loss : [0.018202269982014383] Val Score : [0.7379018553027905])\n",
            "Epoch : [44] Train loss : [0.018750650542122976] Val Score : [0.4997363518121419])\n",
            "Epoch : [45] Train loss : [0.01790818172906126] Val Score : [0.755629357577611])\n",
            "Epoch : [46] Train loss : [0.018247485160827637] Val Score : [0.7887218676684034])\n",
            "Epoch : [47] Train loss : [0.018016283799495016] Val Score : [0.4997363518121419])\n",
            "Epoch : [48] Train loss : [0.01791256120694535] Val Score : [0.4997363518121419])\n",
            "Epoch : [49] Train loss : [0.018402960284480026] Val Score : [0.562253919707516])\n",
            "\n",
            "etc col : V22 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V23\n",
            "Epoch : [0] Train loss : [0.24324938335589] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.1116511874965259] Val Score : [0.755629357577611])\n",
            "Epoch : [2] Train loss : [0.08631260027842862] Val Score : [0.856966968023358])\n",
            "Epoch : [3] Train loss : [0.0680135435291699] Val Score : [0.8724347298745778])\n",
            "Epoch : [4] Train loss : [0.039250797858195643] Val Score : [0.0206579441470785])\n",
            "Epoch : [5] Train loss : [0.046317078971437046] Val Score : [0.9137051774467988])\n",
            "Epoch : [6] Train loss : [0.05237627894218479] Val Score : [0.9165787375726882])\n",
            "Epoch : [7] Train loss : [0.0379246019625238] Val Score : [0.9137051774467988])\n",
            "Epoch : [8] Train loss : [0.03590744135103056] Val Score : [0.9236496787663914])\n",
            "Epoch : [9] Train loss : [0.03821937247578587] Val Score : [0.8598769209128951])\n",
            "Epoch : [10] Train loss : [0.03289698862603733] Val Score : [0.9137051774467988])\n",
            "Epoch : [11] Train loss : [0.034132251382938454] Val Score : [0.9165787375726882])\n",
            "Epoch : [12] Train loss : [0.032219517709953446] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.029036721347698143] Val Score : [0.9165787375726882])\n",
            "Epoch : [14] Train loss : [0.026679889831159796] Val Score : [0.899903286500554])\n",
            "Epoch : [15] Train loss : [0.03212976681866816] Val Score : [0.8927516353661109])\n",
            "Epoch : [16] Train loss : [0.0307883085416896] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.03156682649361236] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.02867668348231486] Val Score : [0.8652615319692264])\n",
            "Epoch : [19] Train loss : [0.028930411407990114] Val Score : [0.8331926764657618])\n",
            "Epoch 00020: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [20] Train loss : [0.0258732247831566] Val Score : [0.8927516353661109])\n",
            "Epoch : [21] Train loss : [0.02489546872675419] Val Score : [0.8331926764657618])\n",
            "Epoch : [22] Train loss : [0.023590419308415482] Val Score : [0.8041895926750926])\n",
            "Epoch : [23] Train loss : [0.024297905819756643] Val Score : [0.8041895926750926])\n",
            "Epoch : [24] Train loss : [0.0232644650552954] Val Score : [0.8331926764657618])\n",
            "Epoch : [25] Train loss : [0.021750115124242648] Val Score : [0.8598769209128951])\n",
            "Epoch : [26] Train loss : [0.020825385648225034] Val Score : [0.8331926764657618])\n",
            "Epoch : [27] Train loss : [0.023182523037706102] Val Score : [0.8331926764657618])\n",
            "Epoch : [28] Train loss : [0.023056718919958388] Val Score : [0.9137051774467988])\n",
            "Epoch : [29] Train loss : [0.02366717372621809] Val Score : [0.8331926764657618])\n",
            "Epoch : [30] Train loss : [0.020373623685113022] Val Score : [0.870247282626393])\n",
            "Epoch 00031: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [31] Train loss : [0.019701742700168064] Val Score : [0.8041895926750926])\n",
            "Epoch : [32] Train loss : [0.01875462755560875] Val Score : [0.8331926764657618])\n",
            "Epoch : [33] Train loss : [0.021867612642901286] Val Score : [0.8041895926750926])\n",
            "Epoch : [34] Train loss : [0.018908318664346422] Val Score : [0.7379018553027905])\n",
            "Epoch : [35] Train loss : [0.021356988033013686] Val Score : [0.8724347298745778])\n",
            "Epoch : [36] Train loss : [0.020752296516937867] Val Score : [0.8041895926750926])\n",
            "Epoch : [37] Train loss : [0.019250148508165563] Val Score : [0.7887218676684034])\n",
            "Epoch : [38] Train loss : [0.017770671551781043] Val Score : [0.8041895926750926])\n",
            "Epoch : [39] Train loss : [0.01862359419465065] Val Score : [0.7725514640071602])\n",
            "Epoch : [40] Train loss : [0.01874642233763422] Val Score : [0.8041895926750926])\n",
            "Epoch : [41] Train loss : [0.01925874674426658] Val Score : [0.6426374167237955])\n",
            "Epoch 00042: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [42] Train loss : [0.01867309452167579] Val Score : [0.7437178496040009])\n",
            "Epoch : [43] Train loss : [0.01789346443755286] Val Score : [0.4997363518121419])\n",
            "Epoch : [44] Train loss : [0.01851698463516576] Val Score : [0.7437178496040009])\n",
            "Epoch : [45] Train loss : [0.018411385427628244] Val Score : [0.7498242036425005])\n",
            "Epoch : [46] Train loss : [0.018092382699251175] Val Score : [0.4997363518121419])\n",
            "Epoch : [47] Train loss : [0.01831735284732921] Val Score : [0.4997363518121419])\n",
            "Epoch : [48] Train loss : [0.017546283613358225] Val Score : [0.7049260428710196])\n",
            "Epoch : [49] Train loss : [0.017850209825805256] Val Score : [0.755629357577611])\n",
            "\n",
            "etc col : V23 / Marco F1 Score : 0.9236496787663914\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V24\n",
            "Epoch : [0] Train loss : [0.22840473534805433] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.10336092806288175] Val Score : [0.0010529271374420891])\n",
            "Epoch : [2] Train loss : [0.07618056450571332] Val Score : [0.9034120550289857])\n",
            "Epoch : [3] Train loss : [0.06479728275111743] Val Score : [0.9165787375726882])\n",
            "Epoch : [4] Train loss : [0.05309099903596299] Val Score : [0.846806907378336])\n",
            "Epoch : [5] Train loss : [0.03845040579991681] Val Score : [0.899903286500554])\n",
            "Epoch : [6] Train loss : [0.04546817099409444] Val Score : [0.9097393418694286])\n",
            "Epoch : [7] Train loss : [0.031516983705971925] Val Score : [0.9137051774467988])\n",
            "Epoch : [8] Train loss : [0.03439939022064209] Val Score : [0.8772441968135101])\n",
            "Epoch : [9] Train loss : [0.03344344946422747] Val Score : [0.8598769209128951])\n",
            "Epoch : [10] Train loss : [0.032779276237956116] Val Score : [0.899903286500554])\n",
            "Epoch : [11] Train loss : [0.03617137311292546] Val Score : [0.9165787375726882])\n",
            "Epoch : [12] Train loss : [0.0340081922976034] Val Score : [0.9137051774467988])\n",
            "Epoch : [13] Train loss : [0.02926550925310169] Val Score : [0.899903286500554])\n",
            "Epoch : [14] Train loss : [0.02739368232765368] Val Score : [0.8041895926750926])\n",
            "Epoch 00015: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [15] Train loss : [0.032198368039514334] Val Score : [0.8331926764657618])\n",
            "Epoch : [16] Train loss : [0.027824973421437398] Val Score : [0.8927516353661109])\n",
            "Epoch : [17] Train loss : [0.026209384336003234] Val Score : [0.8598769209128951])\n",
            "Epoch : [18] Train loss : [0.030008016553308283] Val Score : [0.899903286500554])\n",
            "Epoch : [19] Train loss : [0.026807541559849466] Val Score : [0.899903286500554])\n",
            "Epoch : [20] Train loss : [0.027069100444870337] Val Score : [0.899903286500554])\n",
            "Epoch : [21] Train loss : [0.024181255006364415] Val Score : [0.8331926764657618])\n",
            "Epoch : [22] Train loss : [0.02399198085601841] Val Score : [0.8652615319692264])\n",
            "Epoch : [23] Train loss : [0.02449038571545056] Val Score : [0.8598769209128951])\n",
            "Epoch : [24] Train loss : [0.026900910240198885] Val Score : [0.8598769209128951])\n",
            "Epoch : [25] Train loss : [0.022730880683021887] Val Score : [0.8927516353661109])\n",
            "Epoch 00026: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [26] Train loss : [0.02335558964737824] Val Score : [0.8189994908759815])\n",
            "Epoch : [27] Train loss : [0.022238579312605516] Val Score : [0.7379018553027905])\n",
            "Epoch : [28] Train loss : [0.022272851185074875] Val Score : [0.8189994908759815])\n",
            "Epoch : [29] Train loss : [0.02304302408759083] Val Score : [0.7379018553027905])\n",
            "Epoch : [30] Train loss : [0.022475159327898706] Val Score : [0.7887218676684034])\n",
            "Epoch : [31] Train loss : [0.021723512560129166] Val Score : [0.8041895926750926])\n",
            "Epoch : [32] Train loss : [0.024038128155682768] Val Score : [0.8041895926750926])\n",
            "Epoch : [33] Train loss : [0.020461817138961384] Val Score : [0.8189994908759815])\n",
            "Epoch : [34] Train loss : [0.022396248632243702] Val Score : [0.8189994908759815])\n",
            "Epoch : [35] Train loss : [0.01958761483963047] Val Score : [0.8331926764657618])\n",
            "Epoch : [36] Train loss : [0.01976645046046802] Val Score : [0.7379018553027905])\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [37] Train loss : [0.020595038309693336] Val Score : [0.755629357577611])\n",
            "Epoch : [38] Train loss : [0.020003525806324824] Val Score : [0.7379018553027905])\n",
            "Epoch : [39] Train loss : [0.01965750873621021] Val Score : [0.8041895926750926])\n",
            "Epoch : [40] Train loss : [0.01968122912304742] Val Score : [0.7379018553027905])\n",
            "Epoch : [41] Train loss : [0.02335665055683681] Val Score : [0.7379018553027905])\n",
            "Epoch : [42] Train loss : [0.022051947191357613] Val Score : [0.755629357577611])\n",
            "Epoch : [43] Train loss : [0.020326937681862285] Val Score : [0.755629357577611])\n",
            "Epoch : [44] Train loss : [0.01988836404468332] Val Score : [0.7379018553027905])\n",
            "Epoch : [45] Train loss : [0.02023888672036784] Val Score : [0.7887218676684034])\n",
            "Epoch : [46] Train loss : [0.019830414360123023] Val Score : [0.755629357577611])\n",
            "Epoch : [47] Train loss : [0.019421251490712166] Val Score : [0.7103329465949443])\n",
            "Epoch 00048: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [48] Train loss : [0.019687414036265442] Val Score : [0.7437178496040009])\n",
            "Epoch : [49] Train loss : [0.019401010258921554] Val Score : [0.562253919707516])\n",
            "\n",
            "etc col : V24 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V25\n",
            "Epoch : [0] Train loss : [0.22344294775809562] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.11686515754887036] Val Score : [0.8598769209128951])\n",
            "Epoch : [2] Train loss : [0.0980195685156754] Val Score : [0.8331926764657618])\n",
            "Epoch : [3] Train loss : [0.077385599059718] Val Score : [0.7379018553027905])\n",
            "Epoch : [4] Train loss : [0.0727549482669149] Val Score : [0.7379018553027905])\n",
            "Epoch : [5] Train loss : [0.03727043553122452] Val Score : [0.9137051774467988])\n",
            "Epoch : [6] Train loss : [0.033122399023600986] Val Score : [0.8528093037014359])\n",
            "Epoch : [7] Train loss : [0.0325420190181051] Val Score : [0.8528093037014359])\n",
            "Epoch : [8] Train loss : [0.029579661919602325] Val Score : [0.8598769209128951])\n",
            "Epoch : [9] Train loss : [0.03259878272988966] Val Score : [0.8041895926750926])\n",
            "Epoch : [10] Train loss : [0.029088876343199184] Val Score : [0.8927516353661109])\n",
            "Epoch : [11] Train loss : [0.025436349346169403] Val Score : [0.8331926764657618])\n",
            "Epoch : [12] Train loss : [0.027812572063079903] Val Score : [0.9137051774467988])\n",
            "Epoch : [13] Train loss : [0.032688334717282226] Val Score : [0.8724347298745778])\n",
            "Epoch : [14] Train loss : [0.03218053627227034] Val Score : [0.8927516353661109])\n",
            "Epoch : [15] Train loss : [0.039011066646448204] Val Score : [0.8927516353661109])\n",
            "Epoch : [16] Train loss : [0.04121321626007557] Val Score : [0.8887833851083367])\n",
            "Epoch 00017: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [17] Train loss : [0.03961428507630314] Val Score : [0.8041895926750926])\n",
            "Epoch : [18] Train loss : [0.024934202964816774] Val Score : [0.755629357577611])\n",
            "Epoch : [19] Train loss : [0.0284913887402841] Val Score : [0.7887218676684034])\n",
            "Epoch : [20] Train loss : [0.030532822545085634] Val Score : [0.8189994908759815])\n",
            "Epoch : [21] Train loss : [0.02940854017755815] Val Score : [0.755629357577611])\n",
            "Epoch : [22] Train loss : [0.026204318473381654] Val Score : [0.755629357577611])\n",
            "Epoch : [23] Train loss : [0.02465848731143134] Val Score : [0.7437178496040009])\n",
            "Epoch : [24] Train loss : [0.02157043559210641] Val Score : [0.8331926764657618])\n",
            "Epoch : [25] Train loss : [0.02494542926017727] Val Score : [0.7379018553027905])\n",
            "Epoch : [26] Train loss : [0.02424250583031348] Val Score : [0.7887218676684034])\n",
            "Epoch : [27] Train loss : [0.02190053476286786] Val Score : [0.7379018553027905])\n",
            "Epoch 00028: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [28] Train loss : [0.02338342967310122] Val Score : [0.7437178496040009])\n",
            "Epoch : [29] Train loss : [0.02004484965332917] Val Score : [0.755629357577611])\n",
            "Epoch : [30] Train loss : [0.022905850916036537] Val Score : [0.7379018553027905])\n",
            "Epoch : [31] Train loss : [0.022050008976033757] Val Score : [0.7379018553027905])\n",
            "Epoch : [32] Train loss : [0.023972174285777977] Val Score : [0.6426374167237955])\n",
            "Epoch : [33] Train loss : [0.021918861594583307] Val Score : [0.755629357577611])\n",
            "Epoch : [34] Train loss : [0.02243866039706128] Val Score : [0.7887218676684034])\n",
            "Epoch : [35] Train loss : [0.020726295321115425] Val Score : [0.755629357577611])\n",
            "Epoch : [36] Train loss : [0.01991737261414528] Val Score : [0.755629357577611])\n",
            "Epoch : [37] Train loss : [0.021048378864569322] Val Score : [0.8041895926750926])\n",
            "Epoch : [38] Train loss : [0.01967290389750685] Val Score : [0.4997363518121419])\n",
            "Epoch 00039: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [39] Train loss : [0.020673941421721662] Val Score : [0.4997363518121419])\n",
            "Epoch : [40] Train loss : [0.018453958444297314] Val Score : [0.7379018553027905])\n",
            "Epoch : [41] Train loss : [0.018787241274757043] Val Score : [0.7379018553027905])\n",
            "Epoch : [42] Train loss : [0.020060303221855844] Val Score : [0.7248066240067507])\n",
            "Epoch : [43] Train loss : [0.018593594564923217] Val Score : [0.4997363518121419])\n",
            "Epoch : [44] Train loss : [0.018126441165804863] Val Score : [0.4997363518121419])\n",
            "Epoch : [45] Train loss : [0.0195337160091315] Val Score : [0.4997363518121419])\n",
            "Epoch : [46] Train loss : [0.01842171499239547] Val Score : [0.4997363518121419])\n",
            "Epoch : [47] Train loss : [0.019276379607617855] Val Score : [0.4997363518121419])\n",
            "Epoch : [48] Train loss : [0.017980382112520083] Val Score : [0.4997363518121419])\n",
            "Epoch : [49] Train loss : [0.017807879352143834] Val Score : [0.4997363518121419])\n",
            "Epoch 00050: reducing learning rate of group 0 to 6.2500e-04.\n",
            "\n",
            "etc col : V25 / Marco F1 Score : 0.9137051774467988\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V26\n",
            "Epoch : [0] Train loss : [0.2657843828201294] Val Score : [0.8331926764657618])\n",
            "Epoch : [1] Train loss : [0.16550716598119056] Val Score : [0.005015781463317467])\n",
            "Epoch : [2] Train loss : [0.11309032035725457] Val Score : [0.789600037726278])\n",
            "Epoch : [3] Train loss : [0.08709954284131527] Val Score : [0.47726157731321694])\n",
            "Epoch : [4] Train loss : [0.055198196321725845] Val Score : [0.755629357577611])\n",
            "Epoch : [5] Train loss : [0.04814256301948002] Val Score : [0.7379018553027905])\n",
            "Epoch : [6] Train loss : [0.045160984088267596] Val Score : [0.755629357577611])\n",
            "Epoch : [7] Train loss : [0.04926887553717409] Val Score : [0.6839995781035756])\n",
            "Epoch : [8] Train loss : [0.04639120639434883] Val Score : [0.7379018553027905])\n",
            "Epoch : [9] Train loss : [0.036474406852253845] Val Score : [0.7379018553027905])\n",
            "Epoch : [10] Train loss : [0.03226319248122828] Val Score : [0.7379018553027905])\n",
            "Epoch : [11] Train loss : [0.031567608671528954] Val Score : [0.7379018553027905])\n",
            "Epoch 00012: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [12] Train loss : [0.03115100786089897] Val Score : [0.7442422608617514])\n",
            "Epoch : [13] Train loss : [0.028579913478876864] Val Score : [0.6386603696932764])\n",
            "Epoch : [14] Train loss : [0.02698623082999672] Val Score : [0.7379018553027905])\n",
            "Epoch : [15] Train loss : [0.02716787744845663] Val Score : [0.6386603696932764])\n",
            "Epoch : [16] Train loss : [0.026041889430156777] Val Score : [0.562253919707516])\n",
            "Epoch : [17] Train loss : [0.02598160252507244] Val Score : [0.5320032001215638])\n",
            "Epoch : [18] Train loss : [0.026424546060817584] Val Score : [0.5320032001215638])\n",
            "Epoch : [19] Train loss : [0.024275749123522213] Val Score : [0.5320032001215638])\n",
            "Epoch : [20] Train loss : [0.02408975296254669] Val Score : [0.7437178496040009])\n",
            "Epoch : [21] Train loss : [0.023938146952007498] Val Score : [0.5320032001215638])\n",
            "Epoch : [22] Train loss : [0.022701256243245944] Val Score : [0.5603511872517514])\n",
            "Epoch 00023: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [23] Train loss : [0.02289893212062972] Val Score : [0.562253919707516])\n",
            "Epoch : [24] Train loss : [0.022211157184626375] Val Score : [0.5320032001215638])\n",
            "Epoch : [25] Train loss : [0.02462336075093065] Val Score : [0.562253919707516])\n",
            "Epoch : [26] Train loss : [0.02410400499190603] Val Score : [0.6386603696932764])\n",
            "Epoch : [27] Train loss : [0.02272292718823467] Val Score : [0.5320032001215638])\n",
            "Epoch : [28] Train loss : [0.023050550637500628] Val Score : [0.5320032001215638])\n",
            "Epoch : [29] Train loss : [0.022016720713249276] Val Score : [0.562253919707516])\n",
            "Epoch : [30] Train loss : [0.02144880858915193] Val Score : [0.5320032001215638])\n",
            "Epoch : [31] Train loss : [0.02120474606220211] Val Score : [0.562253919707516])\n",
            "Epoch : [32] Train loss : [0.02105466356234891] Val Score : [0.562253919707516])\n",
            "Epoch : [33] Train loss : [0.02088940343154328] Val Score : [0.562253919707516])\n",
            "Epoch 00034: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [34] Train loss : [0.020570859845195497] Val Score : [0.5320032001215638])\n",
            "Epoch : [35] Train loss : [0.020883403585425446] Val Score : [0.5320032001215638])\n",
            "Epoch : [36] Train loss : [0.020730869179325446] Val Score : [0.5320032001215638])\n",
            "Epoch : [37] Train loss : [0.02091620463345732] Val Score : [0.5320032001215638])\n",
            "Epoch : [38] Train loss : [0.020736477470823696] Val Score : [0.5320032001215638])\n",
            "Epoch : [39] Train loss : [0.020592941104301384] Val Score : [0.5320032001215638])\n",
            "Epoch : [40] Train loss : [0.020274970680475235] Val Score : [0.5320032001215638])\n",
            "Epoch : [41] Train loss : [0.02091395921472992] Val Score : [0.5320032001215638])\n",
            "Epoch : [42] Train loss : [0.020350139987255846] Val Score : [0.5320032001215638])\n",
            "Epoch : [43] Train loss : [0.02050054565604244] Val Score : [0.5320032001215638])\n",
            "Epoch : [44] Train loss : [0.020351757827614034] Val Score : [0.5320032001215638])\n",
            "Epoch 00045: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [45] Train loss : [0.020059230604342053] Val Score : [0.5320032001215638])\n",
            "Epoch : [46] Train loss : [0.019754614947097644] Val Score : [0.5320032001215638])\n",
            "Epoch : [47] Train loss : [0.020197346274341856] Val Score : [0.5320032001215638])\n",
            "Epoch : [48] Train loss : [0.02022922398256404] Val Score : [0.5320032001215638])\n",
            "Epoch : [49] Train loss : [0.020411344644214426] Val Score : [0.5320032001215638])\n",
            "\n",
            "etc col : V26 / Marco F1 Score : 0.8331926764657618\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V27\n",
            "Epoch : [0] Train loss : [0.25238308204071863] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.11816781493169921] Val Score : [0.8546804317413637])\n",
            "Epoch : [2] Train loss : [0.05880655614393098] Val Score : [0.8887833851083367])\n",
            "Epoch : [3] Train loss : [0.04172499743955476] Val Score : [0.9165787375726882])\n",
            "Epoch : [4] Train loss : [0.04402401018887758] Val Score : [0.9097393418694286])\n",
            "Epoch : [5] Train loss : [0.03972777085644858] Val Score : [0.8967110829723166])\n",
            "Epoch : [6] Train loss : [0.02797134273818561] Val Score : [0.9031202878275757])\n",
            "Epoch : [7] Train loss : [0.02717788065118449] Val Score : [0.9165787375726882])\n",
            "Epoch : [8] Train loss : [0.030187832324632576] Val Score : [0.9165787375726882])\n",
            "Epoch : [9] Train loss : [0.028523437811860015] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.038091328527246206] Val Score : [0.8519279892324237])\n",
            "Epoch : [11] Train loss : [0.03689827676862478] Val Score : [0.8844834793761085])\n",
            "Epoch : [12] Train loss : [0.028972125479153225] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.029636980965733528] Val Score : [0.9137051774467988])\n",
            "Epoch : [14] Train loss : [0.03079634133194174] Val Score : [0.899903286500554])\n",
            "Epoch 00015: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [15] Train loss : [0.027310901587562903] Val Score : [0.9034120550289857])\n",
            "Epoch : [16] Train loss : [0.02339135136987482] Val Score : [0.8598769209128951])\n",
            "Epoch : [17] Train loss : [0.023086920912776674] Val Score : [0.9034120550289857])\n",
            "Epoch : [18] Train loss : [0.024375383609107563] Val Score : [0.9137051774467988])\n",
            "Epoch : [19] Train loss : [0.02360786750380482] Val Score : [0.8927516353661109])\n",
            "Epoch : [20] Train loss : [0.02309020794928074] Val Score : [0.8772441968135101])\n",
            "Epoch : [21] Train loss : [0.022687157216881002] Val Score : [0.899903286500554])\n",
            "Epoch : [22] Train loss : [0.024640058566417013] Val Score : [0.846806907378336])\n",
            "Epoch : [23] Train loss : [0.020239335085664476] Val Score : [0.8331926764657618])\n",
            "Epoch : [24] Train loss : [0.023390180032168115] Val Score : [0.846806907378336])\n",
            "Epoch : [25] Train loss : [0.02307677867689303] Val Score : [0.755629357577611])\n",
            "Epoch 00026: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [26] Train loss : [0.02034241519868374] Val Score : [0.8189994908759815])\n",
            "Epoch : [27] Train loss : [0.022604516707360744] Val Score : [0.8041895926750926])\n",
            "Epoch : [28] Train loss : [0.01948587117450578] Val Score : [0.8189994908759815])\n",
            "Epoch : [29] Train loss : [0.018619075949702944] Val Score : [0.7725514640071602])\n",
            "Epoch : [30] Train loss : [0.01921650754021747] Val Score : [0.8189994908759815])\n",
            "Epoch : [31] Train loss : [0.01819290087691375] Val Score : [0.8331926764657618])\n",
            "Epoch : [32] Train loss : [0.02204273547977209] Val Score : [0.846806907378336])\n",
            "Epoch : [33] Train loss : [0.02099098757441555] Val Score : [0.9137051774467988])\n",
            "Epoch : [34] Train loss : [0.01936879594411169] Val Score : [0.8189994908759815])\n",
            "Epoch : [35] Train loss : [0.020091195590794086] Val Score : [0.899903286500554])\n",
            "Epoch : [36] Train loss : [0.02022984411035265] Val Score : [0.8041895926750926])\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [37] Train loss : [0.019963886056627547] Val Score : [0.8041895926750926])\n",
            "Epoch : [38] Train loss : [0.019832112959453037] Val Score : [0.8189994908759815])\n",
            "Epoch : [39] Train loss : [0.02161452333842005] Val Score : [0.8041895926750926])\n",
            "Epoch : [40] Train loss : [0.01860156868185316] Val Score : [0.7887218676684034])\n",
            "Epoch : [41] Train loss : [0.01917730937046664] Val Score : [0.8041895926750926])\n",
            "Epoch : [42] Train loss : [0.01870185589151723] Val Score : [0.7437178496040009])\n",
            "Epoch : [43] Train loss : [0.020056954052831446] Val Score : [0.755629357577611])\n",
            "Epoch : [44] Train loss : [0.017942043021321297] Val Score : [0.8189994908759815])\n",
            "Epoch : [45] Train loss : [0.017336330509611537] Val Score : [0.8189994908759815])\n",
            "Epoch : [46] Train loss : [0.016978786193898747] Val Score : [0.755629357577611])\n",
            "Epoch : [47] Train loss : [0.02051020839384624] Val Score : [0.6174185476616381])\n",
            "Epoch 00048: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [48] Train loss : [0.017706997426492826] Val Score : [0.7887218676684034])\n",
            "Epoch : [49] Train loss : [0.016950208228081465] Val Score : [0.755629357577611])\n",
            "\n",
            "etc col : V27 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V28\n",
            "Epoch : [0] Train loss : [0.22058633927788054] Val Score : [0.755629357577611])\n",
            "Epoch : [1] Train loss : [0.15097513422369957] Val Score : [0.010089807414920843])\n",
            "Epoch : [2] Train loss : [0.09439872152038983] Val Score : [0.872984830495149])\n",
            "Epoch : [3] Train loss : [0.08039145304688386] Val Score : [0.846806907378336])\n",
            "Epoch : [4] Train loss : [0.04542059132031032] Val Score : [0.7235746300909537])\n",
            "Epoch : [5] Train loss : [0.04020658042281866] Val Score : [0.9137051774467988])\n",
            "Epoch : [6] Train loss : [0.03352974235479321] Val Score : [0.9034120550289857])\n",
            "Epoch : [7] Train loss : [0.029760426309491907] Val Score : [0.8927516353661109])\n",
            "Epoch : [8] Train loss : [0.029814166016876698] Val Score : [0.8927516353661109])\n",
            "Epoch : [9] Train loss : [0.026508301762597903] Val Score : [0.846806907378336])\n",
            "Epoch : [10] Train loss : [0.030698465848607675] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.028586846377168382] Val Score : [0.9165787375726882])\n",
            "Epoch : [12] Train loss : [0.02878868194030864] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.031214572755353793] Val Score : [0.9034120550289857])\n",
            "Epoch : [14] Train loss : [0.029217738791235855] Val Score : [0.899903286500554])\n",
            "Epoch : [15] Train loss : [0.02576612095747675] Val Score : [0.8331926764657618])\n",
            "Epoch : [16] Train loss : [0.026175205861883506] Val Score : [0.8845098845450512])\n",
            "Epoch : [17] Train loss : [0.025219621003738472] Val Score : [0.8598769209128951])\n",
            "Epoch : [18] Train loss : [0.02249638071017606] Val Score : [0.8331926764657618])\n",
            "Epoch : [19] Train loss : [0.026158669298248633] Val Score : [0.9165787375726882])\n",
            "Epoch : [20] Train loss : [0.027537178514259204] Val Score : [0.8927516353661109])\n",
            "Epoch : [21] Train loss : [0.028079790861478875] Val Score : [0.8817038840461091])\n",
            "Epoch 00022: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [22] Train loss : [0.024382890867335454] Val Score : [0.8331926764657618])\n",
            "Epoch : [23] Train loss : [0.022523260808416774] Val Score : [0.846806907378336])\n",
            "Epoch : [24] Train loss : [0.021620647183486393] Val Score : [0.8331926764657618])\n",
            "Epoch : [25] Train loss : [0.02013047811176096] Val Score : [0.8041895926750926])\n",
            "Epoch : [26] Train loss : [0.020974891792450632] Val Score : [0.8041895926750926])\n",
            "Epoch : [27] Train loss : [0.020243226683565547] Val Score : [0.8041895926750926])\n",
            "Epoch : [28] Train loss : [0.019576084933110645] Val Score : [0.8041895926750926])\n",
            "Epoch : [29] Train loss : [0.019676901400089264] Val Score : [0.8331926764657618])\n",
            "Epoch : [30] Train loss : [0.01950846745499543] Val Score : [0.8041895926750926])\n",
            "Epoch : [31] Train loss : [0.019276385993829796] Val Score : [0.755629357577611])\n",
            "Epoch : [32] Train loss : [0.018933016008564403] Val Score : [0.8041895926750926])\n",
            "Epoch 00033: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [33] Train loss : [0.01851186329232795] Val Score : [0.755629357577611])\n",
            "Epoch : [34] Train loss : [0.018872727107788836] Val Score : [0.8331926764657618])\n",
            "Epoch : [35] Train loss : [0.018539473281375] Val Score : [0.7379018553027905])\n",
            "Epoch : [36] Train loss : [0.018339546530374458] Val Score : [0.7887218676684034])\n",
            "Epoch : [37] Train loss : [0.01748454317982708] Val Score : [0.7725514640071602])\n",
            "Epoch : [38] Train loss : [0.017815076746046543] Val Score : [0.7379018553027905])\n",
            "Epoch : [39] Train loss : [0.01796844508498907] Val Score : [0.755629357577611])\n",
            "Epoch : [40] Train loss : [0.017354571127465794] Val Score : [0.5906717950274928])\n",
            "Epoch : [41] Train loss : [0.0170791664027742] Val Score : [0.7887218676684034])\n",
            "Epoch : [42] Train loss : [0.017156374108578478] Val Score : [0.7887218676684034])\n",
            "Epoch : [43] Train loss : [0.01678101146327598] Val Score : [0.7379018553027905])\n",
            "Epoch 00044: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [44] Train loss : [0.016843849793076515] Val Score : [0.755629357577611])\n",
            "Epoch : [45] Train loss : [0.016457751193749055] Val Score : [0.7049260428710196])\n",
            "Epoch : [46] Train loss : [0.017492665510092462] Val Score : [0.7379018553027905])\n",
            "Epoch : [47] Train loss : [0.016921276093593667] Val Score : [0.7887218676684034])\n",
            "Epoch : [48] Train loss : [0.016505644523671696] Val Score : [0.755629357577611])\n",
            "Epoch : [49] Train loss : [0.016440173411475762] Val Score : [0.7379018553027905])\n",
            "\n",
            "etc col : V28 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V29\n",
            "Epoch : [0] Train loss : [0.21767227298447064] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.11358918835009847] Val Score : [0.8263811616954475])\n",
            "Epoch : [2] Train loss : [0.0961021182260343] Val Score : [0.0010529271374420891])\n",
            "Epoch : [3] Train loss : [0.045880483729498725] Val Score : [0.9097393418694286])\n",
            "Epoch : [4] Train loss : [0.03872377172644649] Val Score : [0.9034120550289857])\n",
            "Epoch : [5] Train loss : [0.034347123466432095] Val Score : [0.9137051774467988])\n",
            "Epoch : [6] Train loss : [0.03001775619174753] Val Score : [0.9066829407144783])\n",
            "Epoch : [7] Train loss : [0.037600960449448655] Val Score : [0.9165787375726882])\n",
            "Epoch : [8] Train loss : [0.03813019235219274] Val Score : [0.9165787375726882])\n",
            "Epoch : [9] Train loss : [0.03262298221566847] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.03024083176361663] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.029710231481918266] Val Score : [0.8927516353661109])\n",
            "Epoch : [12] Train loss : [0.036206452175974846] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.029510660762233392] Val Score : [0.9165787375726882])\n",
            "Epoch : [14] Train loss : [0.02836576569825411] Val Score : [0.9137051774467988])\n",
            "Epoch : [15] Train loss : [0.0284683353134564] Val Score : [0.8887833851083367])\n",
            "Epoch : [16] Train loss : [0.030215433399592127] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.027611606089132174] Val Score : [0.8927516353661109])\n",
            "Epoch : [18] Train loss : [0.0330807152869446] Val Score : [0.9165787375726882])\n",
            "Epoch 00019: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [19] Train loss : [0.031222476490906308] Val Score : [0.9034120550289857])\n",
            "Epoch : [20] Train loss : [0.033298872012112825] Val Score : [0.899903286500554])\n",
            "Epoch : [21] Train loss : [0.030737522058188915] Val Score : [0.8331926764657618])\n",
            "Epoch : [22] Train loss : [0.022261606928493296] Val Score : [0.8189994908759815])\n",
            "Epoch : [23] Train loss : [0.024625404870935848] Val Score : [0.8331926764657618])\n",
            "Epoch : [24] Train loss : [0.023658682060028826] Val Score : [0.8927516353661109])\n",
            "Epoch : [25] Train loss : [0.02308294443147523] Val Score : [0.8331926764657618])\n",
            "Epoch : [26] Train loss : [0.021544383705726693] Val Score : [0.755629357577611])\n",
            "Epoch : [27] Train loss : [0.02089216560125351] Val Score : [0.8927516353661109])\n",
            "Epoch : [28] Train loss : [0.019181040381746634] Val Score : [0.8041895926750926])\n",
            "Epoch : [29] Train loss : [0.01940935411091362] Val Score : [0.8927516353661109])\n",
            "Epoch 00030: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [30] Train loss : [0.01971761602908373] Val Score : [0.8041895926750926])\n",
            "Epoch : [31] Train loss : [0.020867219726954187] Val Score : [0.755629357577611])\n",
            "Epoch : [32] Train loss : [0.020177191788596765] Val Score : [0.8331926764657618])\n",
            "Epoch : [33] Train loss : [0.01860236855489867] Val Score : [0.7379018553027905])\n",
            "Epoch : [34] Train loss : [0.02025251210268055] Val Score : [0.755629357577611])\n",
            "Epoch : [35] Train loss : [0.02097367575126035] Val Score : [0.7725514640071602])\n",
            "Epoch : [36] Train loss : [0.020560128215168203] Val Score : [0.7887218676684034])\n",
            "Epoch : [37] Train loss : [0.019588976300188472] Val Score : [0.8189994908759815])\n",
            "Epoch : [38] Train loss : [0.01821679901331663] Val Score : [0.7379018553027905])\n",
            "Epoch : [39] Train loss : [0.01944840912308012] Val Score : [0.8041895926750926])\n",
            "Epoch : [40] Train loss : [0.01856930953051363] Val Score : [0.7725514640071602])\n",
            "Epoch 00041: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [41] Train loss : [0.017570941842028072] Val Score : [0.562253919707516])\n",
            "Epoch : [42] Train loss : [0.017197344452142715] Val Score : [0.755629357577611])\n",
            "Epoch : [43] Train loss : [0.017564755864441395] Val Score : [0.5320032001215638])\n",
            "Epoch : [44] Train loss : [0.017856258233743056] Val Score : [0.7379018553027905])\n",
            "Epoch : [45] Train loss : [0.017778985734496797] Val Score : [0.4997363518121419])\n",
            "Epoch : [46] Train loss : [0.017734671676797525] Val Score : [0.755629357577611])\n",
            "Epoch : [47] Train loss : [0.018198301616523947] Val Score : [0.7887218676684034])\n",
            "Epoch : [48] Train loss : [0.01749116461724043] Val Score : [0.7379018553027905])\n",
            "Epoch : [49] Train loss : [0.017945065296122005] Val Score : [0.7498242036425005])\n",
            "\n",
            "etc col : V29 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V30\n",
            "Epoch : [0] Train loss : [0.2704354609761919] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.11433353594371251] Val Score : [0.8331926764657618])\n",
            "Epoch : [2] Train loss : [0.09329343427504812] Val Score : [0.8189994908759815])\n",
            "Epoch : [3] Train loss : [0.07776694691606931] Val Score : [0.7887218676684034])\n",
            "Epoch : [4] Train loss : [0.0569264218211174] Val Score : [0.7725514640071602])\n",
            "Epoch : [5] Train loss : [0.050894412877304215] Val Score : [0.9165787375726882])\n",
            "Epoch : [6] Train loss : [0.04272437494780336] Val Score : [0.8927516353661109])\n",
            "Epoch : [7] Train loss : [0.03641381274376597] Val Score : [0.9137051774467988])\n",
            "Epoch : [8] Train loss : [0.033342912660113404] Val Score : [0.8189994908759815])\n",
            "Epoch : [9] Train loss : [0.03279552595423801] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.02924325117575271] Val Score : [0.9137051774467988])\n",
            "Epoch : [11] Train loss : [0.02987228267427002] Val Score : [0.9137051774467988])\n",
            "Epoch : [12] Train loss : [0.028005403067384447] Val Score : [0.8598769209128951])\n",
            "Epoch : [13] Train loss : [0.033520751632750034] Val Score : [0.8927516353661109])\n",
            "Epoch : [14] Train loss : [0.029644693514066085] Val Score : [0.8598769209128951])\n",
            "Epoch : [15] Train loss : [0.03266034913914544] Val Score : [0.8724347298745778])\n",
            "Epoch : [16] Train loss : [0.03402069264224598] Val Score : [0.8598769209128951])\n",
            "Epoch 00017: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [17] Train loss : [0.028931924008897374] Val Score : [0.8189994908759815])\n",
            "Epoch : [18] Train loss : [0.026416725079928125] Val Score : [0.8189994908759815])\n",
            "Epoch : [19] Train loss : [0.02607460679220302] Val Score : [0.8041895926750926])\n",
            "Epoch : [20] Train loss : [0.025295857739235674] Val Score : [0.7379018553027905])\n",
            "Epoch : [21] Train loss : [0.025617912677781924] Val Score : [0.7725514640071602])\n",
            "Epoch : [22] Train loss : [0.02757580777896302] Val Score : [0.8598769209128951])\n",
            "Epoch : [23] Train loss : [0.02379241106765611] Val Score : [0.8598769209128951])\n",
            "Epoch : [24] Train loss : [0.023987730965018272] Val Score : [0.755629357577611])\n",
            "Epoch : [25] Train loss : [0.02330613269337586] Val Score : [0.8598769209128951])\n",
            "Epoch : [26] Train loss : [0.024573059087353095] Val Score : [0.8041895926750926])\n",
            "Epoch : [27] Train loss : [0.02363796199538878] Val Score : [0.8331926764657618])\n",
            "Epoch 00028: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [28] Train loss : [0.023845197899000987] Val Score : [0.8041895926750926])\n",
            "Epoch : [29] Train loss : [0.025765734059470042] Val Score : [0.7887218676684034])\n",
            "Epoch : [30] Train loss : [0.02288685818868024] Val Score : [0.8189994908759815])\n",
            "Epoch : [31] Train loss : [0.023162487362112318] Val Score : [0.7379018553027905])\n",
            "Epoch : [32] Train loss : [0.021856305322476795] Val Score : [0.8041895926750926])\n",
            "Epoch : [33] Train loss : [0.021318965192352022] Val Score : [0.8041895926750926])\n",
            "Epoch : [34] Train loss : [0.022648931347898076] Val Score : [0.8041895926750926])\n",
            "Epoch : [35] Train loss : [0.024222167607929026] Val Score : [0.8041895926750926])\n",
            "Epoch : [36] Train loss : [0.02383504688207592] Val Score : [0.8041895926750926])\n",
            "Epoch : [37] Train loss : [0.021473849059215615] Val Score : [0.8041895926750926])\n",
            "Epoch : [38] Train loss : [0.02165981541786875] Val Score : [0.7379018553027905])\n",
            "Epoch 00039: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [39] Train loss : [0.022431049096797193] Val Score : [0.7887218676684034])\n",
            "Epoch : [40] Train loss : [0.0211004355390157] Val Score : [0.5309863425437672])\n",
            "Epoch : [41] Train loss : [0.021659552385764464] Val Score : [0.7379018553027905])\n",
            "Epoch : [42] Train loss : [0.021756819981549467] Val Score : [0.7379018553027905])\n",
            "Epoch : [43] Train loss : [0.020536350618515695] Val Score : [0.5320032001215638])\n",
            "Epoch : [44] Train loss : [0.021112790597336634] Val Score : [0.6889870340395065])\n",
            "Epoch : [45] Train loss : [0.02058016069765602] Val Score : [0.5906717950274928])\n",
            "Epoch : [46] Train loss : [0.02001287867980344] Val Score : [0.4997363518121419])\n",
            "Epoch : [47] Train loss : [0.019935775681265762] Val Score : [0.5320032001215638])\n",
            "Epoch : [48] Train loss : [0.021184643198336874] Val Score : [0.755629357577611])\n",
            "Epoch : [49] Train loss : [0.0211442517382758] Val Score : [0.7437178496040009])\n",
            "Epoch 00050: reducing learning rate of group 0 to 6.2500e-04.\n",
            "\n",
            "etc col : V30 / Marco F1 Score : 0.9165787375726882\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evalution"
      ],
      "metadata": {
        "id": "_MFNAKnKpCHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check(result, ts, val):\n",
        "\n",
        "  pred_result = []\n",
        "\n",
        "  for i in result:\n",
        "\n",
        "    if i >= ts:\n",
        "\n",
        "      i = 1\n",
        "\n",
        "    else:\n",
        "\n",
        "      i = 0\n",
        "\n",
        "    pred_result.append(i)\n",
        "\n",
        "  if val == True:\n",
        "\n",
        "    val_score = f1_score(y_val, pred_result, average='macro')\n",
        "    recall = recall_score(y_val, pred_result)\n",
        "    precision = precision_score(y_val, pred_result)\n",
        "\n",
        "    print(f'Marco F1 Score : {val_score}\\n')\n",
        "    print(f'Recall : {recall}\\n')\n",
        "    print(f'Precision : {precision}\\n')\n",
        "\n",
        "    print(classification_report(y_val, pred_result))\n",
        "\n",
        "  return pred_result"
      ],
      "metadata": {
        "id": "tvSbyHAh4mGk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_val = check(result_val, 16, val=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jPsytCf5YL0",
        "outputId": "94ed0606-6fb0-4808-b40d-03729e3bdbbe"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marco F1 Score : 0.9236496787663914\n",
            "\n",
            "Recall : 0.8333333333333334\n",
            "\n",
            "Precision : 0.8620689655172413\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     28432\n",
            "           1       0.86      0.83      0.85        30\n",
            "\n",
            "    accuracy                           1.00     28462\n",
            "   macro avg       0.93      0.92      0.92     28462\n",
            "weighted avg       1.00      1.00      1.00     28462\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix = confusion_matrix(y_val, pred_val)\n",
        "sns.heatmap(cf_matrix, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "2ik01IURFu15",
        "outputId": "0683eb89-4888-45c1-8e14-1428c7fbba6d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "M8c0IedopEGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test = check(result_test, 16, val=False)"
      ],
      "metadata": {
        "id": "WNBewGZxGMUI"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "2AxD3czQpFdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('./sample_submission.csv')"
      ],
      "metadata": {
        "id": "-9R_uDJSGbX7"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit['Class'] = pred_test\n",
        "submit.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JTk-Uq9TGl_O",
        "outputId": "aabf7b4d-16b5-4c92-998a-d315c3c5dec5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID  Class\n",
              "0  AAAA0x1      0\n",
              "1  AAAA0x2      0\n",
              "2  AAAA0x5      0\n",
              "3  AAAA0x7      0\n",
              "4  AAAA0xc      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b677f54-0b2d-4d6d-a1db-85a5d5f3141e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAAA0x1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAAA0x2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAAA0x5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAAA0x7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAAA0xc</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b677f54-0b2d-4d6d-a1db-85a5d5f3141e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b677f54-0b2d-4d6d-a1db-85a5d5f3141e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b677f54-0b2d-4d6d-a1db-85a5d5f3141e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit.to_csv('./E_Auto_Encoder.csv', index=False)"
      ],
      "metadata": {
        "id": "J01N6tyOGnOT"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}