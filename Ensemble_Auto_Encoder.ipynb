{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Uwe-PUxx1Flz"
      },
      "outputs": [],
      "source": [
        "# 데이터 다루기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "# 전처리\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.decomposition import PCA, KernelPCA, SparsePCA, TruncatedSVD, IncrementalPCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
        "\n",
        "# 모델링\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score # 재현율\n",
        "from sklearn.metrics import precision_score # 정밀도\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 기타\n",
        "import os\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "B7YGq6Py1HFA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.optim import Optimizer, AdamW\n",
        "from torch.optim.lr_scheduler import LambdaLR, CyclicLR, OneCycleLR"
      ],
      "metadata": {
        "id": "U-Df5snx1IVE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "1saXz_tA1KFq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')"
      ],
      "metadata": {
        "id": "VKVUFl5Z1Li8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(42) # Seed 고정"
      ],
      "metadata": {
        "id": "uJJcsV1r1Mt1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeVZI9271PKV",
        "outputId": "b05a7c1a-e4ec-4c3b-9cb7-9af34aa7e520"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip --qq '/content/drive/MyDrive/머신러닝 엔지니어링/데이콘/사기거래/data/사기거래.zip'"
      ],
      "metadata": {
        "id": "Hcg3DfOl1Qlr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/train.csv')\n",
        "val = pd.read_csv('/content/val.csv')\n",
        "test = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "EwSXD0ex1R0q"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, df, eval_mode):\n",
        "        self.df = df\n",
        "        self.eval_mode = eval_mode\n",
        "        if self.eval_mode:\n",
        "            self.labels = self.df['Class'].values\n",
        "            self.df = self.df.drop(columns=['Class']).values\n",
        "        else:\n",
        "            self.df = self.df.values\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        if self.eval_mode:\n",
        "            x = torch.from_numpy(self.df[index]).type(torch.FloatTensor)\n",
        "            y = torch.FloatTensor([self.labels[index]])\n",
        "            return x, y\n",
        "            #self.x = self.df[index]\n",
        "            #self.y = self.labels[index]\n",
        "            #return torch.Tensor(self.x), self.y\n",
        "        else:\n",
        "            self.x = self.df[index]\n",
        "            return torch.Tensor(self.x)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "metadata": {
        "id": "adZTW_tb3RpH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        self.Encoder = nn.Sequential(\n",
        "            nn.Linear(473,512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(512,1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(1024,2048),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(2048,4096),\n",
        "            nn.BatchNorm1d(4096),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.Decoder = nn.Sequential(\n",
        "            nn.Linear(4096,2048),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(2048,1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(1024,512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(512,473),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.Encoder(x)\n",
        "        x = self.Decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "NBYFd8UN3TgD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.scheduler = scheduler\n",
        "        self.device = device\n",
        "        # Loss Function\n",
        "        self.criterion = nn.L1Loss().to(self.device)\n",
        "        \n",
        "    def fit(self):\n",
        "        self.model.to(self.device)\n",
        "        best_score = 0\n",
        "        avg = 1\n",
        "        for epoch in range(50):\n",
        "            self.model.train()\n",
        "            train_loss = []\n",
        "            for x in iter(self.train_loader):\n",
        "                x = x.float().to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                _x = self.model(x)\n",
        "                loss = self.criterion(x, _x)\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                train_loss.append(loss.item())\n",
        "\n",
        "            score = self.validation(self.model, 0.95)\n",
        "            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n",
        "\n",
        "            if self.scheduler is not None:\n",
        "                self.scheduler.step(score)\n",
        "\n",
        "            if best_score <= score and avg > np.mean(train_loss):\n",
        "                best_score = score\n",
        "                avg = np.mean(train_loss)\n",
        "                torch.save(model.module.state_dict(), './best_model.pth', _use_new_zipfile_serialization=False)\n",
        "    \n",
        "    def validation(self, eval_model, thr):\n",
        "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "        eval_model.eval()\n",
        "        pred = []\n",
        "        true = []\n",
        "        with torch.no_grad():\n",
        "            for x, y in iter(self.val_loader):\n",
        "                x = x.float().to(self.device)\n",
        "\n",
        "                _x = self.model(x)\n",
        "                diff = cos(x, _x).cpu().tolist()\n",
        "                batch_pred = np.where(np.array(diff)<thr, 1, 0).tolist()\n",
        "                pred += batch_pred\n",
        "                true += y.tolist()\n",
        "\n",
        "        return f1_score(true, pred, average='macro')"
      ],
      "metadata": {
        "id": "XXsRIChU3ge-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(model, thr, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "    pred = []\n",
        "    with torch.no_grad():\n",
        "        for x in iter(test_loader):\n",
        "            x = x.float().to(device)\n",
        "            _x = model(x)\n",
        "            \n",
        "            diff = cos(x, _x).cpu().tolist()\n",
        "            batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n",
        "            pred += batch_pred\n",
        "    return pred"
      ],
      "metadata": {
        "id": "-rCC4zAp3iSq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.drop(columns=['ID']) \n",
        "\n",
        "X_val = val.drop(columns=['ID', 'Class']) \n",
        "y_val = val['Class']\n",
        "\n",
        "X_test = test.drop(columns=['ID'])"
      ],
      "metadata": {
        "id": "1th0Lc6h1TTk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[['V3', 'V4', 'V9', 'V10', 'V11',\n",
        "                   'V12', 'V14', 'V16', 'V17', 'V18']]\n",
        "\n",
        "X_val = X_val[['V3', 'V4', 'V9', 'V10', 'V11',\n",
        "               'V12', 'V14', 'V16', 'V17', 'V18']]\n",
        "\n",
        "X_test = X_test[['V3', 'V4', 'V9', 'V10', 'V11',\n",
        "                 'V12', 'V14', 'V16', 'V17', 'V18']]"
      ],
      "metadata": {
        "id": "suWUzg_w1UO4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_drop_cols = list(X_train.columns) + ['ID']\n",
        "\n",
        "list_etc_cols = list(train.drop(columns=list_drop_cols))"
      ],
      "metadata": {
        "id": "n5MQTkr_1Vsr"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list_etc_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoPjhwYcGHIy",
        "outputId": "2aa9d195-80f5-4b5d-f8a9-ebd3d43f123d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_val = np.zeros(val.shape[0])\n",
        "result_test = np.zeros(test.shape[0])\n",
        "\n",
        "y_val = val[['Class']]\n",
        "\n",
        "for etc_col in list_etc_cols:\n",
        "\n",
        "  X_train = pd.concat([X_train, train[[etc_col]]], axis=1)\n",
        "  X_val = pd.concat([X_val, val[[etc_col]]], axis=1)\n",
        "  X_test = pd.concat([X_test, test[[etc_col]]], axis=1)\n",
        "\n",
        "  scaler = RobustScaler(quantile_range=(45.0, 55.0))\n",
        "\n",
        "  scaled_train = scaler.fit_transform(X_train)\n",
        "\n",
        "  scaled_val = scaler.transform(X_val)\n",
        "  scaled_test = scaler.transform(X_test)\n",
        "\n",
        "  scaled_train = pd.DataFrame(scaled_train)\n",
        "  scaled_val = pd.DataFrame(scaled_val)\n",
        "  scaled_test = pd.DataFrame(scaled_test)\n",
        "\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "\n",
        "  scaled_train = scaler.fit_transform(scaled_train)\n",
        "  scaled_val = scaler.transform(scaled_val)\n",
        "  scaled_test = scaler.transform(scaled_test)\n",
        "\n",
        "  scaled_train = pd.DataFrame(scaled_train)\n",
        "  scaled_val = pd.DataFrame(scaled_val)\n",
        "  scaled_test = pd.DataFrame(scaled_test)\n",
        "\n",
        "  main_columns = list(scaled_train.columns)\n",
        "\n",
        "  com_main = list(combinations(main_columns, 5))\n",
        "\n",
        "  for com in com_main:\n",
        "\n",
        "    x = com[0]\n",
        "    y = com[1]\n",
        "    z = com[2]\n",
        "    w = com[3]\n",
        "    v = com[-1]\n",
        "\n",
        "    scaled_train[f'{x}_{y}_{z}_{w}_{v}_mean'] = (scaled_train[x] + scaled_train[y] + scaled_train[z] + scaled_train[w] + scaled_train[v]) / 5\n",
        "    scaled_val[f'{x}_{y}_{z}_{w}_{v}_mean'] = (scaled_val[x] + scaled_val[y] + scaled_val[z] + scaled_val[w] + scaled_val[v]) / 5\n",
        "    scaled_test[f'{x}_{y}_{z}_{w}_{v}_mean'] = (scaled_test[x] + scaled_test[y] + scaled_test[z] + scaled_test[w] + scaled_test[v]) / 5\n",
        "  \n",
        "  dimesion_reducer = SparseRandomProjection(n_components=473, eps=0.1, random_state=42)\n",
        "\n",
        "\n",
        "  reduced_train = dimesion_reducer.fit_transform(scaled_train)\n",
        "  reduced_val = dimesion_reducer.transform(scaled_val)\n",
        "  reduced_test = dimesion_reducer.transform(scaled_test)\n",
        "\n",
        "  reduced_train = pd.DataFrame(reduced_train)\n",
        "  reduced_val = pd.DataFrame(reduced_val)\n",
        "  reduced_test = pd.DataFrame(reduced_test)\n",
        "\n",
        "  print()\n",
        "  print('-'*100)\n",
        "  print()\n",
        "  print(f'{etc_col}')\n",
        "\n",
        "  train_dataset = MyDataset(df=reduced_train, eval_mode=False)\n",
        "  train_loader = DataLoader(train_dataset, batch_size=2**13, shuffle=True, num_workers=6)\n",
        "\n",
        "  reduced_val=pd.concat([reduced_val, val[['Class']]], axis=1)\n",
        "  val_dataset = MyDataset(df=reduced_val, eval_mode=True)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=2**13, shuffle=False, num_workers=6)\n",
        "\n",
        "  model = nn.DataParallel(AutoEncoder())\n",
        "  model.eval()\n",
        "  optimizer = torch.optim.Adam(params = model.parameters(), lr = 1e-2)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
        "\n",
        "  trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n",
        "  trainer.fit()\n",
        "\n",
        "  model = AutoEncoder()\n",
        "  model.load_state_dict(torch.load('./best_model.pth'))\n",
        "  model = nn.DataParallel(model)\n",
        "  model.eval()\n",
        "\n",
        "  reduced_val = reduced_val.drop(columns=['Class'])\n",
        "  val_dataset = MyDataset(reduced_val, False)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=2**13, shuffle=False, num_workers=6)\n",
        "\n",
        "  pred_val = prediction(model, 0.95, val_loader, device)\n",
        "  result_val += pred_val\n",
        "\n",
        "  val_score = f1_score(y_val, pred_val, average='macro')\n",
        "  print(f'\\netc col : {etc_col} / Marco F1 Score : {val_score}\\n')\n",
        "\n",
        "  test_dataset = MyDataset(reduced_test, False)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=2**13, shuffle=False, num_workers=6)\n",
        "\n",
        "  pred_test = prediction(model, 0.95, test_loader, device)\n",
        "  result_test += pred_test\n",
        "\n",
        "  X_train = X_train.drop(columns=etc_col)\n",
        "  X_val = X_val.drop(columns=etc_col)\n",
        "  X_test = X_test.drop(columns=etc_col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OVQIg-J2Gao",
        "outputId": "3b4165b2-7cf2-4d54-f154-508b5b3f2e77"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V1\n",
            "Epoch : [0] Train loss : [0.3524628590260233] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.10534716131431716] Val Score : [0.0010881344945152598])\n",
            "Epoch : [2] Train loss : [0.07976299444479602] Val Score : [0.5338563455730152])\n",
            "Epoch : [3] Train loss : [0.052443762842033594] Val Score : [0.8786471773914175])\n",
            "Epoch : [4] Train loss : [0.038795128863837035] Val Score : [0.8674887641844412])\n",
            "Epoch : [5] Train loss : [0.05193223697798593] Val Score : [0.8786471773914175])\n",
            "Epoch : [6] Train loss : [0.041913182607718875] Val Score : [0.872984830495149])\n",
            "Epoch : [7] Train loss : [0.048135669635874886] Val Score : [0.9165787375726882])\n",
            "Epoch : [8] Train loss : [0.04364072451634066] Val Score : [0.9165787375726882])\n",
            "Epoch : [9] Train loss : [0.04164548763739211] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.057302744793040414] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.048226263241044114] Val Score : [0.9165787375726882])\n",
            "Epoch : [12] Train loss : [0.027913026245576993] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.028725719478513514] Val Score : [0.9165787375726882])\n",
            "Epoch : [14] Train loss : [0.02727084101310798] Val Score : [0.9165787375726882])\n",
            "Epoch : [15] Train loss : [0.0359518343050565] Val Score : [0.9097393418694286])\n",
            "Epoch : [16] Train loss : [0.022185307129153183] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.022507299669086933] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.03396251198968717] Val Score : [0.9165787375726882])\n",
            "Epoch 00019: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [19] Train loss : [0.026335155458322594] Val Score : [0.9165787375726882])\n",
            "Epoch : [20] Train loss : [0.023503591572599753] Val Score : [0.9137051774467988])\n",
            "Epoch : [21] Train loss : [0.018879993951746395] Val Score : [0.9165787375726882])\n",
            "Epoch : [22] Train loss : [0.02030478377959558] Val Score : [0.9236496787663914])\n",
            "Epoch : [23] Train loss : [0.022071488201618195] Val Score : [0.9137051774467988])\n",
            "Epoch : [24] Train loss : [0.019558255693742206] Val Score : [0.9236496787663914])\n",
            "Epoch : [25] Train loss : [0.017591037787497044] Val Score : [0.9165787375726882])\n",
            "Epoch : [26] Train loss : [0.01696382276713848] Val Score : [0.9165787375726882])\n",
            "Epoch : [27] Train loss : [0.019891750067472458] Val Score : [0.9165787375726882])\n",
            "Epoch : [28] Train loss : [0.01589355996942946] Val Score : [0.9165787375726882])\n",
            "Epoch : [29] Train loss : [0.015120123579565967] Val Score : [0.9137051774467988])\n",
            "Epoch : [30] Train loss : [0.01528503093868494] Val Score : [0.9137051774467988])\n",
            "Epoch : [31] Train loss : [0.01692003051617316] Val Score : [0.9165787375726882])\n",
            "Epoch : [32] Train loss : [0.0138394973639931] Val Score : [0.9165787375726882])\n",
            "Epoch : [33] Train loss : [0.01331486233643123] Val Score : [0.9165787375726882])\n",
            "Epoch 00034: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [34] Train loss : [0.01288879629490631] Val Score : [0.8598769209128951])\n",
            "Epoch : [35] Train loss : [0.012720606489373105] Val Score : [0.899903286500554])\n",
            "Epoch : [36] Train loss : [0.012568212380366666] Val Score : [0.8331926764657618])\n",
            "Epoch : [37] Train loss : [0.012499457890433925] Val Score : [0.8887833851083367])\n",
            "Epoch : [38] Train loss : [0.012038135302386113] Val Score : [0.8598769209128951])\n",
            "Epoch : [39] Train loss : [0.011900849507323332] Val Score : [0.8331926764657618])\n",
            "Epoch : [40] Train loss : [0.011681353473769767] Val Score : [0.8724347298745778])\n",
            "Epoch : [41] Train loss : [0.011738603202892202] Val Score : [0.8598769209128951])\n",
            "Epoch : [42] Train loss : [0.011558360819305693] Val Score : [0.8598769209128951])\n",
            "Epoch : [43] Train loss : [0.011355785519949027] Val Score : [0.846806907378336])\n",
            "Epoch : [44] Train loss : [0.01127124737415995] Val Score : [0.8598769209128951])\n",
            "Epoch 00045: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [45] Train loss : [0.011066603740411145] Val Score : [0.8189994908759815])\n",
            "Epoch : [46] Train loss : [0.011159139618809735] Val Score : [0.8189994908759815])\n",
            "Epoch : [47] Train loss : [0.010745522965277945] Val Score : [0.8041895926750926])\n",
            "Epoch : [48] Train loss : [0.010685780950422798] Val Score : [0.8041895926750926])\n",
            "Epoch : [49] Train loss : [0.010583003384194203] Val Score : [0.8041895926750926])\n",
            "\n",
            "etc col : V1 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V2\n",
            "Epoch : [0] Train loss : [0.26984418822186335] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.1376368190561022] Val Score : [0.001053203360564854])\n",
            "Epoch : [2] Train loss : [0.05679584374385221] Val Score : [0.5065834888680203])\n",
            "Epoch : [3] Train loss : [0.053251701939318864] Val Score : [0.9097393418694286])\n",
            "Epoch : [4] Train loss : [0.04731868912598917] Val Score : [0.8202665410912253])\n",
            "Epoch : [5] Train loss : [0.05777457010533128] Val Score : [0.8621517488551477])\n",
            "Epoch : [6] Train loss : [0.0824892848197903] Val Score : [0.9097393418694286])\n",
            "Epoch : [7] Train loss : [0.07597817427345685] Val Score : [0.9097393418694286])\n",
            "Epoch : [8] Train loss : [0.044182716868817806] Val Score : [0.8967110829723166])\n",
            "Epoch : [9] Train loss : [0.04250061817999397] Val Score : [0.890501890608512])\n",
            "Epoch : [10] Train loss : [0.050606941272105486] Val Score : [0.8967110829723166])\n",
            "Epoch : [11] Train loss : [0.050845508729772906] Val Score : [0.8967110829723166])\n",
            "Epoch : [12] Train loss : [0.05113813906375851] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.030929632484912872] Val Score : [0.9097393418694286])\n",
            "Epoch : [14] Train loss : [0.028554017522505352] Val Score : [0.8967110829723166])\n",
            "Epoch : [15] Train loss : [0.023237492623073713] Val Score : [0.890501890608512])\n",
            "Epoch : [16] Train loss : [0.02420586866459676] Val Score : [0.8967110829723166])\n",
            "Epoch : [17] Train loss : [0.026910189805286273] Val Score : [0.890501890608512])\n",
            "Epoch : [18] Train loss : [0.025704541110566685] Val Score : [0.8786471773914175])\n",
            "Epoch : [19] Train loss : [0.020905665255018642] Val Score : [0.8786471773914175])\n",
            "Epoch : [20] Train loss : [0.028997022259448255] Val Score : [0.8621517488551477])\n",
            "Epoch : [21] Train loss : [0.02000202251864331] Val Score : [0.8786471773914175])\n",
            "Epoch : [22] Train loss : [0.018452365150941268] Val Score : [0.8844834793761085])\n",
            "Epoch : [23] Train loss : [0.01750923347260271] Val Score : [0.8844834793761085])\n",
            "Epoch 00024: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [24] Train loss : [0.013696694946182626] Val Score : [0.9097393418694286])\n",
            "Epoch : [25] Train loss : [0.01285840550969754] Val Score : [0.9097393418694286])\n",
            "Epoch : [26] Train loss : [0.01176619709336332] Val Score : [0.9137051774467988])\n",
            "Epoch : [27] Train loss : [0.01327074212687356] Val Score : [0.9137051774467988])\n",
            "Epoch : [28] Train loss : [0.01199669111520052] Val Score : [0.9137051774467988])\n",
            "Epoch : [29] Train loss : [0.01119649370333978] Val Score : [0.9034120550289857])\n",
            "Epoch : [30] Train loss : [0.010851538407483272] Val Score : [0.9137051774467988])\n",
            "Epoch : [31] Train loss : [0.010475935680525643] Val Score : [0.9066829407144783])\n",
            "Epoch : [32] Train loss : [0.010174817738256283] Val Score : [0.9034120550289857])\n",
            "Epoch : [33] Train loss : [0.009977896298680986] Val Score : [0.9034120550289857])\n",
            "Epoch : [34] Train loss : [0.009725480872605528] Val Score : [0.9165787375726882])\n",
            "Epoch 00035: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [35] Train loss : [0.009246745545949255] Val Score : [0.8772441968135101])\n",
            "Epoch : [36] Train loss : [0.009071174609873976] Val Score : [0.8331926764657618])\n",
            "Epoch : [37] Train loss : [0.008777043050421136] Val Score : [0.8331926764657618])\n",
            "Epoch : [38] Train loss : [0.008448627910443715] Val Score : [0.8331926764657618])\n",
            "Epoch : [39] Train loss : [0.008403535799256392] Val Score : [0.8331926764657618])\n",
            "Epoch : [40] Train loss : [0.008159899152815342] Val Score : [0.8331926764657618])\n",
            "Epoch : [41] Train loss : [0.008138366309659821] Val Score : [0.8652615319692264])\n",
            "Epoch : [42] Train loss : [0.008039187506905623] Val Score : [0.8331926764657618])\n",
            "Epoch : [43] Train loss : [0.00788628333248198] Val Score : [0.8331926764657618])\n",
            "Epoch : [44] Train loss : [0.007866107659148318] Val Score : [0.8331926764657618])\n",
            "Epoch : [45] Train loss : [0.007764536355222974] Val Score : [0.8331926764657618])\n",
            "Epoch 00046: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [46] Train loss : [0.0075543274038604325] Val Score : [0.7887218676684034])\n",
            "Epoch : [47] Train loss : [0.007520465912031276] Val Score : [0.7887218676684034])\n",
            "Epoch : [48] Train loss : [0.007649793056771159] Val Score : [0.8041895926750926])\n",
            "Epoch : [49] Train loss : [0.0075441173809979644] Val Score : [0.8041895926750926])\n",
            "\n",
            "etc col : V2 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V5\n",
            "Epoch : [0] Train loss : [0.3946494885853359] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.14751009802733148] Val Score : [0.0010881344945152598])\n",
            "Epoch : [2] Train loss : [0.11102968427751746] Val Score : [0.3899934325876208])\n",
            "Epoch : [3] Train loss : [0.04973476978817156] Val Score : [0.7743645687973808])\n",
            "Epoch : [4] Train loss : [0.04168583971581289] Val Score : [0.890501890608512])\n",
            "Epoch : [5] Train loss : [0.033604097951735766] Val Score : [0.7792091738512393])\n",
            "Epoch : [6] Train loss : [0.02960317555282797] Val Score : [0.7837566139258728])\n",
            "Epoch : [7] Train loss : [0.03522252876843725] Val Score : [0.8422634702634115])\n",
            "Epoch : [8] Train loss : [0.032448372670582364] Val Score : [0.872984830495149])\n",
            "Epoch : [9] Train loss : [0.03636650115783725] Val Score : [0.9031202878275757])\n",
            "Epoch : [10] Train loss : [0.03875178777213607] Val Score : [0.7870308296420961])\n",
            "Epoch : [11] Train loss : [0.028893733264080117] Val Score : [0.9031202878275757])\n",
            "Epoch : [12] Train loss : [0.035318021795579364] Val Score : [0.6313838467272398])\n",
            "Epoch : [13] Train loss : [0.038187960029712746] Val Score : [0.7073573830525186])\n",
            "Epoch : [14] Train loss : [0.03112253999071462] Val Score : [0.8376267560436427])\n",
            "Epoch : [15] Train loss : [0.030259542167186737] Val Score : [0.8422634702634115])\n",
            "Epoch : [16] Train loss : [0.0329056005658848] Val Score : [0.8470287373843977])\n",
            "Epoch : [17] Train loss : [0.027006932800369605] Val Score : [0.8422634702634115])\n",
            "Epoch : [18] Train loss : [0.025920125655829906] Val Score : [0.8422634702634115])\n",
            "Epoch : [19] Train loss : [0.020915707839386805] Val Score : [0.8376267560436427])\n",
            "Epoch : [20] Train loss : [0.02223112021705934] Val Score : [0.8786471773914175])\n",
            "Epoch 00021: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [21] Train loss : [0.015782752872577736] Val Score : [0.9097393418694286])\n",
            "Epoch : [22] Train loss : [0.01498545500050698] Val Score : [0.9097393418694286])\n",
            "Epoch : [23] Train loss : [0.013868678361177444] Val Score : [0.9097393418694286])\n",
            "Epoch : [24] Train loss : [0.01415470362241779] Val Score : [0.9097393418694286])\n",
            "Epoch : [25] Train loss : [0.013512814683573586] Val Score : [0.9097393418694286])\n",
            "Epoch : [26] Train loss : [0.013137358373829297] Val Score : [0.9097393418694286])\n",
            "Epoch : [27] Train loss : [0.013424445143235582] Val Score : [0.9165787375726882])\n",
            "Epoch : [28] Train loss : [0.013347813660012824] Val Score : [0.9097393418694286])\n",
            "Epoch : [29] Train loss : [0.013394372072070837] Val Score : [0.9031202878275757])\n",
            "Epoch : [30] Train loss : [0.01259690589670624] Val Score : [0.9165787375726882])\n",
            "Epoch : [31] Train loss : [0.012796289220984493] Val Score : [0.9097393418694286])\n",
            "Epoch : [32] Train loss : [0.011565872468054295] Val Score : [0.9097393418694286])\n",
            "Epoch : [33] Train loss : [0.011352951438831431] Val Score : [0.9165787375726882])\n",
            "Epoch : [34] Train loss : [0.011489622694041048] Val Score : [0.9165787375726882])\n",
            "Epoch : [35] Train loss : [0.011038759058075292] Val Score : [0.9097393418694286])\n",
            "Epoch : [36] Train loss : [0.010727312349315201] Val Score : [0.9165787375726882])\n",
            "Epoch : [37] Train loss : [0.01071600110403129] Val Score : [0.9097393418694286])\n",
            "Epoch : [38] Train loss : [0.010822859925350972] Val Score : [0.9165787375726882])\n",
            "Epoch 00039: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [39] Train loss : [0.010260727722197771] Val Score : [0.8927516353661109])\n",
            "Epoch : [40] Train loss : [0.010055857777063335] Val Score : [0.8652615319692264])\n",
            "Epoch : [41] Train loss : [0.00994431074442608] Val Score : [0.8927516353661109])\n",
            "Epoch : [42] Train loss : [0.009887058953089374] Val Score : [0.899903286500554])\n",
            "Epoch : [43] Train loss : [0.00986967548461897] Val Score : [0.8772441968135101])\n",
            "Epoch : [44] Train loss : [0.009839080540197236] Val Score : [0.899903286500554])\n",
            "Epoch : [45] Train loss : [0.009721015247383289] Val Score : [0.8927516353661109])\n",
            "Epoch : [46] Train loss : [0.01056758440764887] Val Score : [0.9034120550289857])\n",
            "Epoch : [47] Train loss : [0.011041221541485615] Val Score : [0.9137051774467988])\n",
            "Epoch : [48] Train loss : [0.010183696036360093] Val Score : [0.9034120550289857])\n",
            "Epoch : [49] Train loss : [0.010331427345850639] Val Score : [0.9137051774467988])\n",
            "Epoch 00050: reducing learning rate of group 0 to 1.2500e-03.\n",
            "\n",
            "etc col : V5 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V6\n",
            "Epoch : [0] Train loss : [0.30138425369347843] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.08632142921643597] Val Score : [0.1496127851811303])\n",
            "Epoch : [2] Train loss : [0.08377462173146862] Val Score : [0.8674887641844412])\n",
            "Epoch : [3] Train loss : [0.0647610008184399] Val Score : [0.9165787375726882])\n",
            "Epoch : [4] Train loss : [0.049835718769047944] Val Score : [0.6449572053190307])\n",
            "Epoch : [5] Train loss : [0.05777268244751862] Val Score : [0.9165787375726882])\n",
            "Epoch : [6] Train loss : [0.04613451885857752] Val Score : [0.012504328987197288])\n",
            "Epoch : [7] Train loss : [0.04056054912507534] Val Score : [0.9165787375726882])\n",
            "Epoch : [8] Train loss : [0.044048592049096315] Val Score : [0.9165787375726882])\n",
            "Epoch : [9] Train loss : [0.05683910487485783] Val Score : [0.8967110829723166])\n",
            "Epoch : [10] Train loss : [0.03953909248645816] Val Score : [0.43952042726559487])\n",
            "Epoch : [11] Train loss : [0.03803866050605263] Val Score : [0.7358531987954313])\n",
            "Epoch : [12] Train loss : [0.029387753323784897] Val Score : [0.740247921816494])\n",
            "Epoch : [13] Train loss : [0.03047778790018388] Val Score : [0.7973199624677456])\n",
            "Epoch : [14] Train loss : [0.03761978926403182] Val Score : [0.5340596006298505])\n",
            "Epoch 00015: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [15] Train loss : [0.02324506640434265] Val Score : [0.9165787375726882])\n",
            "Epoch : [16] Train loss : [0.02313436208558934] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.019896700911756073] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.020457165515316383] Val Score : [0.9165787375726882])\n",
            "Epoch : [19] Train loss : [0.02142810495570302] Val Score : [0.9165787375726882])\n",
            "Epoch : [20] Train loss : [0.021897951140999794] Val Score : [0.856966968023358])\n",
            "Epoch : [21] Train loss : [0.022927932973418916] Val Score : [0.9097393418694286])\n",
            "Epoch : [22] Train loss : [0.023019063153437207] Val Score : [0.9165787375726882])\n",
            "Epoch : [23] Train loss : [0.018066496920904944] Val Score : [0.9097393418694286])\n",
            "Epoch : [24] Train loss : [0.017817242669739893] Val Score : [0.9165787375726882])\n",
            "Epoch : [25] Train loss : [0.015606234182736703] Val Score : [0.9165787375726882])\n",
            "Epoch 00026: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [26] Train loss : [0.013240038084664516] Val Score : [0.9137051774467988])\n",
            "Epoch : [27] Train loss : [0.013199162602956806] Val Score : [0.899903286500554])\n",
            "Epoch : [28] Train loss : [0.013688628761363881] Val Score : [0.899903286500554])\n",
            "Epoch : [29] Train loss : [0.013332750980875321] Val Score : [0.899903286500554])\n",
            "Epoch : [30] Train loss : [0.013005717324891261] Val Score : [0.8887833851083367])\n",
            "Epoch : [31] Train loss : [0.013476301383759295] Val Score : [0.8887833851083367])\n",
            "Epoch : [32] Train loss : [0.012445979884692602] Val Score : [0.8887833851083367])\n",
            "Epoch : [33] Train loss : [0.012212632623101984] Val Score : [0.899903286500554])\n",
            "Epoch : [34] Train loss : [0.012195141786443335] Val Score : [0.8724347298745778])\n",
            "Epoch : [35] Train loss : [0.011996749256338392] Val Score : [0.8887833851083367])\n",
            "Epoch : [36] Train loss : [0.011958346303020204] Val Score : [0.9137051774467988])\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [37] Train loss : [0.012041334328906876] Val Score : [0.8041895926750926])\n",
            "Epoch : [38] Train loss : [0.011193198950162955] Val Score : [0.8331926764657618])\n",
            "Epoch : [39] Train loss : [0.011025630536356143] Val Score : [0.8331926764657618])\n",
            "Epoch : [40] Train loss : [0.010652346203901939] Val Score : [0.8041895926750926])\n",
            "Epoch : [41] Train loss : [0.010960853059909173] Val Score : [0.8331926764657618])\n",
            "Epoch : [42] Train loss : [0.0105164535343647] Val Score : [0.8189994908759815])\n",
            "Epoch : [43] Train loss : [0.010512052170400108] Val Score : [0.8331926764657618])\n",
            "Epoch : [44] Train loss : [0.010275781819862979] Val Score : [0.8041895926750926])\n",
            "Epoch : [45] Train loss : [0.010230843576469592] Val Score : [0.8189994908759815])\n",
            "Epoch : [46] Train loss : [0.010213252023926802] Val Score : [0.8189994908759815])\n",
            "Epoch : [47] Train loss : [0.01010547751294715] Val Score : [0.8331926764657618])\n",
            "Epoch 00048: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [48] Train loss : [0.009887812260006155] Val Score : [0.7887218676684034])\n",
            "Epoch : [49] Train loss : [0.009824871883860655] Val Score : [0.755629357577611])\n",
            "\n",
            "etc col : V6 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V7\n",
            "Epoch : [0] Train loss : [0.27694952487945557] Val Score : [0.0009828009828009828])\n",
            "Epoch : [1] Train loss : [0.09627364416207586] Val Score : [0.22780607236006017])\n",
            "Epoch : [2] Train loss : [0.05038686668766396] Val Score : [0.2626527450716657])\n",
            "Epoch : [3] Train loss : [0.07901557827634471] Val Score : [0.9165787375726882])\n",
            "Epoch : [4] Train loss : [0.04497072246990034] Val Score : [0.004176734151035529])\n",
            "Epoch : [5] Train loss : [0.03907010890543461] Val Score : [0.2917064986012442])\n",
            "Epoch : [6] Train loss : [0.04481007531285286] Val Score : [0.8621517488551477])\n",
            "Epoch : [7] Train loss : [0.03806293463068349] Val Score : [0.4245973620957263])\n",
            "Epoch : [8] Train loss : [0.03468648490629026] Val Score : [0.5078643271200386])\n",
            "Epoch : [9] Train loss : [0.038090541559670656] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.036319449943091185] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.03622132233743157] Val Score : [0.9097393418694286])\n",
            "Epoch : [12] Train loss : [0.03336205905569451] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.031099409397159303] Val Score : [0.6121373512210138])\n",
            "Epoch : [14] Train loss : [0.02396252006292343] Val Score : [0.833113452596645])\n",
            "Epoch 00015: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [15] Train loss : [0.019819187532578195] Val Score : [0.9165787375726882])\n",
            "Epoch : [16] Train loss : [0.026298308611980507] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.025401092799646512] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.020932552072086504] Val Score : [0.9165787375726882])\n",
            "Epoch : [19] Train loss : [0.019308626053056548] Val Score : [0.9165787375726882])\n",
            "Epoch : [20] Train loss : [0.022729282533483847] Val Score : [0.9165787375726882])\n",
            "Epoch : [21] Train loss : [0.020747327245771885] Val Score : [0.9165787375726882])\n",
            "Epoch : [22] Train loss : [0.019197323226502964] Val Score : [0.9165787375726882])\n",
            "Epoch : [23] Train loss : [0.015144410742712873] Val Score : [0.9165787375726882])\n",
            "Epoch : [24] Train loss : [0.017331328708678484] Val Score : [0.9165787375726882])\n",
            "Epoch : [25] Train loss : [0.013615279059324945] Val Score : [0.9165787375726882])\n",
            "Epoch 00026: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [26] Train loss : [0.01335120014846325] Val Score : [0.8927516353661109])\n",
            "Epoch : [27] Train loss : [0.013643285991357905] Val Score : [0.8927516353661109])\n",
            "Epoch : [28] Train loss : [0.012989133263805084] Val Score : [0.8927516353661109])\n",
            "Epoch : [29] Train loss : [0.012347356083669834] Val Score : [0.8652615319692264])\n",
            "Epoch : [30] Train loss : [0.012334237407360758] Val Score : [0.846806907378336])\n",
            "Epoch : [31] Train loss : [0.011857363528438978] Val Score : [0.8331926764657618])\n",
            "Epoch : [32] Train loss : [0.01164823364732521] Val Score : [0.8652615319692264])\n",
            "Epoch : [33] Train loss : [0.011639736925384827] Val Score : [0.8331926764657618])\n",
            "Epoch : [34] Train loss : [0.011768812114106757] Val Score : [0.899903286500554])\n",
            "Epoch : [35] Train loss : [0.01171984929325325] Val Score : [0.8528093037014359])\n",
            "Epoch : [36] Train loss : [0.011766543412314994] Val Score : [0.846806907378336])\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [37] Train loss : [0.011351905430534057] Val Score : [0.8331926764657618])\n",
            "Epoch : [38] Train loss : [0.011143923670585667] Val Score : [0.8041895926750926])\n",
            "Epoch : [39] Train loss : [0.011072904536766666] Val Score : [0.8041895926750926])\n",
            "Epoch : [40] Train loss : [0.01100450221981321] Val Score : [0.8041895926750926])\n",
            "Epoch : [41] Train loss : [0.010835771116295032] Val Score : [0.8041895926750926])\n",
            "Epoch : [42] Train loss : [0.010635819552200181] Val Score : [0.7887218676684034])\n",
            "Epoch : [43] Train loss : [0.010557902910347496] Val Score : [0.8189994908759815])\n",
            "Epoch : [44] Train loss : [0.010483651488487209] Val Score : [0.8041895926750926])\n",
            "Epoch : [45] Train loss : [0.010256799137485879] Val Score : [0.8041895926750926])\n",
            "Epoch : [46] Train loss : [0.010236742972795452] Val Score : [0.8041895926750926])\n",
            "Epoch : [47] Train loss : [0.010003778817398208] Val Score : [0.8041895926750926])\n",
            "Epoch 00048: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [48] Train loss : [0.009881461371800728] Val Score : [0.8041895926750926])\n",
            "Epoch : [49] Train loss : [0.00978797541132995] Val Score : [0.7887218676684034])\n",
            "\n",
            "etc col : V7 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V8\n",
            "Epoch : [0] Train loss : [0.3169767436172281] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.08421146204429013] Val Score : [0.8189994908759815])\n",
            "Epoch : [2] Train loss : [0.08461093024483748] Val Score : [0.8927516353661109])\n",
            "Epoch : [3] Train loss : [0.052063987723418644] Val Score : [0.7544619903503269])\n",
            "Epoch : [4] Train loss : [0.030475097841450145] Val Score : [0.8247537119133066])\n",
            "Epoch : [5] Train loss : [0.0620380983288799] Val Score : [0.6810168574315032])\n",
            "Epoch : [6] Train loss : [0.06899976464254516] Val Score : [0.9031202878275757])\n",
            "Epoch : [7] Train loss : [0.04047137113021953] Val Score : [0.8621517488551477])\n",
            "Epoch : [8] Train loss : [0.0359932543443782] Val Score : [0.9097393418694286])\n",
            "Epoch : [9] Train loss : [0.034582797570952346] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.037637428513595035] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.027579439005681446] Val Score : [0.9097393418694286])\n",
            "Epoch : [12] Train loss : [0.035443692335060666] Val Score : [0.9097393418694286])\n",
            "Epoch : [13] Train loss : [0.03176818694919348] Val Score : [0.9097393418694286])\n",
            "Epoch : [14] Train loss : [0.035801228801054616] Val Score : [0.9097393418694286])\n",
            "Epoch : [15] Train loss : [0.032059602705495696] Val Score : [0.9165787375726882])\n",
            "Epoch : [16] Train loss : [0.025168640672096183] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.02527687352682863] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.02175511499600751] Val Score : [0.9031202878275757])\n",
            "Epoch : [19] Train loss : [0.03548652771860361] Val Score : [0.49132292643100783])\n",
            "Epoch : [20] Train loss : [0.025010007300547192] Val Score : [0.5149958277619178])\n",
            "Epoch 00021: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [21] Train loss : [0.018281500187835524] Val Score : [0.9165787375726882])\n",
            "Epoch : [22] Train loss : [0.018291143234819174] Val Score : [0.9165787375726882])\n",
            "Epoch : [23] Train loss : [0.0181536182229008] Val Score : [0.9165787375726882])\n",
            "Epoch : [24] Train loss : [0.015957734481032406] Val Score : [0.9165787375726882])\n",
            "Epoch : [25] Train loss : [0.014471964711057288] Val Score : [0.9165787375726882])\n",
            "Epoch : [26] Train loss : [0.013294910280300038] Val Score : [0.9137051774467988])\n",
            "Epoch : [27] Train loss : [0.014417878086013454] Val Score : [0.9165787375726882])\n",
            "Epoch : [28] Train loss : [0.015320009751511472] Val Score : [0.9165787375726882])\n",
            "Epoch : [29] Train loss : [0.014837840039815222] Val Score : [0.9165787375726882])\n",
            "Epoch : [30] Train loss : [0.014203988946974277] Val Score : [0.9165787375726882])\n",
            "Epoch : [31] Train loss : [0.013682742203984941] Val Score : [0.9165787375726882])\n",
            "Epoch 00032: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [32] Train loss : [0.01280618505552411] Val Score : [0.8887833851083367])\n",
            "Epoch : [33] Train loss : [0.012037410068192653] Val Score : [0.8772441968135101])\n",
            "Epoch : [34] Train loss : [0.011961227149835654] Val Score : [0.8331926764657618])\n",
            "Epoch : [35] Train loss : [0.011917025782167912] Val Score : [0.8598769209128951])\n",
            "Epoch : [36] Train loss : [0.01185607457799571] Val Score : [0.8331926764657618])\n",
            "Epoch : [37] Train loss : [0.011581521547798599] Val Score : [0.8331926764657618])\n",
            "Epoch : [38] Train loss : [0.011815393609660012] Val Score : [0.8331926764657618])\n",
            "Epoch : [39] Train loss : [0.011808980189796005] Val Score : [0.8331926764657618])\n",
            "Epoch : [40] Train loss : [0.011648011859506369] Val Score : [0.8331926764657618])\n",
            "Epoch : [41] Train loss : [0.011315155840877975] Val Score : [0.8331926764657618])\n",
            "Epoch : [42] Train loss : [0.011292020524186748] Val Score : [0.8331926764657618])\n",
            "Epoch 00043: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [43] Train loss : [0.011275513297212976] Val Score : [0.8189994908759815])\n",
            "Epoch : [44] Train loss : [0.0110220466075199] Val Score : [0.8041895926750926])\n",
            "Epoch : [45] Train loss : [0.011034944427332707] Val Score : [0.7887218676684034])\n",
            "Epoch : [46] Train loss : [0.0109779767559043] Val Score : [0.755629357577611])\n",
            "Epoch : [47] Train loss : [0.010806742722966842] Val Score : [0.8041895926750926])\n",
            "Epoch : [48] Train loss : [0.0106996265905244] Val Score : [0.7725514640071602])\n",
            "Epoch : [49] Train loss : [0.010850107430347375] Val Score : [0.8041895926750926])\n",
            "\n",
            "etc col : V8 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V13\n",
            "Epoch : [0] Train loss : [0.3112327397934028] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.07072864126946245] Val Score : [0.8724347298745778])\n",
            "Epoch : [2] Train loss : [0.07727043596761567] Val Score : [0.0011937417393830074])\n",
            "Epoch : [3] Train loss : [0.04675213021359274] Val Score : [0.9165787375726882])\n",
            "Epoch : [4] Train loss : [0.03177573172641652] Val Score : [0.9165787375726882])\n",
            "Epoch : [5] Train loss : [0.06419574043580464] Val Score : [0.8967110829723166])\n",
            "Epoch : [6] Train loss : [0.04642444795795849] Val Score : [0.8786471773914175])\n",
            "Epoch : [7] Train loss : [0.04240888955869845] Val Score : [0.6205848343502564])\n",
            "Epoch : [8] Train loss : [0.042397002024309974] Val Score : [0.9165787375726882])\n",
            "Epoch : [9] Train loss : [0.04203756446284907] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.029830303442265307] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.030816185155085156] Val Score : [0.9165787375726882])\n",
            "Epoch : [12] Train loss : [0.02982345356472901] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.032779673247465065] Val Score : [0.9165787375726882])\n",
            "Epoch : [14] Train loss : [0.032645270228385925] Val Score : [0.9165787375726882])\n",
            "Epoch 00015: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [15] Train loss : [0.025637475507599965] Val Score : [0.9165787375726882])\n",
            "Epoch : [16] Train loss : [0.026683604211679528] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.021898891178092787] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.024983777398509637] Val Score : [0.9165787375726882])\n",
            "Epoch : [19] Train loss : [0.01986569112965039] Val Score : [0.9165787375726882])\n",
            "Epoch : [20] Train loss : [0.020156332956893102] Val Score : [0.9165787375726882])\n",
            "Epoch : [21] Train loss : [0.018814334579344307] Val Score : [0.9165787375726882])\n",
            "Epoch : [22] Train loss : [0.018750489290271486] Val Score : [0.9165787375726882])\n",
            "Epoch : [23] Train loss : [0.02052747644484043] Val Score : [0.9165787375726882])\n",
            "Epoch : [24] Train loss : [0.019785208028874228] Val Score : [0.9165787375726882])\n",
            "Epoch : [25] Train loss : [0.018736083193549087] Val Score : [0.9165787375726882])\n",
            "Epoch 00026: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [26] Train loss : [0.01714013935998082] Val Score : [0.9137051774467988])\n",
            "Epoch : [27] Train loss : [0.01590890803241304] Val Score : [0.9034120550289857])\n",
            "Epoch : [28] Train loss : [0.014939585634108101] Val Score : [0.8772441968135101])\n",
            "Epoch : [29] Train loss : [0.01537171205771821] Val Score : [0.8652615319692264])\n",
            "Epoch : [30] Train loss : [0.017813492632870163] Val Score : [0.8927516353661109])\n",
            "Epoch : [31] Train loss : [0.014865348381655557] Val Score : [0.8927516353661109])\n",
            "Epoch : [32] Train loss : [0.015455545125795262] Val Score : [0.8927516353661109])\n",
            "Epoch : [33] Train loss : [0.014090022737426417] Val Score : [0.899903286500554])\n",
            "Epoch : [34] Train loss : [0.013645954363580261] Val Score : [0.8927516353661109])\n",
            "Epoch : [35] Train loss : [0.013648372476122208] Val Score : [0.8887833851083367])\n",
            "Epoch : [36] Train loss : [0.012933221579130207] Val Score : [0.899903286500554])\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [37] Train loss : [0.01179465897647398] Val Score : [0.8331926764657618])\n",
            "Epoch : [38] Train loss : [0.011576297227293253] Val Score : [0.8041895926750926])\n",
            "Epoch : [39] Train loss : [0.012051762946482216] Val Score : [0.8041895926750926])\n",
            "Epoch : [40] Train loss : [0.01227499810712678] Val Score : [0.8041895926750926])\n",
            "Epoch : [41] Train loss : [0.01241441915876099] Val Score : [0.8041895926750926])\n",
            "Epoch : [42] Train loss : [0.013314461335539818] Val Score : [0.8041895926750926])\n",
            "Epoch : [43] Train loss : [0.01221875926213605] Val Score : [0.8331926764657618])\n",
            "Epoch : [44] Train loss : [0.012167072123182672] Val Score : [0.8331926764657618])\n",
            "Epoch : [45] Train loss : [0.01193675012992961] Val Score : [0.8331926764657618])\n",
            "Epoch : [46] Train loss : [0.011735577269324235] Val Score : [0.8041895926750926])\n",
            "Epoch : [47] Train loss : [0.011919406641806875] Val Score : [0.8041895926750926])\n",
            "Epoch 00048: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [48] Train loss : [0.011593010808740343] Val Score : [0.755629357577611])\n",
            "Epoch : [49] Train loss : [0.012072236077593905] Val Score : [0.755629357577611])\n",
            "\n",
            "etc col : V13 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V15\n",
            "Epoch : [0] Train loss : [0.4242589867540768] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.15420072738613402] Val Score : [0.0016513134815218595])\n",
            "Epoch : [2] Train loss : [0.10687801002391747] Val Score : [0.8724347298745778])\n",
            "Epoch : [3] Train loss : [0.06548932806721755] Val Score : [0.9236496787663914])\n",
            "Epoch : [4] Train loss : [0.03488697364394154] Val Score : [0.906144477664439])\n",
            "Epoch : [5] Train loss : [0.03232677826391799] Val Score : [0.8712702712210223])\n",
            "Epoch : [6] Train loss : [0.04268591717949936] Val Score : [0.9031202878275757])\n",
            "Epoch : [7] Train loss : [0.03875819434012685] Val Score : [0.9031202878275757])\n",
            "Epoch : [8] Train loss : [0.03432587507580008] Val Score : [0.8967110829723166])\n",
            "Epoch : [9] Train loss : [0.029057717616004602] Val Score : [0.8967110829723166])\n",
            "Epoch : [10] Train loss : [0.028914525838834897] Val Score : [0.8967110829723166])\n",
            "Epoch : [11] Train loss : [0.026791534386575222] Val Score : [0.8967110829723166])\n",
            "Epoch : [12] Train loss : [0.03134484589099884] Val Score : [0.8967110829723166])\n",
            "Epoch : [13] Train loss : [0.02502463771296399] Val Score : [0.9097393418694286])\n",
            "Epoch : [14] Train loss : [0.020900491358978406] Val Score : [0.9097393418694286])\n",
            "Epoch 00015: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [15] Train loss : [0.02000844744699342] Val Score : [0.9165787375726882])\n",
            "Epoch : [16] Train loss : [0.017765636688896587] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.01878397725522518] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.018573801964521408] Val Score : [0.9165787375726882])\n",
            "Epoch : [19] Train loss : [0.016885947635663406] Val Score : [0.9165787375726882])\n",
            "Epoch : [20] Train loss : [0.017622385706220354] Val Score : [0.9165787375726882])\n",
            "Epoch : [21] Train loss : [0.01656613824889064] Val Score : [0.9165787375726882])\n",
            "Epoch : [22] Train loss : [0.015418115870228835] Val Score : [0.9165787375726882])\n",
            "Epoch : [23] Train loss : [0.016031443939677308] Val Score : [0.9165787375726882])\n",
            "Epoch : [24] Train loss : [0.015372782546494688] Val Score : [0.9165787375726882])\n",
            "Epoch : [25] Train loss : [0.014927626520927464] Val Score : [0.9165787375726882])\n",
            "Epoch 00026: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [26] Train loss : [0.014389489112155778] Val Score : [0.9137051774467988])\n",
            "Epoch : [27] Train loss : [0.01369089147608195] Val Score : [0.9137051774467988])\n",
            "Epoch : [28] Train loss : [0.013488290831446648] Val Score : [0.9137051774467988])\n",
            "Epoch : [29] Train loss : [0.013588387851736375] Val Score : [0.9137051774467988])\n",
            "Epoch : [30] Train loss : [0.013262583275458642] Val Score : [0.9137051774467988])\n",
            "Epoch : [31] Train loss : [0.012776481453329325] Val Score : [0.9137051774467988])\n",
            "Epoch : [32] Train loss : [0.012811930916671242] Val Score : [0.9165787375726882])\n",
            "Epoch : [33] Train loss : [0.012463390627609832] Val Score : [0.9137051774467988])\n",
            "Epoch : [34] Train loss : [0.01204680445204888] Val Score : [0.9137051774467988])\n",
            "Epoch : [35] Train loss : [0.012063568125345878] Val Score : [0.9137051774467988])\n",
            "Epoch : [36] Train loss : [0.01210266917145678] Val Score : [0.9137051774467988])\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [37] Train loss : [0.011670194433203765] Val Score : [0.8598769209128951])\n",
            "Epoch : [38] Train loss : [0.011521297506988049] Val Score : [0.8331926764657618])\n",
            "Epoch : [39] Train loss : [0.011488154197910003] Val Score : [0.846806907378336])\n",
            "Epoch : [40] Train loss : [0.01138022675045899] Val Score : [0.8331926764657618])\n",
            "Epoch : [41] Train loss : [0.011395805182733707] Val Score : [0.8598769209128951])\n",
            "Epoch : [42] Train loss : [0.01135158133027809] Val Score : [0.846806907378336])\n",
            "Epoch : [43] Train loss : [0.011245468697909797] Val Score : [0.8331926764657618])\n",
            "Epoch : [44] Train loss : [0.011252589590315307] Val Score : [0.8598769209128951])\n",
            "Epoch : [45] Train loss : [0.011193589639983006] Val Score : [0.8331926764657618])\n",
            "Epoch : [46] Train loss : [0.011186067680163043] Val Score : [0.846806907378336])\n",
            "Epoch : [47] Train loss : [0.011191495028989655] Val Score : [0.8598769209128951])\n",
            "Epoch 00048: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [48] Train loss : [0.011107403851513351] Val Score : [0.8041895926750926])\n",
            "Epoch : [49] Train loss : [0.010941231556768929] Val Score : [0.8041895926750926])\n",
            "\n",
            "etc col : V15 / Marco F1 Score : 0.9236496787663914\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V19\n",
            "Epoch : [0] Train loss : [0.3397248908877373] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.09734304116240569] Val Score : [0.8135584513551521])\n",
            "Epoch : [2] Train loss : [0.04469980538955757] Val Score : [0.8331926764657618])\n",
            "Epoch : [3] Train loss : [0.07669329496898822] Val Score : [0.29421922036952725])\n",
            "Epoch : [4] Train loss : [0.08925708822373833] Val Score : [0.0011233393803556284])\n",
            "Epoch : [5] Train loss : [0.07265154325536319] Val Score : [0.8844834793761085])\n",
            "Epoch : [6] Train loss : [0.04736725600170238] Val Score : [0.9165787375726882])\n",
            "Epoch : [7] Train loss : [0.037199488441858976] Val Score : [0.9031202878275757])\n",
            "Epoch : [8] Train loss : [0.03418465384415218] Val Score : [0.9165787375726882])\n",
            "Epoch : [9] Train loss : [0.04608060126858098] Val Score : [0.9097393418694286])\n",
            "Epoch : [10] Train loss : [0.03576823363878897] Val Score : [0.9097393418694286])\n",
            "Epoch : [11] Train loss : [0.029050358970250403] Val Score : [0.9031202878275757])\n",
            "Epoch : [12] Train loss : [0.038860781650458066] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.033454800955951214] Val Score : [0.9031202878275757])\n",
            "Epoch : [14] Train loss : [0.03381750998752458] Val Score : [0.7870308296420961])\n",
            "Epoch : [15] Train loss : [0.0334730190890176] Val Score : [0.9165787375726882])\n",
            "Epoch : [16] Train loss : [0.03432920096176011] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.026553722763700143] Val Score : [0.9097393418694286])\n",
            "Epoch 00018: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [18] Train loss : [0.02687936183065176] Val Score : [0.9165787375726882])\n",
            "Epoch : [19] Train loss : [0.02381287076111351] Val Score : [0.9165787375726882])\n",
            "Epoch : [20] Train loss : [0.020792746118136814] Val Score : [0.9165787375726882])\n",
            "Epoch : [21] Train loss : [0.017965420614928007] Val Score : [0.9165787375726882])\n",
            "Epoch : [22] Train loss : [0.022397341073623726] Val Score : [0.9165787375726882])\n",
            "Epoch : [23] Train loss : [0.018052522359149798] Val Score : [0.9236496787663914])\n",
            "Epoch : [24] Train loss : [0.016376542060502937] Val Score : [0.9165787375726882])\n",
            "Epoch : [25] Train loss : [0.017064860090613365] Val Score : [0.9165787375726882])\n",
            "Epoch : [26] Train loss : [0.016303427716983215] Val Score : [0.9165787375726882])\n",
            "Epoch : [27] Train loss : [0.01608754401760442] Val Score : [0.9165787375726882])\n",
            "Epoch : [28] Train loss : [0.016599372095827545] Val Score : [0.9165787375726882])\n",
            "Epoch : [29] Train loss : [0.016383197757282426] Val Score : [0.9236496787663914])\n",
            "Epoch : [30] Train loss : [0.017056545774851526] Val Score : [0.9165787375726882])\n",
            "Epoch : [31] Train loss : [0.015452186776591199] Val Score : [0.9165787375726882])\n",
            "Epoch : [32] Train loss : [0.014948979552303041] Val Score : [0.9236496787663914])\n",
            "Epoch : [33] Train loss : [0.015381682531109877] Val Score : [0.9165787375726882])\n",
            "Epoch : [34] Train loss : [0.014662806676434619] Val Score : [0.9236496787663914])\n",
            "Epoch 00035: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [35] Train loss : [0.013015630056283303] Val Score : [0.8927516353661109])\n",
            "Epoch : [36] Train loss : [0.012500518733369452] Val Score : [0.8927516353661109])\n",
            "Epoch : [37] Train loss : [0.012316705725554909] Val Score : [0.8927516353661109])\n",
            "Epoch : [38] Train loss : [0.012479858406420265] Val Score : [0.8927516353661109])\n",
            "Epoch : [39] Train loss : [0.012386387147541558] Val Score : [0.8772441968135101])\n",
            "Epoch : [40] Train loss : [0.012024026031472854] Val Score : [0.8817038840461091])\n",
            "Epoch : [41] Train loss : [0.011924647060888154] Val Score : [0.8927516353661109])\n",
            "Epoch : [42] Train loss : [0.011828136896448476] Val Score : [0.8772441968135101])\n",
            "Epoch : [43] Train loss : [0.011509824278099197] Val Score : [0.8772441968135101])\n",
            "Epoch : [44] Train loss : [0.011436746322682925] Val Score : [0.8927516353661109])\n",
            "Epoch : [45] Train loss : [0.011237146532429116] Val Score : [0.8927516353661109])\n",
            "Epoch 00046: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [46] Train loss : [0.010889958457223006] Val Score : [0.8189994908759815])\n",
            "Epoch : [47] Train loss : [0.010710698020245348] Val Score : [0.8189994908759815])\n",
            "Epoch : [48] Train loss : [0.010573036702615874] Val Score : [0.8041895926750926])\n",
            "Epoch : [49] Train loss : [0.010400774689125163] Val Score : [0.8189994908759815])\n",
            "\n",
            "etc col : V19 / Marco F1 Score : 0.9236496787663914\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V20\n",
            "Epoch : [0] Train loss : [0.2681249348180635] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.06019281196807112] Val Score : [0.8189994908759815])\n",
            "Epoch : [2] Train loss : [0.08125203262482371] Val Score : [0.9066829407144783])\n",
            "Epoch : [3] Train loss : [0.05981466905879123] Val Score : [0.9165787375726882])\n",
            "Epoch : [4] Train loss : [0.05980034079402685] Val Score : [0.8162006166001039])\n",
            "Epoch : [5] Train loss : [0.06976328098348208] Val Score : [0.8786471773914175])\n",
            "Epoch : [6] Train loss : [0.0593615783644574] Val Score : [0.9165787375726882])\n",
            "Epoch : [7] Train loss : [0.06608672972236361] Val Score : [0.9165787375726882])\n",
            "Epoch : [8] Train loss : [0.03986248493726764] Val Score : [0.890501890608512])\n",
            "Epoch : [9] Train loss : [0.052298992073961666] Val Score : [0.8967110829723166])\n",
            "Epoch : [10] Train loss : [0.05405485270810979] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.04547142130987985] Val Score : [0.9165787375726882])\n",
            "Epoch : [12] Train loss : [0.04447783436626196] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.03682615501540048] Val Score : [0.9165787375726882])\n",
            "Epoch : [14] Train loss : [0.042393554002046585] Val Score : [0.7353562550268086])\n",
            "Epoch 00015: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [15] Train loss : [0.03937779034354857] Val Score : [0.9165787375726882])\n",
            "Epoch : [16] Train loss : [0.022521098809582845] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.028954152017831802] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.04466497512268169] Val Score : [0.9165787375726882])\n",
            "Epoch : [19] Train loss : [0.03567891714296171] Val Score : [0.9165787375726882])\n",
            "Epoch : [20] Train loss : [0.021302999462932348] Val Score : [0.9165787375726882])\n",
            "Epoch : [21] Train loss : [0.029880893283656666] Val Score : [0.9165787375726882])\n",
            "Epoch : [22] Train loss : [0.020760426430829933] Val Score : [0.9165787375726882])\n",
            "Epoch : [23] Train loss : [0.02096146790842925] Val Score : [0.9165787375726882])\n",
            "Epoch : [24] Train loss : [0.01632619496168835] Val Score : [0.9165787375726882])\n",
            "Epoch : [25] Train loss : [0.015433450429035085] Val Score : [0.9165787375726882])\n",
            "Epoch 00026: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [26] Train loss : [0.014110386105520385] Val Score : [0.9034120550289857])\n",
            "Epoch : [27] Train loss : [0.01639122183301619] Val Score : [0.8927516353661109])\n",
            "Epoch : [28] Train loss : [0.015181851839380605] Val Score : [0.8927516353661109])\n",
            "Epoch : [29] Train loss : [0.014177595863917045] Val Score : [0.8927516353661109])\n",
            "Epoch : [30] Train loss : [0.015008223110011645] Val Score : [0.8927516353661109])\n",
            "Epoch : [31] Train loss : [0.013833451084792614] Val Score : [0.8927516353661109])\n",
            "Epoch : [32] Train loss : [0.014487940618502242] Val Score : [0.8927516353661109])\n",
            "Epoch : [33] Train loss : [0.014290363394788333] Val Score : [0.9034120550289857])\n",
            "Epoch : [34] Train loss : [0.013270061063979353] Val Score : [0.8927516353661109])\n",
            "Epoch : [35] Train loss : [0.01299080006512148] Val Score : [0.8927516353661109])\n",
            "Epoch : [36] Train loss : [0.012655937312436956] Val Score : [0.8927516353661109])\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [37] Train loss : [0.013095964544585772] Val Score : [0.8331926764657618])\n",
            "Epoch : [38] Train loss : [0.012449309495942933] Val Score : [0.8331926764657618])\n",
            "Epoch : [39] Train loss : [0.01193916012666055] Val Score : [0.8331926764657618])\n",
            "Epoch : [40] Train loss : [0.011548834586782115] Val Score : [0.8041895926750926])\n",
            "Epoch : [41] Train loss : [0.011756807898304291] Val Score : [0.8041895926750926])\n",
            "Epoch : [42] Train loss : [0.011970269028097391] Val Score : [0.8331926764657618])\n",
            "Epoch : [43] Train loss : [0.01209957804530859] Val Score : [0.8041895926750926])\n",
            "Epoch : [44] Train loss : [0.01191342921395387] Val Score : [0.8041895926750926])\n",
            "Epoch : [45] Train loss : [0.011993782594799995] Val Score : [0.846806907378336])\n",
            "Epoch : [46] Train loss : [0.011756753216364555] Val Score : [0.8331926764657618])\n",
            "Epoch : [47] Train loss : [0.012030572364372867] Val Score : [0.8331926764657618])\n",
            "Epoch 00048: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [48] Train loss : [0.01199975682954703] Val Score : [0.8041895926750926])\n",
            "Epoch : [49] Train loss : [0.011516342205660684] Val Score : [0.7887218676684034])\n",
            "\n",
            "etc col : V20 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V21\n",
            "Epoch : [0] Train loss : [0.2625920277621065] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.10624528623053006] Val Score : [0.5253729226863484])\n",
            "Epoch : [2] Train loss : [0.07975500050399985] Val Score : [0.9165787375726882])\n",
            "Epoch : [3] Train loss : [0.051699018238910606] Val Score : [0.02467178579703934])\n",
            "Epoch : [4] Train loss : [0.05582534881042583] Val Score : [0.9031202878275757])\n",
            "Epoch : [5] Train loss : [0.07106379845312663] Val Score : [0.9031202878275757])\n",
            "Epoch : [6] Train loss : [0.040345867164433] Val Score : [0.8786471773914175])\n",
            "Epoch : [7] Train loss : [0.04380604651357446] Val Score : [0.9165787375726882])\n",
            "Epoch : [8] Train loss : [0.037566128985158036] Val Score : [0.9165787375726882])\n",
            "Epoch : [9] Train loss : [0.0474624853315098] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.03761247718440635] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.03977551297949893] Val Score : [0.8967110829723166])\n",
            "Epoch : [12] Train loss : [0.05327808976705585] Val Score : [0.0010529271374420891])\n",
            "Epoch : [13] Train loss : [0.04046980198472738] Val Score : [0.007211596956432566])\n",
            "Epoch 00014: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [14] Train loss : [0.030663644229727133] Val Score : [0.8470287373843977])\n",
            "Epoch : [15] Train loss : [0.023214178825063363] Val Score : [0.890501890608512])\n",
            "Epoch : [16] Train loss : [0.019788768009415696] Val Score : [0.9031202878275757])\n",
            "Epoch : [17] Train loss : [0.02188033557363919] Val Score : [0.890501890608512])\n",
            "Epoch : [18] Train loss : [0.01853514788672328] Val Score : [0.890501890608512])\n",
            "Epoch : [19] Train loss : [0.022147754140730416] Val Score : [0.9031202878275757])\n",
            "Epoch : [20] Train loss : [0.01914724680994238] Val Score : [0.9097393418694286])\n",
            "Epoch : [21] Train loss : [0.017168928536453416] Val Score : [0.9097393418694286])\n",
            "Epoch : [22] Train loss : [0.01682083953970245] Val Score : [0.9097393418694286])\n",
            "Epoch : [23] Train loss : [0.016928194889000485] Val Score : [0.9097393418694286])\n",
            "Epoch : [24] Train loss : [0.01713770388492516] Val Score : [0.9097393418694286])\n",
            "Epoch 00025: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [25] Train loss : [0.014908982973013605] Val Score : [0.9165787375726882])\n",
            "Epoch : [26] Train loss : [0.014149452360080821] Val Score : [0.9137051774467988])\n",
            "Epoch : [27] Train loss : [0.013892679874386107] Val Score : [0.9209734995691702])\n",
            "Epoch : [28] Train loss : [0.013867349031248264] Val Score : [0.9209734995691702])\n",
            "Epoch : [29] Train loss : [0.013009692675301008] Val Score : [0.9106263628050926])\n",
            "Epoch : [30] Train loss : [0.012794513188834702] Val Score : [0.9209734995691702])\n",
            "Epoch : [31] Train loss : [0.01192332957206028] Val Score : [0.9209734995691702])\n",
            "Epoch : [32] Train loss : [0.011580371963126319] Val Score : [0.899903286500554])\n",
            "Epoch : [33] Train loss : [0.011975426426423448] Val Score : [0.9209734995691702])\n",
            "Epoch : [34] Train loss : [0.01116091012954712] Val Score : [0.9137051774467988])\n",
            "Epoch : [35] Train loss : [0.01098397420719266] Val Score : [0.899903286500554])\n",
            "Epoch : [36] Train loss : [0.011386804881372623] Val Score : [0.9106263628050926])\n",
            "Epoch : [37] Train loss : [0.010925905246819769] Val Score : [0.9137051774467988])\n",
            "Epoch : [38] Train loss : [0.011048201804182358] Val Score : [0.899903286500554])\n",
            "Epoch 00039: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [39] Train loss : [0.010772578684347016] Val Score : [0.8652615319692264])\n",
            "Epoch : [40] Train loss : [0.01038080467177289] Val Score : [0.8189994908759815])\n",
            "Epoch : [41] Train loss : [0.010062205738254957] Val Score : [0.8189994908759815])\n",
            "Epoch : [42] Train loss : [0.010309843812137842] Val Score : [0.8331926764657618])\n",
            "Epoch : [43] Train loss : [0.00987206186567034] Val Score : [0.8598769209128951])\n",
            "Epoch : [44] Train loss : [0.00995031837373972] Val Score : [0.846806907378336])\n",
            "Epoch : [45] Train loss : [0.009936612631593431] Val Score : [0.8331926764657618])\n",
            "Epoch : [46] Train loss : [0.00985268144203084] Val Score : [0.846806907378336])\n",
            "Epoch : [47] Train loss : [0.009956474615527051] Val Score : [0.8331926764657618])\n",
            "Epoch : [48] Train loss : [0.009718034083821945] Val Score : [0.8189994908759815])\n",
            "Epoch : [49] Train loss : [0.00985737138294748] Val Score : [0.8598769209128951])\n",
            "Epoch 00050: reducing learning rate of group 0 to 6.2500e-04.\n",
            "\n",
            "etc col : V21 / Marco F1 Score : 0.9209734995691702\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V22\n",
            "Epoch : [0] Train loss : [0.28939266981823103] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.11947792981352125] Val Score : [0.8189994908759815])\n",
            "Epoch : [2] Train loss : [0.08129823234464441] Val Score : [0.8621517488551477])\n",
            "Epoch : [3] Train loss : [0.07241390379411834] Val Score : [0.856966968023358])\n",
            "Epoch : [4] Train loss : [0.047663534326212745] Val Score : [0.5366625894644536])\n",
            "Epoch : [5] Train loss : [0.04390399330960853] Val Score : [0.9031202878275757])\n",
            "Epoch : [6] Train loss : [0.061762889581067223] Val Score : [0.890501890608512])\n",
            "Epoch : [7] Train loss : [0.0640279445797205] Val Score : [0.872984830495149])\n",
            "Epoch : [8] Train loss : [0.05053102783858776] Val Score : [0.8202665410912253])\n",
            "Epoch : [9] Train loss : [0.042923653099153726] Val Score : [0.8967110829723166])\n",
            "Epoch : [10] Train loss : [0.06403015234640666] Val Score : [0.890501890608512])\n",
            "Epoch : [11] Train loss : [0.04957082548311779] Val Score : [0.890501890608512])\n",
            "Epoch : [12] Train loss : [0.03601021013621773] Val Score : [0.890501890608512])\n",
            "Epoch : [13] Train loss : [0.03277242396559034] Val Score : [0.890501890608512])\n",
            "Epoch : [14] Train loss : [0.03570521290280989] Val Score : [0.8967110829723166])\n",
            "Epoch : [15] Train loss : [0.029851116506116732] Val Score : [0.8844834793761085])\n",
            "Epoch : [16] Train loss : [0.02883351474468197] Val Score : [0.890501890608512])\n",
            "Epoch 00017: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [17] Train loss : [0.022914162570876733] Val Score : [0.8967110829723166])\n",
            "Epoch : [18] Train loss : [0.01931954507849046] Val Score : [0.8967110829723166])\n",
            "Epoch : [19] Train loss : [0.018385708930769136] Val Score : [0.9031202878275757])\n",
            "Epoch : [20] Train loss : [0.020974121056497097] Val Score : [0.8967110829723166])\n",
            "Epoch : [21] Train loss : [0.018739649360733374] Val Score : [0.8967110829723166])\n",
            "Epoch : [22] Train loss : [0.017870352936110327] Val Score : [0.8927516353661109])\n",
            "Epoch : [23] Train loss : [0.017520901480955735] Val Score : [0.8967110829723166])\n",
            "Epoch : [24] Train loss : [0.015646992783461298] Val Score : [0.9031202878275757])\n",
            "Epoch : [25] Train loss : [0.016679907084575722] Val Score : [0.9031202878275757])\n",
            "Epoch : [26] Train loss : [0.017131886245416745] Val Score : [0.9097393418694286])\n",
            "Epoch : [27] Train loss : [0.015840660448053052] Val Score : [0.8967110829723166])\n",
            "Epoch : [28] Train loss : [0.015083368601543563] Val Score : [0.9137051774467988])\n",
            "Epoch : [29] Train loss : [0.014565775370491403] Val Score : [0.8967110829723166])\n",
            "Epoch : [30] Train loss : [0.01425082522577473] Val Score : [0.9031202878275757])\n",
            "Epoch : [31] Train loss : [0.013992514660848039] Val Score : [0.9031202878275757])\n",
            "Epoch : [32] Train loss : [0.013765715794371707] Val Score : [0.9031202878275757])\n",
            "Epoch : [33] Train loss : [0.013969271310738154] Val Score : [0.9066829407144783])\n",
            "Epoch : [34] Train loss : [0.014802871338490928] Val Score : [0.9097393418694286])\n",
            "Epoch : [35] Train loss : [0.014240089870457138] Val Score : [0.9031202878275757])\n",
            "Epoch : [36] Train loss : [0.01336697196321828] Val Score : [0.9137051774467988])\n",
            "Epoch : [37] Train loss : [0.012746857545737709] Val Score : [0.9137051774467988])\n",
            "Epoch : [38] Train loss : [0.012705201748758554] Val Score : [0.9137051774467988])\n",
            "Epoch : [39] Train loss : [0.012267896040741886] Val Score : [0.9137051774467988])\n",
            "Epoch 00040: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [40] Train loss : [0.0118206295051745] Val Score : [0.8724347298745778])\n",
            "Epoch : [41] Train loss : [0.01169256413621562] Val Score : [0.896129704996047])\n",
            "Epoch : [42] Train loss : [0.01141607774687665] Val Score : [0.8331926764657618])\n",
            "Epoch : [43] Train loss : [0.01151494003300156] Val Score : [0.8331926764657618])\n",
            "Epoch : [44] Train loss : [0.011239016827728068] Val Score : [0.8724347298745778])\n",
            "Epoch : [45] Train loss : [0.011126665598047631] Val Score : [0.846806907378336])\n",
            "Epoch : [46] Train loss : [0.011068315644349371] Val Score : [0.8598769209128951])\n",
            "Epoch : [47] Train loss : [0.01096560200676322] Val Score : [0.846806907378336])\n",
            "Epoch : [48] Train loss : [0.010812319881681885] Val Score : [0.846806907378336])\n",
            "Epoch : [49] Train loss : [0.01072443729000432] Val Score : [0.8331926764657618])\n",
            "\n",
            "etc col : V22 / Marco F1 Score : 0.9137051774467988\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V23\n",
            "Epoch : [0] Train loss : [0.26243950373360087] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.07892695308795997] Val Score : [0.0010182500435772218])\n",
            "Epoch : [2] Train loss : [0.0725462134661419] Val Score : [0.46510129345872203])\n",
            "Epoch : [3] Train loss : [0.06029099252607141] Val Score : [0.8897162026625655])\n",
            "Epoch : [4] Train loss : [0.048765016054468494] Val Score : [0.02928270416015131])\n",
            "Epoch : [5] Train loss : [0.06554182858339377] Val Score : [0.9165787375726882])\n",
            "Epoch : [6] Train loss : [0.048894534818828106] Val Score : [0.9165787375726882])\n",
            "Epoch : [7] Train loss : [0.05319321634513991] Val Score : [0.9165787375726882])\n",
            "Epoch : [8] Train loss : [0.046175881155899594] Val Score : [0.8844834793761085])\n",
            "Epoch : [9] Train loss : [0.04938933851995638] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.05664294532367161] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.06220788774745805] Val Score : [0.9165787375726882])\n",
            "Epoch : [12] Train loss : [0.052380300126969814] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.02914727559047086] Val Score : [0.8844834793761085])\n",
            "Epoch : [14] Train loss : [0.023987377461578165] Val Score : [0.5794385812775309])\n",
            "Epoch : [15] Train loss : [0.032720022302653105] Val Score : [0.5634215972732056])\n",
            "Epoch : [16] Train loss : [0.03762218662138496] Val Score : [0.9137051774467988])\n",
            "Epoch 00017: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [17] Train loss : [0.03232488555035421] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.02659990345793111] Val Score : [0.9165787375726882])\n",
            "Epoch : [19] Train loss : [0.02155521059674876] Val Score : [0.9165787375726882])\n",
            "Epoch : [20] Train loss : [0.020929090479122742] Val Score : [0.9165787375726882])\n",
            "Epoch : [21] Train loss : [0.0216768616810441] Val Score : [0.9165787375726882])\n",
            "Epoch : [22] Train loss : [0.025251816026866436] Val Score : [0.9165787375726882])\n",
            "Epoch : [23] Train loss : [0.01940064285216587] Val Score : [0.9165787375726882])\n",
            "Epoch : [24] Train loss : [0.02230290017489876] Val Score : [0.9165787375726882])\n",
            "Epoch : [25] Train loss : [0.01992179672898991] Val Score : [0.9165787375726882])\n",
            "Epoch : [26] Train loss : [0.018895677024764673] Val Score : [0.9165787375726882])\n",
            "Epoch : [27] Train loss : [0.018383108279002563] Val Score : [0.9165787375726882])\n",
            "Epoch 00028: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [28] Train loss : [0.016137080400117805] Val Score : [0.9137051774467988])\n",
            "Epoch : [29] Train loss : [0.01389537425711751] Val Score : [0.9137051774467988])\n",
            "Epoch : [30] Train loss : [0.014270063489675522] Val Score : [0.8927516353661109])\n",
            "Epoch : [31] Train loss : [0.013383511853005205] Val Score : [0.9137051774467988])\n",
            "Epoch : [32] Train loss : [0.01307485339098743] Val Score : [0.9137051774467988])\n",
            "Epoch : [33] Train loss : [0.01291081908025912] Val Score : [0.899903286500554])\n",
            "Epoch : [34] Train loss : [0.01259063689836434] Val Score : [0.8927516353661109])\n",
            "Epoch : [35] Train loss : [0.012264166426445757] Val Score : [0.9137051774467988])\n",
            "Epoch : [36] Train loss : [0.011652785020747356] Val Score : [0.899903286500554])\n",
            "Epoch : [37] Train loss : [0.011147728056779929] Val Score : [0.9137051774467988])\n",
            "Epoch : [38] Train loss : [0.010813521021710975] Val Score : [0.8331926764657618])\n",
            "Epoch 00039: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [39] Train loss : [0.0107656713974263] Val Score : [0.8927516353661109])\n",
            "Epoch : [40] Train loss : [0.010375832140977894] Val Score : [0.8331926764657618])\n",
            "Epoch : [41] Train loss : [0.010229474864900112] Val Score : [0.8331926764657618])\n",
            "Epoch : [42] Train loss : [0.010345456323453359] Val Score : [0.7725514640071602])\n",
            "Epoch : [43] Train loss : [0.010217299086174794] Val Score : [0.8598769209128951])\n",
            "Epoch : [44] Train loss : [0.010276181889431817] Val Score : [0.8041895926750926])\n",
            "Epoch : [45] Train loss : [0.010221879131027631] Val Score : [0.8652615319692264])\n",
            "Epoch : [46] Train loss : [0.010064120537468366] Val Score : [0.8041895926750926])\n",
            "Epoch : [47] Train loss : [0.010247052114989077] Val Score : [0.8331926764657618])\n",
            "Epoch : [48] Train loss : [0.010237372147717647] Val Score : [0.846806907378336])\n",
            "Epoch : [49] Train loss : [0.010204771999269724] Val Score : [0.8331926764657618])\n",
            "Epoch 00050: reducing learning rate of group 0 to 6.2500e-04.\n",
            "\n",
            "etc col : V23 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V24\n",
            "Epoch : [0] Train loss : [0.2893615588545799] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.11681332864931651] Val Score : [0.0919855649441287])\n",
            "Epoch : [2] Train loss : [0.053355159770165174] Val Score : [0.8927516353661109])\n",
            "Epoch : [3] Train loss : [0.05197530559131077] Val Score : [0.9165787375726882])\n",
            "Epoch : [4] Train loss : [0.04368962866387197] Val Score : [0.856966968023358])\n",
            "Epoch : [5] Train loss : [0.046122186950274875] Val Score : [0.8967110829723166])\n",
            "Epoch : [6] Train loss : [0.045809519344142506] Val Score : [0.8844834793761085])\n",
            "Epoch : [7] Train loss : [0.05498445353337696] Val Score : [0.8621517488551477])\n",
            "Epoch : [8] Train loss : [0.0382325341925025] Val Score : [0.872984830495149])\n",
            "Epoch : [9] Train loss : [0.04831049019204719] Val Score : [0.7713696202996474])\n",
            "Epoch : [10] Train loss : [0.04127596864210708] Val Score : [0.9031202878275757])\n",
            "Epoch : [11] Train loss : [0.03201442863792181] Val Score : [0.4235181119668573])\n",
            "Epoch : [12] Train loss : [0.03909574422453131] Val Score : [0.9097393418694286])\n",
            "Epoch : [13] Train loss : [0.03788855339267424] Val Score : [0.9097393418694286])\n",
            "Epoch : [14] Train loss : [0.03659969727907862] Val Score : [0.9165787375726882])\n",
            "Epoch 00015: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [15] Train loss : [0.03109968307295016] Val Score : [0.9165787375726882])\n",
            "Epoch : [16] Train loss : [0.0243896037074072] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.029324053121464595] Val Score : [0.9097393418694286])\n",
            "Epoch : [18] Train loss : [0.026632469546582018] Val Score : [0.9097393418694286])\n",
            "Epoch : [19] Train loss : [0.023498055125985826] Val Score : [0.9097393418694286])\n",
            "Epoch : [20] Train loss : [0.025912764881338392] Val Score : [0.9165787375726882])\n",
            "Epoch : [21] Train loss : [0.02090636401304177] Val Score : [0.9097393418694286])\n",
            "Epoch : [22] Train loss : [0.019673161607767855] Val Score : [0.9165787375726882])\n",
            "Epoch : [23] Train loss : [0.019813258799591234] Val Score : [0.9165787375726882])\n",
            "Epoch : [24] Train loss : [0.018000455240585973] Val Score : [0.9165787375726882])\n",
            "Epoch : [25] Train loss : [0.017774222817804133] Val Score : [0.9165787375726882])\n",
            "Epoch 00026: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [26] Train loss : [0.015121013657855136] Val Score : [0.9137051774467988])\n",
            "Epoch : [27] Train loss : [0.014843310961233718] Val Score : [0.9137051774467988])\n",
            "Epoch : [28] Train loss : [0.01592257778559412] Val Score : [0.9137051774467988])\n",
            "Epoch : [29] Train loss : [0.014334958445812975] Val Score : [0.9137051774467988])\n",
            "Epoch : [30] Train loss : [0.01393330842256546] Val Score : [0.9137051774467988])\n",
            "Epoch : [31] Train loss : [0.013342594461781638] Val Score : [0.8927516353661109])\n",
            "Epoch : [32] Train loss : [0.014890570060483046] Val Score : [0.9137051774467988])\n",
            "Epoch : [33] Train loss : [0.014432636355715138] Val Score : [0.9165787375726882])\n",
            "Epoch : [34] Train loss : [0.013016425272715943] Val Score : [0.9137051774467988])\n",
            "Epoch : [35] Train loss : [0.013204975452806269] Val Score : [0.9165787375726882])\n",
            "Epoch : [36] Train loss : [0.013095976252640997] Val Score : [0.9066829407144783])\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [37] Train loss : [0.01340739828135286] Val Score : [0.899903286500554])\n",
            "Epoch : [38] Train loss : [0.01213126430021865] Val Score : [0.8598769209128951])\n",
            "Epoch : [39] Train loss : [0.011909964494407177] Val Score : [0.8598769209128951])\n",
            "Epoch : [40] Train loss : [0.012050917904291834] Val Score : [0.8887833851083367])\n",
            "Epoch : [41] Train loss : [0.011856262971247946] Val Score : [0.8331926764657618])\n",
            "Epoch : [42] Train loss : [0.011674321190054928] Val Score : [0.8331926764657618])\n",
            "Epoch : [43] Train loss : [0.011928931743438755] Val Score : [0.8331926764657618])\n",
            "Epoch : [44] Train loss : [0.011832536730383123] Val Score : [0.8598769209128951])\n",
            "Epoch : [45] Train loss : [0.012204288904156004] Val Score : [0.8331926764657618])\n",
            "Epoch : [46] Train loss : [0.011925800370850734] Val Score : [0.8331926764657618])\n",
            "Epoch : [47] Train loss : [0.011691378629101174] Val Score : [0.8331926764657618])\n",
            "Epoch 00048: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [48] Train loss : [0.011766530373798949] Val Score : [0.8041895926750926])\n",
            "Epoch : [49] Train loss : [0.011376048970435346] Val Score : [0.8041895926750926])\n",
            "\n",
            "etc col : V24 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V25\n",
            "Epoch : [0] Train loss : [0.31574064386742456] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.09585322812199593] Val Score : [0.011436489179033803])\n",
            "Epoch : [2] Train loss : [0.07333385571837425] Val Score : [0.0010529271374420891])\n",
            "Epoch : [3] Train loss : [0.05135055059301002] Val Score : [0.9165787375726882])\n",
            "Epoch : [4] Train loss : [0.04516371472605637] Val Score : [0.872984830495149])\n",
            "Epoch : [5] Train loss : [0.0487593783597861] Val Score : [0.833113452596645])\n",
            "Epoch : [6] Train loss : [0.04820472773696695] Val Score : [0.9097393418694286])\n",
            "Epoch : [7] Train loss : [0.047479932728622644] Val Score : [0.8422634702634115])\n",
            "Epoch : [8] Train loss : [0.03837874398699829] Val Score : [0.6946258319247834])\n",
            "Epoch : [9] Train loss : [0.04226152851645436] Val Score : [0.872984830495149])\n",
            "Epoch : [10] Train loss : [0.051945650683982034] Val Score : [0.9097393418694286])\n",
            "Epoch : [11] Train loss : [0.03907846419938973] Val Score : [0.9097393418694286])\n",
            "Epoch : [12] Train loss : [0.03289782402238676] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.030652516521513462] Val Score : [0.9165787375726882])\n",
            "Epoch : [14] Train loss : [0.033125976765794415] Val Score : [0.9165787375726882])\n",
            "Epoch 00015: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [15] Train loss : [0.022810193576983044] Val Score : [0.9165787375726882])\n",
            "Epoch : [16] Train loss : [0.01950853830203414] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.017753325602305785] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.02178323421893375] Val Score : [0.9165787375726882])\n",
            "Epoch : [19] Train loss : [0.021190033294260502] Val Score : [0.9165787375726882])\n",
            "Epoch : [20] Train loss : [0.01771054942426937] Val Score : [0.9165787375726882])\n",
            "Epoch : [21] Train loss : [0.016812521166035106] Val Score : [0.9165787375726882])\n",
            "Epoch : [22] Train loss : [0.01725367536502225] Val Score : [0.9165787375726882])\n",
            "Epoch : [23] Train loss : [0.016607684482421194] Val Score : [0.9165787375726882])\n",
            "Epoch : [24] Train loss : [0.015782598472599472] Val Score : [0.9165787375726882])\n",
            "Epoch : [25] Train loss : [0.015666905657521317] Val Score : [0.9165787375726882])\n",
            "Epoch 00026: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [26] Train loss : [0.01415078401831644] Val Score : [0.9165787375726882])\n",
            "Epoch : [27] Train loss : [0.013439283506678683] Val Score : [0.9066829407144783])\n",
            "Epoch : [28] Train loss : [0.013719077887279647] Val Score : [0.9034120550289857])\n",
            "Epoch : [29] Train loss : [0.014566927416516202] Val Score : [0.9066829407144783])\n",
            "Epoch : [30] Train loss : [0.01379768450611404] Val Score : [0.9137051774467988])\n",
            "Epoch : [31] Train loss : [0.013238462286868266] Val Score : [0.9137051774467988])\n",
            "Epoch : [32] Train loss : [0.012493391720844167] Val Score : [0.9137051774467988])\n",
            "Epoch : [33] Train loss : [0.012499944040817874] Val Score : [0.8927516353661109])\n",
            "Epoch : [34] Train loss : [0.012225721829703875] Val Score : [0.8927516353661109])\n",
            "Epoch : [35] Train loss : [0.012078812811523676] Val Score : [0.9034120550289857])\n",
            "Epoch : [36] Train loss : [0.012064044164227588] Val Score : [0.9137051774467988])\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [37] Train loss : [0.01186424573617322] Val Score : [0.8331926764657618])\n",
            "Epoch : [38] Train loss : [0.011971729474940471] Val Score : [0.8598769209128951])\n",
            "Epoch : [39] Train loss : [0.011629420066518443] Val Score : [0.8331926764657618])\n",
            "Epoch : [40] Train loss : [0.011730261612683535] Val Score : [0.8331926764657618])\n",
            "Epoch : [41] Train loss : [0.011489075675074543] Val Score : [0.8331926764657618])\n",
            "Epoch : [42] Train loss : [0.011446591067527021] Val Score : [0.8331926764657618])\n",
            "Epoch : [43] Train loss : [0.011294031050056219] Val Score : [0.8331926764657618])\n",
            "Epoch : [44] Train loss : [0.011347131870154823] Val Score : [0.870247282626393])\n",
            "Epoch : [45] Train loss : [0.011144772105451142] Val Score : [0.8331926764657618])\n",
            "Epoch : [46] Train loss : [0.011024080482976777] Val Score : [0.8331926764657618])\n",
            "Epoch : [47] Train loss : [0.011129787457840783] Val Score : [0.8331926764657618])\n",
            "Epoch 00048: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [48] Train loss : [0.010770378966948815] Val Score : [0.8041895926750926])\n",
            "Epoch : [49] Train loss : [0.01057557821539896] Val Score : [0.8041895926750926])\n",
            "\n",
            "etc col : V25 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V26\n",
            "Epoch : [0] Train loss : [0.23762342120919908] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.08707266194479805] Val Score : [0.7930606812198397])\n",
            "Epoch : [2] Train loss : [0.06978400317685944] Val Score : [0.6230470797117141])\n",
            "Epoch : [3] Train loss : [0.05727458319493702] Val Score : [0.9066829407144783])\n",
            "Epoch : [4] Train loss : [0.03946879346455846] Val Score : [0.9097393418694286])\n",
            "Epoch : [5] Train loss : [0.03375091975820916] Val Score : [0.9236496787663914])\n",
            "Epoch : [6] Train loss : [0.06080922484397888] Val Score : [0.9137051774467988])\n",
            "Epoch : [7] Train loss : [0.04157836588897875] Val Score : [0.8844834793761085])\n",
            "Epoch : [8] Train loss : [0.07053817090179239] Val Score : [0.6211914737686329])\n",
            "Epoch : [9] Train loss : [0.08774670426334653] Val Score : [0.9236496787663914])\n",
            "Epoch : [10] Train loss : [0.05030904430896044] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.04334267960595233] Val Score : [0.9165787375726882])\n",
            "Epoch : [12] Train loss : [0.04494432519589152] Val Score : [0.8422634702634115])\n",
            "Epoch : [13] Train loss : [0.03514059925717967] Val Score : [0.4698378466043446])\n",
            "Epoch : [14] Train loss : [0.030773018752889975] Val Score : [0.890501890608512])\n",
            "Epoch : [15] Train loss : [0.027461683111531392] Val Score : [0.8967110829723166])\n",
            "Epoch : [16] Train loss : [0.02416424666132246] Val Score : [0.9031202878275757])\n",
            "Epoch 00017: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [17] Train loss : [0.02358917985111475] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.02980088030121156] Val Score : [0.9165787375726882])\n",
            "Epoch : [19] Train loss : [0.025394556378679618] Val Score : [0.9165787375726882])\n",
            "Epoch : [20] Train loss : [0.023478935871805464] Val Score : [0.9165787375726882])\n",
            "Epoch : [21] Train loss : [0.0183143357613257] Val Score : [0.9165787375726882])\n",
            "Epoch : [22] Train loss : [0.019252489054841653] Val Score : [0.9165787375726882])\n",
            "Epoch : [23] Train loss : [0.023575639418725456] Val Score : [0.9165787375726882])\n",
            "Epoch : [24] Train loss : [0.01837247995925801] Val Score : [0.9165787375726882])\n",
            "Epoch : [25] Train loss : [0.015306133510810989] Val Score : [0.9165787375726882])\n",
            "Epoch : [26] Train loss : [0.01738116211657013] Val Score : [0.9165787375726882])\n",
            "Epoch : [27] Train loss : [0.017174678788121258] Val Score : [0.9165787375726882])\n",
            "Epoch 00028: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [28] Train loss : [0.015267727231340749] Val Score : [0.9137051774467988])\n",
            "Epoch : [29] Train loss : [0.014618106452482087] Val Score : [0.9034120550289857])\n",
            "Epoch : [30] Train loss : [0.015009362849273853] Val Score : [0.899903286500554])\n",
            "Epoch : [31] Train loss : [0.014262488377945763] Val Score : [0.899903286500554])\n",
            "Epoch : [32] Train loss : [0.01359382611034172] Val Score : [0.9034120550289857])\n",
            "Epoch : [33] Train loss : [0.013404637109488249] Val Score : [0.899903286500554])\n",
            "Epoch : [34] Train loss : [0.012771035943712507] Val Score : [0.9137051774467988])\n",
            "Epoch : [35] Train loss : [0.012614282513303416] Val Score : [0.8887833851083367])\n",
            "Epoch : [36] Train loss : [0.012467517650553159] Val Score : [0.8927516353661109])\n",
            "Epoch : [37] Train loss : [0.012667010338710887] Val Score : [0.8598769209128951])\n",
            "Epoch : [38] Train loss : [0.012286805680819921] Val Score : [0.9034120550289857])\n",
            "Epoch 00039: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [39] Train loss : [0.011399907658674888] Val Score : [0.8331926764657618])\n",
            "Epoch : [40] Train loss : [0.011931157338299922] Val Score : [0.8331926764657618])\n",
            "Epoch : [41] Train loss : [0.011360184821699346] Val Score : [0.8041895926750926])\n",
            "Epoch : [42] Train loss : [0.01117411901109985] Val Score : [0.8041895926750926])\n",
            "Epoch : [43] Train loss : [0.011022451732839857] Val Score : [0.8041895926750926])\n",
            "Epoch : [44] Train loss : [0.010828114314270871] Val Score : [0.8041895926750926])\n",
            "Epoch : [45] Train loss : [0.010662843074117388] Val Score : [0.8189994908759815])\n",
            "Epoch : [46] Train loss : [0.010560609599841493] Val Score : [0.8189994908759815])\n",
            "Epoch : [47] Train loss : [0.010418686483587538] Val Score : [0.8041895926750926])\n",
            "Epoch : [48] Train loss : [0.010218347422778606] Val Score : [0.8189994908759815])\n",
            "Epoch : [49] Train loss : [0.010170226783624716] Val Score : [0.8189994908759815])\n",
            "Epoch 00050: reducing learning rate of group 0 to 6.2500e-04.\n",
            "\n",
            "etc col : V26 / Marco F1 Score : 0.9236496787663914\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V27\n",
            "Epoch : [0] Train loss : [0.24810077675751277] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.0787910387984344] Val Score : [0.0011937417393830074])\n",
            "Epoch : [2] Train loss : [0.09154423565736838] Val Score : [0.5553578945916403])\n",
            "Epoch : [3] Train loss : [0.11225362840507712] Val Score : [0.8519279892324237])\n",
            "Epoch : [4] Train loss : [0.0635180879118187] Val Score : [0.9165787375726882])\n",
            "Epoch : [5] Train loss : [0.06194469505654914] Val Score : [0.9165787375726882])\n",
            "Epoch : [6] Train loss : [0.06374125528548445] Val Score : [0.8786471773914175])\n",
            "Epoch : [7] Train loss : [0.05433747571493898] Val Score : [0.9137051774467988])\n",
            "Epoch : [8] Train loss : [0.04867819457181862] Val Score : [0.9097393418694286])\n",
            "Epoch : [9] Train loss : [0.03648415154644421] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.04002757503518036] Val Score : [0.9031202878275757])\n",
            "Epoch : [11] Train loss : [0.030109985997634276] Val Score : [0.9165787375726882])\n",
            "Epoch : [12] Train loss : [0.03450856637209654] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.04109331765877349] Val Score : [0.9165787375726882])\n",
            "Epoch : [14] Train loss : [0.049131381059331555] Val Score : [0.9165787375726882])\n",
            "Epoch : [15] Train loss : [0.0432686431865607] Val Score : [0.9165787375726882])\n",
            "Epoch 00016: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [16] Train loss : [0.02582528641713517] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.02132674366501825] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.02108012585501586] Val Score : [0.9165787375726882])\n",
            "Epoch : [19] Train loss : [0.01921360394252198] Val Score : [0.9165787375726882])\n",
            "Epoch : [20] Train loss : [0.022656979371926615] Val Score : [0.9165787375726882])\n",
            "Epoch : [21] Train loss : [0.01935482124931046] Val Score : [0.9165787375726882])\n",
            "Epoch : [22] Train loss : [0.02073146542534232] Val Score : [0.9137051774467988])\n",
            "Epoch : [23] Train loss : [0.020677808938281878] Val Score : [0.8674887641844412])\n",
            "Epoch : [24] Train loss : [0.017830449222986187] Val Score : [0.9165787375726882])\n",
            "Epoch : [25] Train loss : [0.016748796549758742] Val Score : [0.9165787375726882])\n",
            "Epoch : [26] Train loss : [0.015566253502454077] Val Score : [0.9165787375726882])\n",
            "Epoch 00027: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [27] Train loss : [0.012790119940681117] Val Score : [0.8927516353661109])\n",
            "Epoch : [28] Train loss : [0.012013924773782492] Val Score : [0.8598769209128951])\n",
            "Epoch : [29] Train loss : [0.012583158111998014] Val Score : [0.8772441968135101])\n",
            "Epoch : [30] Train loss : [0.01323556447667735] Val Score : [0.8724347298745778])\n",
            "Epoch : [31] Train loss : [0.012675442134163209] Val Score : [0.899903286500554])\n",
            "Epoch : [32] Train loss : [0.012055489234626293] Val Score : [0.8927516353661109])\n",
            "Epoch : [33] Train loss : [0.012949193029531412] Val Score : [0.8927516353661109])\n",
            "Epoch : [34] Train loss : [0.011775813265038388] Val Score : [0.8887833851083367])\n",
            "Epoch : [35] Train loss : [0.010747049602546863] Val Score : [0.899903286500554])\n",
            "Epoch : [36] Train loss : [0.010897471902093716] Val Score : [0.899903286500554])\n",
            "Epoch : [37] Train loss : [0.011609438474157028] Val Score : [0.8652615319692264])\n",
            "Epoch 00038: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [38] Train loss : [0.010467014940721648] Val Score : [0.8331926764657618])\n",
            "Epoch : [39] Train loss : [0.010157083560313498] Val Score : [0.8041895926750926])\n",
            "Epoch : [40] Train loss : [0.010000683699867554] Val Score : [0.8041895926750926])\n",
            "Epoch : [41] Train loss : [0.010197998623230628] Val Score : [0.8331926764657618])\n",
            "Epoch : [42] Train loss : [0.01031793128432972] Val Score : [0.8189994908759815])\n",
            "Epoch : [43] Train loss : [0.00987117551267147] Val Score : [0.8189994908759815])\n",
            "Epoch : [44] Train loss : [0.009940149262547493] Val Score : [0.8189994908759815])\n",
            "Epoch : [45] Train loss : [0.01016765513590404] Val Score : [0.8189994908759815])\n",
            "Epoch : [46] Train loss : [0.010110663050519568] Val Score : [0.8041895926750926])\n",
            "Epoch : [47] Train loss : [0.009875207208096981] Val Score : [0.8041895926750926])\n",
            "Epoch : [48] Train loss : [0.009971810039132833] Val Score : [0.8041895926750926])\n",
            "Epoch 00049: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [49] Train loss : [0.009699503891170025] Val Score : [0.7887218676684034])\n",
            "\n",
            "etc col : V27 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V28\n",
            "Epoch : [0] Train loss : [0.26735254590000423] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.08410843302096639] Val Score : [0.8041895926750926])\n",
            "Epoch : [2] Train loss : [0.06944090606910842] Val Score : [0.30405084405488114])\n",
            "Epoch : [3] Train loss : [0.06600033757942063] Val Score : [0.497049961451559])\n",
            "Epoch : [4] Train loss : [0.07249962990837437] Val Score : [0.8422634702634115])\n",
            "Epoch : [5] Train loss : [0.07390865843210902] Val Score : [0.9097393418694286])\n",
            "Epoch : [6] Train loss : [0.06815241277217865] Val Score : [0.9031202878275757])\n",
            "Epoch : [7] Train loss : [0.04775132105818817] Val Score : [0.9031202878275757])\n",
            "Epoch : [8] Train loss : [0.03654962352343968] Val Score : [0.8844834793761085])\n",
            "Epoch : [9] Train loss : [0.03637914718793971] Val Score : [0.626111065018391])\n",
            "Epoch : [10] Train loss : [0.033505626155861785] Val Score : [0.8244378451249526])\n",
            "Epoch : [11] Train loss : [0.028467189786689624] Val Score : [0.9165787375726882])\n",
            "Epoch : [12] Train loss : [0.03626437019556761] Val Score : [0.9165787375726882])\n",
            "Epoch : [13] Train loss : [0.030227197733308588] Val Score : [0.9165787375726882])\n",
            "Epoch : [14] Train loss : [0.027978687680193355] Val Score : [0.9165787375726882])\n",
            "Epoch : [15] Train loss : [0.031167428009212017] Val Score : [0.9031202878275757])\n",
            "Epoch : [16] Train loss : [0.0340131176635623] Val Score : [0.890501890608512])\n",
            "Epoch : [17] Train loss : [0.024478870843138014] Val Score : [0.890501890608512])\n",
            "Epoch : [18] Train loss : [0.02333542930760554] Val Score : [0.9031202878275757])\n",
            "Epoch : [19] Train loss : [0.026896095036395958] Val Score : [0.890501890608512])\n",
            "Epoch : [20] Train loss : [0.02129417099058628] Val Score : [0.8967110829723166])\n",
            "Epoch : [21] Train loss : [0.01765820656770042] Val Score : [0.9031202878275757])\n",
            "Epoch : [22] Train loss : [0.01651986495458654] Val Score : [0.8967110829723166])\n",
            "Epoch 00023: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [23] Train loss : [0.013672368600964546] Val Score : [0.9165787375726882])\n",
            "Epoch : [24] Train loss : [0.012851216298128878] Val Score : [0.9137051774467988])\n",
            "Epoch : [25] Train loss : [0.012594076139586312] Val Score : [0.9165787375726882])\n",
            "Epoch : [26] Train loss : [0.012287640744554145] Val Score : [0.9137051774467988])\n",
            "Epoch : [27] Train loss : [0.011888429056853056] Val Score : [0.9137051774467988])\n",
            "Epoch : [28] Train loss : [0.01108880533969828] Val Score : [0.9137051774467988])\n",
            "Epoch : [29] Train loss : [0.011250216314303023] Val Score : [0.9137051774467988])\n",
            "Epoch : [30] Train loss : [0.010847932193428278] Val Score : [0.8927516353661109])\n",
            "Epoch : [31] Train loss : [0.01063555252871343] Val Score : [0.8927516353661109])\n",
            "Epoch : [32] Train loss : [0.010492643474468164] Val Score : [0.8927516353661109])\n",
            "Epoch : [33] Train loss : [0.010349302419594355] Val Score : [0.9137051774467988])\n",
            "Epoch 00034: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [34] Train loss : [0.009990106602864606] Val Score : [0.8331926764657618])\n",
            "Epoch : [35] Train loss : [0.009752117563039064] Val Score : [0.8331926764657618])\n",
            "Epoch : [36] Train loss : [0.00973016070201993] Val Score : [0.8331926764657618])\n",
            "Epoch : [37] Train loss : [0.009681050133492266] Val Score : [0.8598769209128951])\n",
            "Epoch : [38] Train loss : [0.00966918348733868] Val Score : [0.8598769209128951])\n",
            "Epoch : [39] Train loss : [0.009546846483967133] Val Score : [0.8598769209128951])\n",
            "Epoch : [40] Train loss : [0.00949340992208038] Val Score : [0.8331926764657618])\n",
            "Epoch : [41] Train loss : [0.009558656585535832] Val Score : [0.8189994908759815])\n",
            "Epoch : [42] Train loss : [0.009431403196815933] Val Score : [0.8331926764657618])\n",
            "Epoch : [43] Train loss : [0.009422116912901402] Val Score : [0.8331926764657618])\n",
            "Epoch : [44] Train loss : [0.00944857079801815] Val Score : [0.8331926764657618])\n",
            "Epoch 00045: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [45] Train loss : [0.009183265934033054] Val Score : [0.8041895926750926])\n",
            "Epoch : [46] Train loss : [0.009125851959522282] Val Score : [0.8041895926750926])\n",
            "Epoch : [47] Train loss : [0.008984747675380536] Val Score : [0.7887218676684034])\n",
            "Epoch : [48] Train loss : [0.008925109037331172] Val Score : [0.7887218676684034])\n",
            "Epoch : [49] Train loss : [0.008889558458966869] Val Score : [0.7725514640071602])\n",
            "\n",
            "etc col : V28 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V29\n",
            "Epoch : [0] Train loss : [0.262229717203549] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.08706114175064224] Val Score : [0.2432421500201226])\n",
            "Epoch : [2] Train loss : [0.08576423674821854] Val Score : [0.8964462129361583])\n",
            "Epoch : [3] Train loss : [0.08903448815856661] Val Score : [0.9165787375726882])\n",
            "Epoch : [4] Train loss : [0.06420010487948145] Val Score : [0.9165787375726882])\n",
            "Epoch : [5] Train loss : [0.03664706793746778] Val Score : [0.9165787375726882])\n",
            "Epoch : [6] Train loss : [0.0463152877720339] Val Score : [0.8766620910809216])\n",
            "Epoch : [7] Train loss : [0.0334300941654614] Val Score : [0.9165787375726882])\n",
            "Epoch : [8] Train loss : [0.030019385873207023] Val Score : [0.9165787375726882])\n",
            "Epoch : [9] Train loss : [0.031757229406918795] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.028794928986046995] Val Score : [0.9165787375726882])\n",
            "Epoch : [11] Train loss : [0.03268429743392127] Val Score : [0.7951378447718795])\n",
            "Epoch : [12] Train loss : [0.033629706129431725] Val Score : [0.8418941739375176])\n",
            "Epoch : [13] Train loss : [0.03175345954618284] Val Score : [0.8464643763889133])\n",
            "Epoch : [14] Train loss : [0.03095383396638291] Val Score : [0.9097393418694286])\n",
            "Epoch 00015: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [15] Train loss : [0.024631307061229433] Val Score : [0.9165787375726882])\n",
            "Epoch : [16] Train loss : [0.02830814104527235] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.021018415423376218] Val Score : [0.9126016855919601])\n",
            "Epoch : [18] Train loss : [0.022284426726400852] Val Score : [0.9097393418694286])\n",
            "Epoch : [19] Train loss : [0.01963568219382848] Val Score : [0.9165787375726882])\n",
            "Epoch : [20] Train loss : [0.01745308010971972] Val Score : [0.9165787375726882])\n",
            "Epoch : [21] Train loss : [0.022026301960327795] Val Score : [0.9165787375726882])\n",
            "Epoch : [22] Train loss : [0.019716903500791107] Val Score : [0.9165787375726882])\n",
            "Epoch : [23] Train loss : [0.02239331024299775] Val Score : [0.9165787375726882])\n",
            "Epoch : [24] Train loss : [0.016851966069745167] Val Score : [0.9165787375726882])\n",
            "Epoch : [25] Train loss : [0.015456238029790776] Val Score : [0.9165787375726882])\n",
            "Epoch 00026: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [26] Train loss : [0.014082122926733323] Val Score : [0.9137051774467988])\n",
            "Epoch : [27] Train loss : [0.013136392791888543] Val Score : [0.899903286500554])\n",
            "Epoch : [28] Train loss : [0.01279747426243765] Val Score : [0.899903286500554])\n",
            "Epoch : [29] Train loss : [0.013215366285294294] Val Score : [0.899903286500554])\n",
            "Epoch : [30] Train loss : [0.0139897555511977] Val Score : [0.9137051774467988])\n",
            "Epoch : [31] Train loss : [0.01221958441393716] Val Score : [0.899903286500554])\n",
            "Epoch : [32] Train loss : [0.011978475510009698] Val Score : [0.9034120550289857])\n",
            "Epoch : [33] Train loss : [0.011843738013080187] Val Score : [0.899903286500554])\n",
            "Epoch : [34] Train loss : [0.01123409512053643] Val Score : [0.899903286500554])\n",
            "Epoch : [35] Train loss : [0.010753490629472904] Val Score : [0.899903286500554])\n",
            "Epoch : [36] Train loss : [0.010882423858025245] Val Score : [0.899903286500554])\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [37] Train loss : [0.01069590715425355] Val Score : [0.8598769209128951])\n",
            "Epoch : [38] Train loss : [0.010369825376463788] Val Score : [0.8331926764657618])\n",
            "Epoch : [39] Train loss : [0.00998367415741086] Val Score : [0.8189994908759815])\n",
            "Epoch : [40] Train loss : [0.010322413274220057] Val Score : [0.8331926764657618])\n",
            "Epoch : [41] Train loss : [0.009676442282008273] Val Score : [0.8189994908759815])\n",
            "Epoch : [42] Train loss : [0.00974516397608178] Val Score : [0.8189994908759815])\n",
            "Epoch : [43] Train loss : [0.009592886615012373] Val Score : [0.8189994908759815])\n",
            "Epoch : [44] Train loss : [0.009472825630967106] Val Score : [0.8189994908759815])\n",
            "Epoch : [45] Train loss : [0.009514234560940946] Val Score : [0.8189994908759815])\n",
            "Epoch : [46] Train loss : [0.009444681461900473] Val Score : [0.8189994908759815])\n",
            "Epoch : [47] Train loss : [0.009483662633491414] Val Score : [0.8189994908759815])\n",
            "Epoch 00048: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [48] Train loss : [0.009256173790033375] Val Score : [0.8041895926750926])\n",
            "Epoch : [49] Train loss : [0.009377021209469863] Val Score : [0.7725514640071602])\n",
            "\n",
            "etc col : V29 / Marco F1 Score : 0.9165787375726882\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "V30\n",
            "Epoch : [0] Train loss : [0.32886320033243727] Val Score : [0.0010529271374420891])\n",
            "Epoch : [1] Train loss : [0.13991944278989518] Val Score : [0.4382698327932996])\n",
            "Epoch : [2] Train loss : [0.08584186993539333] Val Score : [0.9137051774467988])\n",
            "Epoch : [3] Train loss : [0.046154777120266645] Val Score : [0.9165787375726882])\n",
            "Epoch : [4] Train loss : [0.04003722446837595] Val Score : [0.9165787375726882])\n",
            "Epoch : [5] Train loss : [0.03411141689866781] Val Score : [0.788554581959938])\n",
            "Epoch : [6] Train loss : [0.03248042041169746] Val Score : [0.8786471773914175])\n",
            "Epoch : [7] Train loss : [0.04538878186472824] Val Score : [0.9097393418694286])\n",
            "Epoch : [8] Train loss : [0.0324265245082123] Val Score : [0.9031202878275757])\n",
            "Epoch : [9] Train loss : [0.03159839540187802] Val Score : [0.9165787375726882])\n",
            "Epoch : [10] Train loss : [0.033018718739705424] Val Score : [0.9097393418694286])\n",
            "Epoch : [11] Train loss : [0.026550767943263054] Val Score : [0.9097393418694286])\n",
            "Epoch : [12] Train loss : [0.023984845727682114] Val Score : [0.9031202878275757])\n",
            "Epoch : [13] Train loss : [0.025484271879707063] Val Score : [0.9165787375726882])\n",
            "Epoch : [14] Train loss : [0.025626643959965025] Val Score : [0.9031202878275757])\n",
            "Epoch 00015: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [15] Train loss : [0.023750973599297658] Val Score : [0.9165787375726882])\n",
            "Epoch : [16] Train loss : [0.022809230190302645] Val Score : [0.9165787375726882])\n",
            "Epoch : [17] Train loss : [0.01758491001757128] Val Score : [0.9165787375726882])\n",
            "Epoch : [18] Train loss : [0.014799188822507858] Val Score : [0.9165787375726882])\n",
            "Epoch : [19] Train loss : [0.016061260231903622] Val Score : [0.9165787375726882])\n",
            "Epoch : [20] Train loss : [0.013883302586951427] Val Score : [0.9165787375726882])\n",
            "Epoch : [21] Train loss : [0.015119292174599] Val Score : [0.9165787375726882])\n",
            "Epoch : [22] Train loss : [0.013777372759899922] Val Score : [0.9165787375726882])\n",
            "Epoch : [23] Train loss : [0.013310415670275688] Val Score : [0.9165787375726882])\n",
            "Epoch : [24] Train loss : [0.013251842864389931] Val Score : [0.9165787375726882])\n",
            "Epoch : [25] Train loss : [0.012471678866339582] Val Score : [0.9165787375726882])\n",
            "Epoch 00026: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [26] Train loss : [0.011789918744138308] Val Score : [0.8927516353661109])\n",
            "Epoch : [27] Train loss : [0.011768759161766087] Val Score : [0.8927516353661109])\n",
            "Epoch : [28] Train loss : [0.011794997512229852] Val Score : [0.8927516353661109])\n",
            "Epoch : [29] Train loss : [0.011542876517134053] Val Score : [0.8927516353661109])\n",
            "Epoch : [30] Train loss : [0.011495603847184352] Val Score : [0.8845098845450512])\n",
            "Epoch : [31] Train loss : [0.011671641109777349] Val Score : [0.8927516353661109])\n",
            "Epoch : [32] Train loss : [0.011498879973909684] Val Score : [0.8927516353661109])\n",
            "Epoch : [33] Train loss : [0.011506539835993732] Val Score : [0.8927516353661109])\n",
            "Epoch : [34] Train loss : [0.011348545218684844] Val Score : [0.8927516353661109])\n",
            "Epoch : [35] Train loss : [0.011453958826937847] Val Score : [0.8927516353661109])\n",
            "Epoch : [36] Train loss : [0.011549049522727728] Val Score : [0.899903286500554])\n",
            "Epoch 00037: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch : [37] Train loss : [0.011365055638764585] Val Score : [0.8331926764657618])\n",
            "Epoch : [38] Train loss : [0.011070023091243846] Val Score : [0.8331926764657618])\n",
            "Epoch : [39] Train loss : [0.01114228620593037] Val Score : [0.8331926764657618])\n",
            "Epoch : [40] Train loss : [0.010996946266719274] Val Score : [0.8041895926750926])\n",
            "Epoch : [41] Train loss : [0.011112921072968416] Val Score : [0.8331926764657618])\n",
            "Epoch : [42] Train loss : [0.011034273475940739] Val Score : [0.8189994908759815])\n",
            "Epoch : [43] Train loss : [0.011026344794247831] Val Score : [0.8189994908759815])\n",
            "Epoch : [44] Train loss : [0.011048511735030584] Val Score : [0.8331926764657618])\n",
            "Epoch : [45] Train loss : [0.011000652664474078] Val Score : [0.8331926764657618])\n",
            "Epoch : [46] Train loss : [0.011257934117955821] Val Score : [0.8331926764657618])\n",
            "Epoch : [47] Train loss : [0.011135677873556103] Val Score : [0.8331926764657618])\n",
            "Epoch 00048: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch : [48] Train loss : [0.01088401089821543] Val Score : [0.8041895926750926])\n",
            "Epoch : [49] Train loss : [0.010790412314236164] Val Score : [0.7725514640071602])\n",
            "\n",
            "etc col : V30 / Marco F1 Score : 0.9165787375726882\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check(result, ts, val):\n",
        "\n",
        "  pred_result = []\n",
        "\n",
        "  for i in result:\n",
        "\n",
        "    if i >= ts:\n",
        "\n",
        "      i = 1\n",
        "\n",
        "    else:\n",
        "\n",
        "      i = 0\n",
        "\n",
        "    pred_result.append(i)\n",
        "\n",
        "  if val == True:\n",
        "\n",
        "    val_score = f1_score(y_val, pred_result, average='macro')\n",
        "    recall = recall_score(y_val, pred_result)\n",
        "    precision = precision_score(y_val, pred_result)\n",
        "\n",
        "    print(f'Marco F1 Score : {val_score}\\n')\n",
        "    print(f'Recall : {recall}\\n')\n",
        "    print(f'Precision : {precision}\\n')\n",
        "\n",
        "    print(classification_report(y_val, pred_result))\n",
        "\n",
        "  return pred_result"
      ],
      "metadata": {
        "id": "tvSbyHAh4mGk"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_val = check(result_val, 16, val=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jPsytCf5YL0",
        "outputId": "17e82e2a-94d3-4bcc-dcde-946a6194eb25"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marco F1 Score : 0.9236496787663914\n",
            "\n",
            "Recall : 0.8333333333333334\n",
            "\n",
            "Precision : 0.8620689655172413\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     28432\n",
            "           1       0.86      0.83      0.85        30\n",
            "\n",
            "    accuracy                           1.00     28462\n",
            "   macro avg       0.93      0.92      0.92     28462\n",
            "weighted avg       1.00      1.00      1.00     28462\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix = confusion_matrix(y_val, pred_val)\n",
        "sns.heatmap(cf_matrix, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "2ik01IURFu15",
        "outputId": "c7fc0013-c7af-4c62-b023-59cb7a60336e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test = check(result_test, 16, val=False)"
      ],
      "metadata": {
        "id": "WNBewGZxGMUI"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('./sample_submission.csv')"
      ],
      "metadata": {
        "id": "-9R_uDJSGbX7"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit['Class'] = pred_test\n",
        "submit.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JTk-Uq9TGl_O",
        "outputId": "fae8d0b3-82c8-4d02-f8ef-ef60b08f67b3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID  Class\n",
              "0  AAAA0x1      0\n",
              "1  AAAA0x2      0\n",
              "2  AAAA0x5      0\n",
              "3  AAAA0x7      0\n",
              "4  AAAA0xc      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4f1f9c6-b763-4099-8aa2-9a678a439906\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAAA0x1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAAA0x2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAAA0x5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAAA0x7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAAA0xc</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4f1f9c6-b763-4099-8aa2-9a678a439906')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4f1f9c6-b763-4099-8aa2-9a678a439906 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4f1f9c6-b763-4099-8aa2-9a678a439906');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit.to_csv('./submission_18.csv', index=False)"
      ],
      "metadata": {
        "id": "J01N6tyOGnOT"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iqhYUOL-G6ss"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}